[ { "title": "游戏和屏幕效果", "url": "/game-tech-post-old/posts/%E6%B8%B8%E6%88%8F%E5%92%8C%E5%B1%8F%E5%B9%95%E6%95%88%E6%9E%9C/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-04-20 00:00:00 +0800", "snippet": "第九章 游戏和屏幕效果当我们要创建可信和沉浸的游戏的时候，我们要考虑的不仅仅只有材料。屏幕效果也会改变游戏的整体感觉。这在电影里面非常常见，比如后期制作阶段中的调色。使用 第八章 通过Unity渲染纹理实现屏幕效果 中学到的知识，你也可以在游戏中实现这些技术。在这一章将会呈现两个有趣的效果；当然，你可以适当修改它们以适用于你的需求，也可以创建完全属于你自己屏幕效果。 在这一章，你将会学到下面...", "content": "第九章 游戏和屏幕效果当我们要创建可信和沉浸的游戏的时候，我们要考虑的不仅仅只有材料。屏幕效果也会改变游戏的整体感觉。这在电影里面非常常见，比如后期制作阶段中的调色。使用 第八章 通过Unity渲染纹理实现屏幕效果 中学到的知识，你也可以在游戏中实现这些技术。在这一章将会呈现两个有趣的效果；当然，你可以适当修改它们以适用于你的需求，也可以创建完全属于你自己屏幕效果。 在这一章，你将会学到下面的这些知识点： 创建一个老电影屏幕效果 创建一个夜视仪效果的屏幕效果 介绍 如果你正在阅读这本书，你很可能玩过一两个游戏。即时游戏一方面会使玩家进入一个沉浸世界，让人觉得他们好像在现实世界玩游戏一样。现代的游戏利用的屏幕效果越多获得的沉浸感也越多。 通过屏幕效果，我们可以将在某个确切环境中的心境从平静转为惊恐，仅仅只要改变屏幕看起来的样子。想象一下走进了某个关卡中的房间，然后游戏突然接管并且将你带进一个电影时刻。很多现代游戏都会使用不同的屏幕效果来改变不同时刻的一个心境。理解如何创建在游戏中使用的效果是我们学习编写着色器的下一个旅程。 在这一章，我们将了解一些更加常用的游戏中的屏幕效果。你将会学习如何改变游戏的样子，把它从正常的样子改成一个老电影效果的样子，并且我们还会去了解大多数 FPS（first-person shooter第一人称射击） 游戏是如何使他们的夜视效果呈现在屏幕中的。通过这些知识点，我们将了解如何将这些效果跟游戏中的事件关联起来，好让游戏根据当前演出的需要去打开或者关闭这些特效。创建一个老电影屏幕效果很多游戏背景设定在不同的时期。有些发生在幻想世界或者科幻世界，更有甚者发生在旧西部，那个时候电影摄像机才刚刚发明并且人们看到的都是一些黑白电影或者棕褐色效果色调的电影。它们看起来格外不同，我们将在Unity中用屏幕效果来复制这种看起来的样子。 获得这种效果需要一些步骤，如果要将整个屏幕变成黑或白或灰，我们需要将这个效果分解成不同的组成部分。如果我们分析一些相关的老电影的镜头，我们就可以开始做这个了。让我们来看看下面这张图片并且分解其中的元素，看看是那些构成了这个老电影的样子： 我们用一些在网上找到的图片构建了这个图片。像这样尝试利用Photoshop来构建图片总是一个很好的主意，它能为你的新的屏幕特效打好一个计划。在这个过程中它不仅能将我们需要用代码编写的元素告诉我们，还提供了一个快捷的方式让我们了解我们的屏幕效果需要使用哪一种混合模式和我们将要构建那些层级。本书这个知识点中我们为Photoshop创建的这些文件的支持网站在http://www.packtpub.com/support[已经失效(译者注)]。它是一个名为 OldFilmEffect_Research_Layout.psd 的文件。 始前准备 我们现在目的明确，让我们看看最终效果的每一层都包含了什么然后为我们的着色器和C#脚本收集一些资源。 复古色调（Sepia tone）： 这是一个相对容易获得的效果，我们只需把原始渲染纹理的所有像素颜色变为一个单一的颜色范围。使用原始图像的亮度然后加上一个常量颜色就可以很容易获得。我们的第一层将会看起来跟下面的图片一样： 渐晕效果（Vignette effect）： 当一些古老的电影放映机放映老电影的时候，我们经常看到某种软边界[ 我个人觉得翻译的不够准确 ]围绕在老电影的四周。这是因为这种电影放映机使用的球形灯泡发出的光中间部位比周围要亮造成的。这种效果通常叫做渐晕效果并且是我们屏幕效果的第二层。我们可以通过在整个屏幕上覆盖一张纹理来获得这个效果。下面的图片演示了这一层看起来的样子，就是一张纹理： 灰尘和划痕（Dust and scratches）： 第三层也是最后一层就是我们的老电影屏幕效果中的灰尘和划痕。这一层将使用两种不同的平铺纹理，一种作为划痕然后另一种作为灰尘。原因就是我们将根据时间以不同的速度对这两种纹理做动画。这将会产生一种效果，就是当电影在播放的时候同时在老电影的每一帧中都会有一些细小的划痕和灰尘。下图演示了它们的纹理看起来效果： 我们用前面的那些纹理来准备好我们的 屏幕效果系统（screen effect system）。按照下面的步骤来： 1.将 渐晕纹理（vignette texture） 和 灰尘划痕纹理（dust and scratches texture） 收集起来，就像我们前面看到的那几张。 2.创建一个名为 OldFilmEffect.cs 的新脚本和一个名为 OldFilmEffectShader.shader 的新着色器。 3.创建好这些新的文件后，给它们编写需要的代码来完成我们的屏幕效果系统并且顺利的跑起来。想知道具体如何做，可以参考 第八章 通过Unity渲染纹理实现屏幕效果 来了解。 最后，随着我们的屏幕效果系统完成并且顺利跑起来，以及收集好了我们的纹理，我们就可以开始复现老电影效果的制作过程了。 操作步骤 老电影屏幕效果的那些独特层级都很简单，但是将它们组合之后我们就能获得令人震惊的视觉效果。让我们缕一缕该怎么构建我们的脚本和着色器，之后我们就能逐行解析并且学习为什么可以那样写。此时，你应该有个设置好的屏幕效果系统而且能顺利运行，因为我们这个知识点不会涵盖如何设置这个系统。 1.我们将添加脚本代码。我们要输入的第一个代码块将定义我们的变量，这些变量会在 检查器 (Inspector) 上显示，好让这个效果的使用者可以可以用想填的数据修改它们。如我们还想在检查器上显示我们效果用到的那些我们处理好的Photoshop文件，也可以在此添加它们的引用。在脚本中添加下面的代码： #region Variablespublic Shader oldFilmShader;\tpublic float OldFilmEffectAmount = 1.0f;public float contrast = 3.0f;public float distortion = 0.2f;public float cubicDistortion = 0.6f;public float scale = 0.8f;\tpublic Color sepiaColor = Color.white;public Texture2D vignetteTexture;public float vignetteAmount = 1.0f;\tpublic Texture2D scratchesTexture;public float scratchesYSpeed = 10.0f;public float scratchesXSpeed = 10.0f;\tpublic Texture2D dustTexture;public float dustYSpeed = 10.0f;public float dustXSpeed = 10.0f;\tprivate Material curMaterial;private float randomValue;#endregion 2.接下来，我们需要修改 OnRenderImage() 方法中的内容了。在这里，我们将把脚本中变量的数据传给着着色器好让着色器在处理渲染纹理的时候可以使用这些数据： private void OnRenderImage(RenderTexture src, RenderTexture dest){ if(oldFilmShader != null) {\t material.SetColor(\"_SepiaColor\", sepiaColor); material.SetFloat(\"_VignetteAmount\", vignetteAmount); material.SetFloat(\"_EffectAmount\", OldFilmEffectAmount); material.SetFloat(\"_Contrast\", contrast); material.SetFloat(\"_cubicDistortion\", cubicDistortion); material.SetFloat(\"_distortion\", distortion); material.SetFloat(\"_scale\",scale);\t\t\t if(vignetteTexture) { material.SetTexture(\"_VignetteTex\", vignetteTexture); }\t\t\t if(scratchesTexture) { material.SetTexture(\"_ScratchesTex\", scratchesTexture); material.SetFloat(\"_ScratchesYSpeed\", scratchesYSpeed); material.SetFloat(\"_ScratchesXSpeed\", scratchesXSpeed); }\t\t\t if(dustTexture) { material.SetTexture(\"_DustTex\", dustTexture); material.SetFloat(\"_dustYSpeed\", dustYSpeed); material.SetFloat(\"_dustXSpeed\", dustXSpeed); material.SetFloat(\"_RandomValue\", randomValue); }\t\t\t Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }} 3.为了完成特效的脚本部分，接下来只要确保把变量值控制在合理的范围而不是任意值就可以了。 private void Update(){ vignetteAmount = Mathf.Clamp01(vignetteAmount); OldFilmEffectAmount = Mathf.Clamp(OldFilmEffectAmount, 0f, 1.5f); randomValue = Random.Range(-1f,1f); contrast = Mathf.Clamp(contrast, 0f, 4f); distortion = Mathf.Clamp(distortion, -1f,1f); cubicDistortion = Mathf.Clamp(cubicDistortion, -1f, 1f); scale = Mathf.Clamp(scale, 0f, 1f);} 注意 作者这里只贴了关键代码，下面是完整的脚本代码[译者注]： using UnityEngine;[ExecuteInEditMode]public class OldFilmEffect : MonoBehaviour{#region Variablespublic Shader oldFilmShader;\tpublic float OldFilmEffectAmount = 1.0f;public float contrast = 3.0f;public float distortion = 0.2f;public float cubicDistortion = 0.6f;public float scale = 0.8f;\tpublic Color sepiaColor = Color.white;public Texture2D vignetteTexture;public float vignetteAmount = 1.0f;\tpublic Texture2D scratchesTexture;public float scratchesYSpeed = 10.0f;public float scratchesXSpeed = 10.0f;\tpublic Texture2D dustTexture;public float dustYSpeed = 10.0f;public float dustXSpeed = 10.0f;\tprivate Material curMaterial;private float randomValue;#endregion\t#region PropertiesMaterial material{ get { if(curMaterial == null) { curMaterial = new Material(oldFilmShader); curMaterial.hideFlags = HideFlags.HideAndDontSave; } return curMaterial; }}#endregionprivate void Start(){ if (!SystemInfo.supportsImageEffects) { enabled = false; return; } if (oldFilmShader &amp;&amp; !oldFilmShader.isSupported) { enabled = false; }}private void OnRenderImage(RenderTexture src, RenderTexture dest){ if(oldFilmShader != null) {\t material.SetColor(\"_SepiaColor\", sepiaColor); material.SetFloat(\"_VignetteAmount\", vignetteAmount); material.SetFloat(\"_EffectAmount\", OldFilmEffectAmount); material.SetFloat(\"_Contrast\", contrast); material.SetFloat(\"_cubicDistortion\", cubicDistortion); material.SetFloat(\"_distortion\", distortion); material.SetFloat(\"_scale\",scale);\t\t\t if(vignetteTexture) { material.SetTexture(\"_VignetteTex\", vignetteTexture); }\t\t\t if(scratchesTexture) { material.SetTexture(\"_ScratchesTex\", scratchesTexture); material.SetFloat(\"_ScratchesYSpeed\", scratchesYSpeed); material.SetFloat(\"_ScratchesXSpeed\", scratchesXSpeed); }\t\t\t if(dustTexture) { material.SetTexture(\"_DustTex\", dustTexture); material.SetFloat(\"_dustYSpeed\", dustYSpeed); material.SetFloat(\"_dustXSpeed\", dustXSpeed); material.SetFloat(\"_RandomValue\", randomValue); }\t\t\t Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }}private void Update(){ vignetteAmount = Mathf.Clamp01(vignetteAmount); OldFilmEffectAmount = Mathf.Clamp(OldFilmEffectAmount, 0f, 1.5f); randomValue = Random.Range(-1f,1f); contrast = Mathf.Clamp(contrast, 0f, 4f); distortion = Mathf.Clamp(distortion, -1f,1f); cubicDistortion = Mathf.Clamp(cubicDistortion, -1f, 1f); scale = Mathf.Clamp(scale, 0f, 1f);}private void OnDisable(){ if (curMaterial) { DestroyImmediate(curMaterial); }}} 4.当我们的脚本完成之后，注意力转移到着色器上来。我们要在着色器上也创建跟脚本变量对应的着色器变量。这样的话可以让脚本跟着色器相互通信。在着色器的 属性块（Properties block） 中添加下面的代码： Properties{ _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _VignetteTex (\"Vignette Texture\", 2D) = \"white\"{} _ScratchesTex (\"Scartches Texture\", 2D) = \"white\"{} _DustTex (\"Dust Texture\", 2D) = \"white\"{} _SepiaColor (\"Sepia Color\", Color) = (1,1,1,1) _EffectAmount (\"Old Film Effect Amount\", Range(0,1)) = 1.0 _VignetteAmount (\"Vignette Opacity\", Range(0,1)) = 1.0 _ScratchesYSpeed (\"Scratches Y Speed\", Float) = 10.0 _ScratchesXSpeed (\"Scratches X Speed\", Float) = 10.0 _dustXSpeed (\"Dust X Speed\", Float) = 10.0 _dustYSpeed (\"Dust Y Speed\", Float) = 10.0 _RandomValue (\"Random Value\", Float) = 1.0 _Contrast (\"Contrast\", Float) = 3.0 _distortion (\"Distortion\", Float) = 0.2 _cubicDistortion (\"Cubic Distortion\", Float) = 0.6 _scale (\"Scale (Zoom)\", Float) = 0.8} 5.接下来，跟往常一样，接下来在 CGPROGRAM 块中添加与属性块对应的变量好让属性块可以跟 CGPROGRAM 块通信： uniform sampler2D _MainTex;uniform sampler2D _VignetteTex;uniform sampler2D _ScratchesTex;uniform sampler2D _DustTex;fixed4 _SepiaColor;fixed _VignetteAmount;fixed _ScratchesYSpeed;fixed _ScratchesXSpeed;fixed _dustXSpeed;fixed _dustYSpeed;fixed _EffectAmount;fixed _RandomValue;fixed _Contrast;float _distortion;float _cubicDistortion;float _scale; 6.现在，我们简单的将 frag() 函数内容修改一下好让我们能处理屏幕效果上的像素。让我们获取来自脚本的 渲染纹理（render texture） 和 渐晕纹理（vignette texture）： fixed4 frag(v2f_img i) : COLOR{ //获得渲染纹理的颜色并且获取 v2f_img的uv half2 distortedUV = barrelDistortion(i.uv); distortedUV = half2(i.uv.x, i.uv.y + (_RandomValue * _SinTime.z * 0.005)); fixed4 renderTex = tex2D(_MainTex, i.uv); //获取渐晕纹理的像素 fixed4 vignetteTex = tex2D(_VignetteTex, i.uv); 7.我们接下来添加处理划痕和灰尘的代码： //处理划痕的UV和像素half2 scratchesUV = half2(i.uv.x + (_RandomValue * _SinTime.z * _ScratchesXSpeed), i.uv.y + (_Time.x * _ScratchesYSpeed));fixed4 scratchesTex = tex2D(_ScratchesTex, scratchesUV);//处理灰尘的UV和像素half2 dustUV = half2(i.uv.x + (_RandomValue * (_SinTime.z * _dustXSpeed)), i.uv.y + (_RandomValue * (_SinTime.z * _dustYSpeed)));fixed4 dustTex = tex2D(_DustTex, dustUV); 8.接下来处理深褐色色调： //使用YIQ值从渲染纹理中获取亮度值。fixed lum = dot(fixed3(0.299, 0.587, 0.114), renderTex.rgb);//给亮度值加上一个常量颜色fixed4 finalColor = lum + lerp(_SepiaColor, _SepiaColor + fixed4(0.1f, 0.1f, 0.1f, 1.0f), _RandomValue);finalColor = pow(finalColor, _Contrast); 9.最后，我们将所有的层和颜色都叠加到一块并将最终的屏幕效果纹理返回： //创建一个白色的常量颜色，这样我们可以调节效果的不透明度。 fixed3 constantWhite = fixed3(1,1,1); //将不同的层混合到一起来创建最终的屏幕效果 finalColor = lerp(finalColor, finalColor * vignetteTex, _VignetteAmount); finalColor.rgb *= lerp(scratchesTex, constantWhite, (_RandomValue)); finalColor.rgb *= lerp(dustTex.rgb, constantWhite, (_RandomValue * _SinTime.z)); finalColor = lerp(renderTex, finalColor, _EffectAmount); return finalColor;} 10.当我们把所有代码都完成并且没有遇到错误，你应该有个跟下图很相似的结果。在编辑器中点击运行按钮，就可以看到灰尘效果和划痕效果，而且可以看到屏幕效果上的轻微的图片位移： 注意 作者少说了一个函数，将下面的 barrelDistortion 函数添加到 frag() 函数上面[译者注]： float2 barrelDistortion(float2 coord) { // Inspired by SynthEyes lens distortion algorithm // See http://www.ssontech.com/content/lensalg.htm float2 h = coord.xy - float2(0.5, 0.5); float r2 = h.x * h.x + h.y * h.y; float f = 1.0 + r2 * (_distortion + _cubicDistortion * sqrt(r2)); return f * _scale * h + 0.5;} –已经不用了 " }, { "title": "屏幕效果中的覆盖混合模式", "url": "/game-tech-post-old/posts/%E5%B1%8F%E5%B9%95%E6%95%88%E6%9E%9C%E4%B8%AD%E7%9A%84%E8%A6%86%E7%9B%96%E6%B7%B7%E5%90%88%E6%A8%A1%E5%BC%8F/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-04-18 00:00:00 +0800", "snippet": "屏幕效果中的覆盖混合模式对于我们最后要讲的知识点，我们将会去了解另一种混合模式，覆盖混合模式。这种模式实际上是利用了一些条件声明，这些条件声明决定了每个通道上的每个像素的最终颜色。所以，在使用这种混合模式的过程中需要编写的代码会更多一些。接下来我们看看该如何实现它。 始前准备 对于最后这个屏幕特效，我们需要像前面两个知识点中那样设置两个脚本（一个C#， 一个shader）。对于这个知识点，...", "content": "屏幕效果中的覆盖混合模式对于我们最后要讲的知识点，我们将会去了解另一种混合模式，覆盖混合模式。这种模式实际上是利用了一些条件声明，这些条件声明决定了每个通道上的每个像素的最终颜色。所以，在使用这种混合模式的过程中需要编写的代码会更多一些。接下来我们看看该如何实现它。 始前准备 对于最后这个屏幕特效，我们需要像前面两个知识点中那样设置两个脚本（一个C#， 一个shader）。对于这个知识点，我们将使用之前使用的场景，所以我们不必创建新的场景了： 1.分别创建一个名为 Overlay_ImageEffect 的C#脚本和一个名为 Overlay_Effect 的着色器脚本。 2.把上一个知识点中用的C#脚本代码复制到这个新的C#脚本中来。 3.将上一个知识点中使用的着色器代码复制到这个新的着色器代码中来。 4.将 Overlay_ImageEffect C#脚本挂载到主摄像机上（注意把之前的C#脚本先移除），然后在 查看面板（Inspector） 中将 Overlay_Effect 着色器拖拽到C#脚本组件的着色器变量上。 5.然后分别双击C#脚本和着色器在代码编辑器上打开它们。 操作步骤 开始处理我们的覆盖屏幕效果，我们将需要完成着色器代码而且要运行起来没有错误。接下来我们就可以修改C#脚本用来给着色器发送正确的数据。 1.首先要做的是在着色器的 属性块（Properties block） 中添加需要的属性。我们将使用这一章前面几个知识点中一样的一些属性： Properties{ _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _BlendTex (\"Blend Texture\", 2D) = \"white\" {} _Opacity (\"Blend Opacity\", Range(0, 1)) = 1} 2.接下来我们需要在 CGPROGRAM 代码块之内添加与属性对应的变量： CGPROGRAM#pragma vertex vert_img#pragma fragment frag#pragma fragmentoption ARB_precision_hint_fastest#include \"UnityCG.cginc\"uniform sampler2D _MainTex;uniform sampler2D _BlendTex;fixed _Opacity; 3.为了让 覆盖混合效果（Overlay Blend effect） 能起作用，我们必须要分别处理每通道中的每一个像素。为了实现这一操作，我们要编写一个自定义函数，这个函数接收一个单独通道，比如传递一个红色通道给它，并且进行覆盖操作。在着色器的变量声明下面输入下面的代码： fixed OverlayBlendMode(fixed basePixel, fixed blendPixel){ if(basePixel &lt; 0.5) { return (2.0 * basePixel * blendPixel); } else { return (1.0 - 2.0 * (1.0 - basePixel) * (1.0 - blendPixel)); }} 4.最后，我们要去修改 frag() 函数来处理纹理的每一个通道从而进行混合操作： fixed4 frag(v2f_img i) : COLOR{ //获得渲染纹理的颜色并且获取 v2f_img的uv fixed4 renderTex = tex2D(_MainTex, i.uv); fixed4 blendTex = tex2D(_BlendTex, i.uv); fixed4 blendedImage = renderTex; blendedImage.r = OverlayBlendMode(renderTex.r, blendTex.r); blendedImage.g = OverlayBlendMode(renderTex.g, blendTex.g); blendedImage.b = OverlayBlendMode(renderTex.b, blendTex.b); //对混合模式程度进行线性插值 renderTex = lerp(renderTex, blendedImage, _Opacity); return renderTex;} 5.当我们的着色器代码编写好后，我们的期待的效果应该起作用了。保存着色器代码并且返回到Unity编辑器让着色器编译。我们的C#脚本完全不用改并且已经设置好了。当着色器编译完成之后，你将会看到跟下图相似的一个结果： 原理介绍 我们的覆盖混合模式的确涉及到了很多更深的内容，但是如果你真的仔细剖析这些函数的话，你就会发现它是一个简单的 multiply 混合模式和一个简单的 屏幕混合模式（screen blend mode） （就是说可以拆为这两个，通过条件语句）。真的就是那样，在这个例子中，我们通过条件检测对一个像素执行不同的混合模式。 通过这个特定的屏幕效果，当 覆盖函数（Overlay function） 接收到一个像素后，会检测它是否小于0.5.如果是，我们就对它执行一个修改过的 multiply 混合模式；如果不是，则对它执行一个修改过的 屏幕混合模式（screen blend mode）。对于每个通道上的每一个像素我们都执行上述操作，最终得到我们屏幕效果的RGB像素值。 正如你所看到的，对于屏幕效果来说可以做很多的事情。这真的就取决于是什么平台和可以为屏幕效果分配多少内存。通常，这是由游戏项目的整个过程决定的，所以，玩的开心并且在屏幕效果上尽情发挥你的想象力吧。" }, { "title": "在屏幕效果中使用基础的类photoshop混合模式", "url": "/game-tech-post-old/posts/%E5%9C%A8%E5%B1%8F%E5%B9%95%E6%95%88%E6%9E%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%E7%9A%84%E7%B1%BBPhotoshop%E6%B7%B7%E5%90%88%E6%A8%A1%E5%BC%8F/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-04-16 00:00:00 +0800", "snippet": "在屏幕效果中使用基础的类Photoshop混合模式屏幕效果不仅仅只限于调整游戏中渲染纹理的颜色。我们还可以使用它将渲染纹理和其他的图像结合在一起。这个技术跟Photoshop中创建一个新的图层没有什么不同然后选择一种混合模式将两张图片混合在一起，当然在我们这里就是将一张纹理跟渲染纹理混合。这是一个非常强的技术，因为它提供给了艺术家一个在游戏中模拟混合模式的生产环境，而不不仅仅只是在Photo...", "content": "在屏幕效果中使用基础的类Photoshop混合模式屏幕效果不仅仅只限于调整游戏中渲染纹理的颜色。我们还可以使用它将渲染纹理和其他的图像结合在一起。这个技术跟Photoshop中创建一个新的图层没有什么不同然后选择一种混合模式将两张图片混合在一起，当然在我们这里就是将一张纹理跟渲染纹理混合。这是一个非常强的技术，因为它提供给了艺术家一个在游戏中模拟混合模式的生产环境，而不不仅仅只是在Photoshop中。 对于这个特定的知识点，我们将会了解一些更加常用的混合模式，比如说 Multiply，Add 和 Overlay。你将会看到在游戏中拥有一个Photoshop中的混合模式的功能是多么的简单。 始前准备 开始前，我们需要准备资源。所以请跟着下面的步骤为我们新的 混合模式屏幕效果（ Blend mode screen effect） 设置好我们的屏幕效果系统并且让它顺利运行起来： 1.创建一个新的C#脚本，并且为其命名为 BlendMode_ImageEffect 2.创建一个新的着色器，命名为 BlendMode_Effect 3.我们简单的将我们本章节第一个知识点中的C#脚本中的代码复制到我们这个新的C#脚本中来。这样我们就可以将精力放在混合模式效果实现的数学原理上。 4.同样，将本章节第一个知识点中的着色器代码赋值到我们这个新的着色器代码中来。 5.最后，我们需要一张额外的纹理来表现我们的混合模式效果。在这个知识点，我们将使用一张 粗旧类型纹理（grunge type texture）。它能让测试效果看起来非常明显。 下图是这个效果要使用的一张粗旧型贴图。使用一张有足够细节和有良好灰度值范围的纹理有助于我们测试新的效果： 操作步骤 我们第一个要实现的混合模式是Photoshop中的一样的 Multiply 混合模式。让我们先修改我们着色器中的代码。 1.在Unity的项目窗口中双击着色器，在代码编辑器中打开我们的着色器代码。 2.我们需要在属性块中添加一些新的属性好让我们可以有纹理可以混合并且要有一个 不透明度滑动条（a slider for an opacity value）。在你的着色器中输入下面的代码： Properties{ _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _BlendTex (\"Blend Texture\", 2D) = \"white\" {} _Opacity (\"Blend Opacity\", Range(0, 1)) = 1} 3.在 CGPROGRAM 代码块中添加与属性对应的变量好让我们可以访问 属性块（Properties block） 中的数据： CGPROGRAM#pragma vertex vert_img#pragma fragment frag#pragma fragmentoption ARB_precision_hint_fastest#include \"UnityCG.cginc\"uniform sampler2D _MainTex;uniform sampler2D _BlendTex;fixed _Opacity; 4.最后我们修改 frag() 函数从而来表现我们两张纹理的 multiply 操作： fixed4 frag(v2f_img i) : COLOR{ //获得渲染纹理的颜色并且获取 v2f_img的uv fixed4 renderTex = tex2D(_MainTex, i.uv); fixed4 blendTex = tex2D(_BlendTex, i.uv); //执行 multiplay 混合模式 fixed4 blendedMultiply = renderTex * blendTex; //对混合模式程度进行线性插值 renderTex = lerp(renderTex, blendedMultiply, _Opacity); return renderTex;} 5.保存着色器代码并且返回Unity编辑器，让着色器编译并且看看有没有错误。如果没有遇到错误，我们就双击C#脚本在代码编辑器中打开。 6.在C#脚本中我们同样需要创建一些相应的变量。我们需要一个纹理变量用来赋值纹理并且将它发送给着色器，我们还需要一个滑动条用来调整我们想要的混合模式的最终程度： #region Variablespublic Shader curShader;public Material curMaterial;public Texture2D blendTexture;public float blendOpacity = 1.0f;#endregion 7.接下来，我们需要通过 OnRenderImage() 方法给着色器传递我们的变量数据： private void OnRenderImage(RenderTexture src, RenderTexture dest){ if (curShader != null) { material.SetTexture(\"_BlendTex\", blendTexture); material.SetFloat(\"_Opacity\", blendOpacity); Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }} 8.为了完成我们的脚本，我们还要修改 Update() 方法，这样我们就能把 blendOpacity 变量的值控制在 [0, 1] 范围内。 private void Update(){ blendOpacity = Mathf.Clamp(blendOpacity, 0.0f, 1.0f);} 当这些都完成之后，我们将屏幕效果脚本挂到我们的主摄像机上并且将我们的着色器拖拽赋值到我们的C#脚本中，这样让脚本可以有一个着色器来进行逐像素操作。最终，为了让效果能完全发挥功能，脚本和着色器都需要一张纹理。你可以在Unity的 检查器面板（Inspector tab） 给屏幕效果脚本的纹理变量添加任何一张纹理。一旦你添加了一张纹理，你就能看到游戏的渲染纹理之上还有我们刚刚添加的纹理，并且已经进行了 multiplying 混合操作。下图演示了这个屏幕效果： 下图演示了当不透明度更高时，对图像进行 multiplying 操作让它叠在渲染纹理上的表现更加明显： 随着我们第一个混合模式设置好，对于添加其他混合模式效果和调整游戏的最终效果也能更容易举一反三。不过，我们先剖析一下当前发生了什么。 原理介绍 现在我们在 屏幕效果（Screen Effects） 编程上获得了很大的能力和灵活性。我可以肯定你现在已经逐渐理解在Unity中这么一个简单的系统能实现多少效果了。我们可以在游戏中从字面上去复制Photoshop的层级效果功能，这能让艺术家们灵活的在短时间内获得高质量的图形效果。 通过这一知识点的内容，我们了解了如何让两张图片通过 multiply 混合模式处理，将他们叠加到一起，并且如何通过一点数学知识，在屏幕上执行混合模式。在使用混合模式的时候，有一点时在逐像素操作时需要思考的。比如，什么时候我们用 multiply 混合模式，我们在字面意义上从原渲染纹理上获取像素然后跟要混合的纹理上的像素进行 multiply 操作。add 混合模式也是这样的一个过程。也是从原渲染纹理（或渲染纹理）中获取像素然后跟要混合的纹理上的像素进行 add 操作这么一个简单的数学过程。 屏幕混合模式肯定还有更深的内容，不过过程都是一样的。这个过程中获取图像，渲染纹理和混合纹理，将它们进行数据的转化，然后将他们叠加在一起，之后又将这些数据转化从而获得最终的样子。就跟Photoshop使用混合模式将那些图片混合在一起一样，我们可以使用屏幕效果做同样的事情。 额外内容 继续这一知识点，给我们的屏幕效果添加一些其他的混合模式。 在屏幕效果着色器中，给 frag() 函数添加下面着色器代码然后修改返回给脚本的值。我们要注释掉 multiply 混合的代码，我们不需要这个返回： fixed4 frag(v2f_img i) : COLOR{ //获得渲染纹理的颜色并且获取 v2f_img的uv fixed4 renderTex = tex2D(_MainTex, i.uv); fixed4 blendTex = tex2D(_BlendTex, i.uv); //执行 multiplay 混合模式 //fixed4 blendedMultiply = renderTex * blendTex; fixed4 blendedAdd = renderTex + blendTex; //对混合模式程度进行线性插值 renderTex = lerp(renderTex, blendedAdd, _Opacity); return renderTex;} 1.保存着色器代码然后返回Unity编辑器让着色器代码编译。如果没有出现错误，你将会看到类似下图的一个结果。这个就是一个简单的 add 混合模式： 你可以看到，它的效果跟 multiply 混合模式相反因为我们是将两个图片进行了 add 混合操作。 2.最后让我们再添加一个叫做 屏幕混合（Screen Blend） 的混合模式。这个效果在数学上来说稍微深一点，但实现起来依然简单。在着色器的 frag() 函数中输入下面的代码： fixed4 frag(v2f_img i) : COLOR{ //获得渲染纹理的颜色并且获取 v2f_img的uv fixed4 renderTex = tex2D(_MainTex, i.uv); fixed4 blendTex = tex2D(_BlendTex, i.uv); //执行 multiplay 混合模式 //fixed4 blendedMultiply = renderTex * blendTex; //fixed4 blendedAdd = renderTex + blendTex; fixed4 blendScreen = (1.0 - ((1.0 - renderTex) * (1.0 - blendTex))); //对混合模式程度进行线性插值 renderTex = lerp(renderTex, blendScreen, _Opacity); return renderTex;} 下图的屏幕效果演示了使用 屏幕混合（Screen Blend） 模式将两张图片混合到一起的结果： " }, { "title": "在屏幕效果中使用亮度, 饱和度和对比度", "url": "/game-tech-post-old/posts/%E5%9C%A8%E5%B1%8F%E5%B9%95%E6%95%88%E6%9E%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%BA%AE%E5%BA%A6,-%E9%A5%B1%E5%92%8C%E5%BA%A6%E5%92%8C%E5%AF%B9%E6%AF%94%E5%BA%A6/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-04-15 00:00:00 +0800", "snippet": "在屏幕效果中使用亮度, 饱和度和对比度现在我们有了自己的屏幕效果系统并且能正常运行，我们就可以去探索在当今的游戏当中更多涉及到像素操作的一些更常用的屏幕效果。 首先，使用屏幕效果来调节游戏整体的最终颜色效果，这肯定可以给艺术家对于游戏最终的样子，有一个全局的控制。比如可以用一些颜色滑动条用来调节游戏最终渲染结果的 R,G,B 颜色强度。又或者是给整个屏幕填充大量的某个颜色这样看起来就像是一种...", "content": "在屏幕效果中使用亮度, 饱和度和对比度现在我们有了自己的屏幕效果系统并且能正常运行，我们就可以去探索在当今的游戏当中更多涉及到像素操作的一些更常用的屏幕效果。 首先，使用屏幕效果来调节游戏整体的最终颜色效果，这肯定可以给艺术家对于游戏最终的样子，有一个全局的控制。比如可以用一些颜色滑动条用来调节游戏最终渲染结果的 R,G,B 颜色强度。又或者是给整个屏幕填充大量的某个颜色这样看起来就像是一种深褐色的胶片效果。 对于这个特殊的知识点，我们将会涵盖一些可以在图像上进行的更加核心的颜色修改操作。它们是 亮度（brightness）, 饱和度（saturation） 和 对比度（contrast）。学习如何对这些颜色调整过程进行编码，将给我们学习屏幕的艺术效果一个很好的基础。 始前准备 这里我们需要创建一些新的资源。我们可以利用同样的场景作为我们的测试场景，但是我们需要一个新的脚本和着色器： 1.创建一个新的名为 BSC_ImageEffect 的脚本。 2.创建一个名为 BSC_Effect 的新着色器。 3.现在我们需要简单将前一个知识点中的脚本代码复制到现在这个新的脚本中来。这样的话可以让我们把重点放在亮度，饱和度和对比度的数学原理上。 4.把上一个知识点中的着色器代码复制到我们这个新的着色器中。 5.在场景中创建几个新的游戏对象，然后添加几个不同颜色的漫反射材质球，然后把这些材质球随机的添加给场景中这几个新的游戏对象。这将会给我们一个很好的颜色范围来测试我们的新屏幕效果。 当这些完成之后，你将会有一个类似于下图的游戏场景： 操作步骤 现在我们设置好了我们的场景并且创建好了我们的新脚本和着色器，我们可以开始填写必要的代码从而获得亮度，饱和度和对比度屏幕特效了。我们将着重于像素操作和为我们的脚本和着色器设置好变量。就跟我们在 设置屏幕效果脚本系统 这个知识点中描述的一样，准备好我们的屏幕效果系统并且让它跑起来： 1.用我们的代码编辑器打开我们的脚本和着色器。我们只需简单在 项目窗口（project view） 双击就可以进行前面的两个操作。 2.先编辑着色器，这样可以让我们更加清楚我们的C#脚本需要哪些变量。我们先在属性块中给亮度，饱和度和对比度效果添加对应的属性。注意，我们要保留属性块中的 _MainTex 属性，因为这是我们创建屏幕效果时 渲染纹理 目标需要的属性： Properties{ _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _BrightnessAmount (\"Brightness Amount\", Range(0.0, 1)) = 1.0 _satAmount (\"Saturation Amount\", Range(0.0, 1)) = 1.0 _conAmount (\"Contrast Amount\", Range(0.0, 1)) = 1.0} 3.如往常一样，为了能在 CGPROGRAM 代码块中访问来自属性的数据，我们需要在 CGPROGRAM 代码块中创建与之对应的变量： CGPROGRAM#pragma vertex vert_img#pragma fragment frag#pragma fragmentoption ARB_precision_hint_fastest#include \"UnityCG.cginc\"uniform sampler2D _MainTex;fixed _BrightnessAmount;fixed _satAmount;fixed _conAmount; 4.现在我们需要添加一些操作好用来表现我们的亮度，饱和度和对比度效果。在我们的着色器中添加下面的新函数，在 frag() 函数上面添加即可。不要担心它现在虽然还没啥用；我们将在下一个知识点中解释所有的代码： float3 ContrastSaturationBrightness(float3 color, float brt, float sat, float con){ float AvgLumR = 0.5; float AvgLumG = 0.5; float AvgLumB = 0.5; float LuminanceCoeff = float3(0.2125, 0.7154, 0.0721); float3 AvgLumin = float3(AvgLumR, AvgLumG, AvgLumB); float3 brtColor = color * brt; float intensityf = dot(brtColor, LuminanceCoeff); float3 intensity = float3(intensityf, intensityf, intensityf); float3 satColor = lerp(intensity, brtColor, sat); float3 conColor = lerp(AvgLumin, satColor, con); return conColor;} 5.最后，我们需要更新 frag() 函数去使用 ContrastSaturationBrightness() 函数。这将会处理我们渲染纹理的所有像素并且传回给我们的C#脚本： fixed4 frag(v2f_img i) : COLOR{ fixed4 renderTex = tex2D(_MainTex, i.uv); renderTex.rgb = ContrastSaturationBrightness(renderTex.rgb, _BrightnessAmount, _satAmount, _conAmount); return renderTex;} 着色器代码写好之后，返回Unity编辑器让它编译着色器。如果没有报错，我们返回代码编辑器来编辑C#脚本了。开始时先创建几行新的代码用来发送合适数据给着色器： 1.我们的第一步是修改我们的脚本添加合适的变量，这些变量将驱动屏幕效果中相应的值。在这里，我们分别需要三个滑动条，它们分别用来调整亮度，饱和度和对比度： #region Variablespublic Shader curShader;public Material curMaterial;public float brightnessAmount = 1.0f;public float saturationAmount = 1.0f;public float contrastAmount = 1.0f;#endregion 2.设置好我们的变量后，现在我们需要让脚本把它的数据传给着色器。我们在 OnRenderImage() 方法实现这一操作： private void OnRenderImage(RenderTexture src, RenderTexture dest){ if (curShader != null) { material.SetFloat(\"_BrightnessAmount\", brightnessAmount); material.SetFloat(\"_satAmount\", saturationAmount); material.SetFloat(\"_conAmount\", contrastAmount); Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }} 3.最后，我们需要将变量的值控制在一个合理的范围。这些控制范围内的值完全优先，这样你可以使用任何你觉得合适的值： private void Update(){ brightnessAmount = Mathf.Clamp(brightnessAmount, 0.0f, 2.0f); saturationAmount = Mathf.Clamp(brightnessAmount, 0.0f, 2.0f); contrastAmount = Mathf.Clamp(brightnessAmount, 0.0f, 3.0f);} 当我们的脚本和着色器完成之后，我们只需将脚本挂在我们的主摄像机上并且将着色器添加到我们的脚本中，之后你通过修改滑动条的值就应该可以看到亮度，饱和度和对比度的效果变化了。下图展示了你能得到的屏幕效果： 下面的图片展示了另一个例子，它可以通过调整渲染图像的颜色获得： 原理介绍 从我们知道基本的屏幕效果系统是如何工作的之后，我们就在 ContrastSaturationBrightness() 函数中实现了这一逐像素操作。 函数的开头接收了一些参数，首先也是最重要的就是当前的渲染纹理。而其他的参数仅是用来调整屏幕效果的整体效果并且它们就是对应在 检查面板（Inspector tab） 中的那些滑动条。当这个函数接收到渲染纹理和那些调整后的值后，它就声明了一些常量，我们用这些常量去跟原始的渲染纹理进行修改和比较。 变量 luminanceCoeff 中保存的值可以给我们当前图像的整体亮度。这个系数是基于 CIE（国际照明委员会） 色 匹配函数并且对于整个工业来说还挺标准的。通过当前图像和这个亮度系数的 dot 操作的投影，我们可以得到图像的整体亮度。一旦我们有了亮度，我就用一些 lerp 函数，来混合亮度操作的灰度图和跟亮度值进行了乘操作的原始图像， 这些参数传递给lerp函数。【抱歉，前面这一句我不会翻译，这里我觉得有问题，所以把英文贴出来：Once we have the brightness, we simply use a couple of lerp functions to blend from the grayscale version of the brightness operation and the original image multiplied by the brightness value, being passed into the function.】 屏幕效果对于你的游戏获得高质量的图形来说是至关重要的，就好比我们这个屏幕效果，因为它不用你麻烦的去编辑你当前游戏场景中的每一个材质就可以改变游戏的最终样子。" }, { "title": "通过unity渲染纹理实现屏幕效果", "url": "/game-tech-post-old/posts/%E9%80%9A%E8%BF%87Unity%E6%B8%B2%E6%9F%93%E7%BA%B9%E7%90%86%E5%AE%9E%E7%8E%B0%E5%B1%8F%E5%B9%95%E6%95%88%E6%9E%9C/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-04-02 00:00:00 +0800", "snippet": "第八章 通过Unity渲染纹理实现屏幕效果我们在这一章会学习下面的这些知识点： 设置屏幕效果脚本系统 在屏幕效果中使用亮度, 饱和度和对比度 在屏幕效果中使用基础的类Photoshop混合模式 屏幕效果中的覆盖混合模式 介绍 学习编写着色器最让人印象深刻的是创建你自己的屏幕效果的过程，也就是常说的后处理。有了这些屏幕效果，我们就可以用 Bloom，Motion Blur 和 HDR...", "content": "第八章 通过Unity渲染纹理实现屏幕效果我们在这一章会学习下面的这些知识点： 设置屏幕效果脚本系统 在屏幕效果中使用亮度, 饱和度和对比度 在屏幕效果中使用基础的类Photoshop混合模式 屏幕效果中的覆盖混合模式 介绍 学习编写着色器最让人印象深刻的是创建你自己的屏幕效果的过程，也就是常说的后处理。有了这些屏幕效果，我们就可以用 Bloom，Motion Blur 和 HDR 效果等技术创建出一些惊奇的实时图像。当今游戏市场推出的大部分游戏在 景深（depth of field） 效果，辉光（bloom） 效果甚至 颜色修正（color correction） 效果上都大量使用了屏幕效果。 通过这个章节，你将会学习如何构建一个如何去控制这些屏幕效果的脚本系统。我们将会涵盖 渲染纹理（Render Texture），深度缓冲（depth buffer），以及如何创建一个类Photoshop感的效果，从而去控制游戏的最终渲染图片的效果。通过为你的游戏使用屏幕效果，你不经可以完成你的着色器编写知识，同时你还将会拥有在Unity中创自己那些不可思议的渲染器的能力。 设置屏幕效果脚本系统 创建屏幕效果是这么一个过程，我们先抓取一张全屏的图像（或者纹理），然后用一个着色器在GPU中去处理它的像素，之后再把它发回给Unity的渲染器并且应用到游戏的整个渲染好的图像上去。这样的话就允许我们实时的在游戏的渲染图片上进行逐像素操作了，从而使我们对艺术效果有更广的控制。 试想一下如果你不得不仔细检查并且调节你游戏中每一个游戏对象上的每个材质，而这么做仅仅是想调节游戏最终视效的对比度。尽管可行，但还是有点费事。通过利用屏幕效果，我们就可以整个的调整屏幕的最终效果，因此对于有些最终呈现我们能获得更强的 类Photoshop（Photoshop-like） 的控制。 为了建立起一个屏幕效果系统并且使它成功运行，我们需要准备一个脚本来跟游戏当前的渲染图片进行通信，这个 渲染图片（rendered image） 就是Unity中的 渲染纹理（Render Texture）。利用这个脚本将渲染纹理传给着色器，我们能创建一个灵活的系统来创建屏幕效果。对于我们的第一个屏幕效果，我们将创建一个非常简单的灰度效果，这个效果可以让我们的游戏看起来是黑白的效果。让我们拭目以待。 始前准备 为了构建好我们的屏幕效果系统并且顺利运行，我们需要为当前的Unity工程创建一些资产。为了获得这些，跟着下面的步骤走就对了： 1.在当前的项目中，我们创建一个名为 TestRenderImage.cs 的脚本。 2.创建一个新的着色器，命名为 ImageEffect.shader。 3.在场景中新建一个球体并且为其添加一个新的材质球，新材质可以任意，比如我们创建了一个简单的红色的，带有高光的材质球。 4.最后，创建一个新的方向光，然后保存场景。 当我们把所有的资源准备好后，就等于是简单的设置好了场景，看起来就跟下图一样： 操作步骤 为了让我们灰度屏幕效果能运行，我们需要一个脚本和着色器。我们将会在这里完成这新的两项并且给它们添加合适的代码从而生成我们的第一个屏幕效果。我们的首个任务就是完成C#脚本。这样可以让我们的整个系统跑起。在这之后，我们将会完成着色器的编写并且看到我们的屏幕效果。让我们通过下面的步骤完成我们的脚本和着色器： 1.打开 TestRenderImage.cs 这个脚本并且添加一些变量好让我们能保存导入的游戏对象和数据。在 TestRenderImage 这个类的最上面添加下面的代码： public class TestRenderImage : MonoBehaviour{ #region Variables public Shader curShader; public float grayScaleAmount = 1.0f; public Material curMaterial; #endregion #region Properties} 2.当Unity编辑器没有运行的时候，为了让我们能够实时的编辑屏幕效果，我们需要在 TestRenderImage 类的声明上面添加下面这行代码： 3.因为我们的屏幕效果是使用一个着色器在一个屏幕图像上进行逐像素操作，所以我们必须要创建一个材质来运行这个着色器。没有这个材质，我们就没有办法访问着色器的属性。因此，我们将创建一个C#的属性来检测材质，如果没有找到这个材质就创建一个。在第一个步骤的变量声明的下面输入下面的代码： #region PropertiesMaterial material{ get { if (curMaterial == null) { curMaterial = new Material(CurShader); curMaterial.hideFlags = HideFlags.HideAndDontSave; } return curMaterial; }}#endregion 4.现在我们想在脚本中设置一些检测来看看当前我们build的Unity游戏在平台上是否支持图像效果。如果在脚本开始运行的时候发现不支持，这个脚本将会被禁用掉： private void Start(){ if (!SystemInfo.supportsImageEffects) { enabled = false; return; } if (curShader &amp;&amp; !curShader.isSupported) { enabled = false; }} 事实上 SystemInfo.supportsImageEffects 在较新的Unity版本中，是一直返回 true 的，这个属性已经被废弃掉了【译者述】 5.为了能够从Unity的渲染器中抓取 渲染图像（Rendered Image），我们需要利用下面这个Unity内建的 OnRenderImage() 方法。请输入下面的代码以便于我们能访问当前的 渲染纹理（Render Texture）： private void OnRenderImage(RenderTexture src, RenderTexture dest){ if (curShader != null) { material.SetFloat(\"_LuminosityAmount\", grayScaleAmount); Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }} 6.我们的屏幕效果有一个叫 grayScaleAmount 的变量，它可以控制我们想要的灰度屏幕效果的程度。所以，在这里我们需要控制它的取值范围是[0 - 1]，0表示没有灰度效果，1表示满程度的灰度效果。我们将会在 Update() 方法中进行这个操作，这意味着当脚本运行的时候会在游戏的每一帧去设置它们： private void Update(){ grayScaleAmount = Mathf.Clamp(grayScaleAmount, 0.0f, 1.0f);} 7.最后，当脚本运行的时候，对于我们创建的这些对象我们需要对它们进行一些清理，这样这个脚本就完成了： private void OnDisable(){ if (curMaterial) { DestroyImmediate(curMaterial); }} 这个时候，如果编译通过后，我们可以将脚本挂在到我们的摄像机中去了。让我们把 TestRenderImage.cs 这个脚本挂载到我们场景中的主摄像机上。你可以在编辑器上看到 grayScaleAmount 这个值和一个着色器的域，但这个脚本会在控制台窗口抛出一个错误。说它丢失了一个对象实例并且有可能会运行不正常。如果你回顾第四个步骤的话，可以看到我们做了一些检测来确定我们是否有着色器和当前的平台是否支持该着色器。我们还没有给这个屏幕效果脚本一个着色器让它能正常的工作，所以 curShader 变量是空的，所以抛出了这个错误。所以让我们继续完成着色器来完善我们的屏幕效果系统吧。 8.开始着手编写我们的着色器了，我们将会修改着色器的属性块，添加一些属性，好让我们能给这个着色器发送一些数据： Properties{ _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _LuminosityAmount (\"GrayScale Amount\", Range(0.0, 1)) = 1.0} 9.现在我们的着色器将使用纯CG着色器代码编写，而不是使用Unity内建的 表面着色器（Surface Shader） 代码。因为这样我们的屏幕效果可以得到更好的优化，因为这里我们仅仅是需要处理 渲染纹理（Render Texture） 的像素而已。所以我们将在着色器中创建一个新的 通道块（Pass block） 并且添加一些我们之前没有看过的 #pragma 声明： Pass{ CGPROGRAM #pragma vertex vert_img #pragma fragment frag #pragma fragmentoption ARB_precision_hint_fastest #include \"UnityCG.cginc\" 10.为了能够访问从Unity编辑器发送到着色器的数据，我们需要在 CGPROGRAM 中创建对应的变量： uniform sampler2D _MainTex;fixed _LuminosityAmount; 11.最后，就剩下去设置我们的 像素函数（pixel function） 了，在这个例子中就是 frag() 函数。这也是这个屏幕效果的关键代码。这个函数将会处理 渲染纹理（Render Texture） 的每一个像素并且给我们的 TestRenderImage.cs 脚本中返回一张新的图像： fixed4 frag(v2f_img i) : COLOR{ fixed4 renderTex = tex2D(_MainTex, i.uv); float luminosity = 0.299 * renderTex.r + 0.587 * renderTex.g + 0.114 * renderTex.b; fixed4 finalColor = lerp(renderTex, luminosity, _LuminosityAmount); return finalColor;} 【为了防止大家跟我一样，看的一头雾水，我在这里贴一下完整的着色器代码】： Shader \"Custom/ImageEffect\"{Properties{ _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _LuminosityAmount (\"GrayScale Amount\", Range(0.0, 1)) = 1.0}SubShader{ Tags { \"RenderType\"=\"Opaque\" } LOD 200 Pass { CGPROGRAM #pragma vertex vert_img #pragma fragment frag #pragma fragmentoption ARB_precision_hint_fastest #include \"UnityCG.cginc\" uniform sampler2D _MainTex; fixed _LuminosityAmount; fixed4 frag(v2f_img i) : COLOR { fixed4 renderTex = tex2D(_MainTex, i.uv); float luminosity = 0.299 * renderTex.r + 0.587 * renderTex.g + 0.114 * renderTex.b; fixed4 finalColor = lerp(renderTex, luminosity, _LuminosityAmount); return finalColor; } ENDCG }}FallBack \"Diffuse\"} 当完成我们的着色器之后，返回到Unity编辑器让它编译着色器并且看看有没有遇到任何的错误。如果没有，就将这个新的着色器拖拽并且赋值给 TestRenderImage.cs 脚本，并且修改脚本上面的灰度变量的值。你应该可以在游戏窗口中看到游戏从有颜色变为灰色。下面的图片演示了这个屏幕效果： 当完成了这些之后，我们就有了一个非常方便的途径去测试新的屏幕效果着色器，这样就不用反复的去编写 屏幕效果系统（Screen Effect system） 的代码了。接下来让我们更深入的去了解一下在 渲染纹理（Render Texture） 中都发生了什么，并且在整个过程中是如何处理它的。 原理介绍 为了完成我们的屏幕效果并且在Unity中能运行起来，我们需要创建一个脚本和一个着色器。这个脚本在Unity的编辑器上会实时刷新，它也负责从从主摄像机中捕获 渲染纹理（Render Texture） 并且把它传到着色器中。一旦这个渲染纹理到达着色器，我们就可以使用这个着色器进行逐像素操作。 在脚本的开始运行的时候，我们进行了一些检测，这样是为了确保我们当前选择build的平台是否支持屏幕效果，是否支持我们的着色器。它们是当前平台是否支持屏幕效果和是否支持我们使用的着色器的实例。所以检查一下我们在 Start() 方法中所做的事情，确保如果当前平台不支持屏幕效果的时候不会有任何的报错。 当我们的游戏脚本通过了检测之后，我们就通过调用Unity内建的 OnRenderImage() 方法来初始化屏幕效果系统。这个方法负责抓取渲染纹理，并且通过调用 Graphics.Blit() 方法将它传给着色器，并且将处理好的图像返回给Unity的渲染器。你可以通过下面的两个链接找到这两个方法更详细的信息： OnRenderImage： https://docs.unity3d.com/ScriptReference/MonoBehaviour.OnRenderImage.html Graphics.Blit: https://docs.unity3d.com/ScriptReference/Graphics.Blit.html 一旦当前的渲染纹理到达着色器后，着色器就通过 frag() 函数处理获取到的纹理，并且返回每一个像素最终颜色。 可以看到这很强大，对于游戏的最终渲染图像，它能给我们类似于Photoshop这种工具一样控制。这些屏幕效果就像Photoshop中的层级概念一样在摄像机中按次序的工作。当你把这些屏幕效果依次前后叠好，它们就会按照排列顺序处理。这些仅仅是屏幕效果工作过程的一个大致步骤，但也是屏幕效果系统如何工作的核心。 额外内容 现在我们完成了一个简单的屏幕效果系统并且能够运行，让我们来了解一下我们能从Unity的渲染器中获得的一些其他的有用的信息： 我们可以通过打开Unity内建的深度模式来让当前游戏中的所有物体都有深度效果。一旦深度效果打开，我们就可以为很多不同的效果使用深度信息。让我们来了解一下这是怎么实现的： 1.创建一个名为 SceneDepth_Effect 的着色器。然后双击打开编辑。 2.我们将会创建两个属性，主纹理属性和深度控制属性。深度控制属性用来控制场景深度的程度。在你的着色器中输入下面的代码： Properties{ _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _DepthPower (\"Depth Power\", Range(1, 5)) = 1} 3.接下来我们要在 CGPROGRAM 块中添加相应的变量。我们将添加一个叫 _CameraDepthTexture 的额外变量。这是Unity通过UnityCG cginclude 文件提供给我们的一个内建的变量。它提供了来自摄像机的深度信息： Pass{ CGPROGRAM #pragma vertex vert_img #pragma fragment frag #pragma fragmentoption ARB_precision_hint_fastest #include \"UnityCG.cginc\" uniform sampler2D _MainTex; fixed _DepthPower; sampler2D _CameraDepthTexture; 4.我们将使用Unity提供的几个内建的函数来完成我们的 深度着色器（depth shader），一个是 UNITY_SAMPLE_DEPTH()，另一个是 linear01Depth()。第一个函数从变量 _CameraDepthTexture 中获得深度信息并且为每一个像素生成一个单精度浮点值。Linear01Depth() 函数确保这个单精度浮点值能控制在 [0 - 1]范围内，因为这个值要作为指数，因为在场景内[0 - 1]之间的值能确保它的位置在摄像机内【翻译不太准确，有知道的请留言】： fixed4 frag(v2f_img i) : COLOR{ float d = UNITY_SAMPLE_DEPTH(tex2D(_CameraDepthTexture, i.uv.xy)); d = pow(Linear01Depth(d), _DepthPower); return d;} 5.完成我们的着色器之后，让我们把注意力转移到我们的屏幕效果脚本上来。我们需要给脚本添加一个 depthPower 变量，这样我们就可以让用户在编辑器上去修改这个值： #region Variablespublic Shader curShader;public Material curMaterial;public float depthPower = 1.0f;#endregion 6.我们的 OnRenderImage() 方法需要更新一下好让我们能够传递正确的值给着色器： private void OnRenderImage(RenderTexture src, RenderTexture dest){ if (curShader != null) { material.SetFloat(\"_DepthPower\", depthPower); Graphics.Blit(src, dest, material); } else { Graphics.Blit(src, dest); }} 7.要完成我们的屏幕深度效果，我们需要告诉Unity让它在当前的摄像机上打开深度渲染。我们可以通过设置摄像机的 depthTextureMode 属性来达到目的： private void Update(){ Camera.main.depthTextureMode = DepthTextureMode.Depth; depthPower = Mathf.Clamp(depthPower, 0, 5);} 当代码写好后，保存你的脚本和着色器然后返回到Unity编辑器让它们完成编译。如果没有遇到什么错误，你将会看到如下图类似的结果： " }, { "title": "Windows下自动连接openvpn的powershell脚本", "url": "/game-tech-post-old/posts/windows%E4%B8%8B%E8%87%AA%E5%8A%A8%E8%BF%9E%E6%8E%A5openvpn%E7%9A%84powershell%E8%84%9A%E6%9C%AC/", "categories": "openvpn", "tags": "powershell, openvpn, windows11, 自动连接, ovpn文件, 指定目录", "date": "2023-03-28 00:00:00 +0800", "snippet": "windows下的openvpn自动连接powershell脚本，自动尝试指定目录下的所有.ovpn文件powershell的脚本如下所示：$ovpn_dir = \"D:\\MyProject\\mybat\\vpnconf\"$auth_file = \"D:\\MyProject\\mybat\\auth.txt\"$log_file = \"D:\\MyProject\\mybat\\temp.log\"fore...", "content": "windows下的openvpn自动连接powershell脚本，自动尝试指定目录下的所有.ovpn文件powershell的脚本如下所示：$ovpn_dir = \"D:\\MyProject\\mybat\\vpnconf\"$auth_file = \"D:\\MyProject\\mybat\\auth.txt\"$log_file = \"D:\\MyProject\\mybat\\temp.log\"foreach ($ovpn_file in Get-ChildItem -Path $ovpn_dir -Filter *.ovpn) { Write-Host \"Trying $($ovpn_file.Name)\" Remove-Item $log_file -ErrorAction SilentlyContinue $process = Start-Process -FilePath \"C:\\Program Files\\OpenVPN\\bin\\openvpn.exe\" -ArgumentList \"--config $ovpn_file --auth-user-pass $auth_file\" -NoNewWindow -PassThru -RedirectStandardOutput $log_file $connected = $false while (!$process.HasExited) { $content = Get-Content $log_file if ($content -match \"Initialization Sequence Completed\") { $connected = $true Write-Host \"Connected successfully!\" break } Start-Sleep -Milliseconds 1000 } if ($connected) { $inputStr = Read-Host \"Type 'stop' to terminate the program\" if ($inputStr.Equals(\"stop\")) { $killProcess = Get-Process -Name *openvpn* if ($killProcess) { Stop-Process -Name \"openvpn\" -Force } break } } if (!$connected) { Write-Host \"Configurations failed\" $killProcess = Get-Process -Name *openvpn* if ($killProcess) { Stop-Process -Name \"openvpn\" -Force } Start-Sleep -Seconds 5 }} $ovpn_dir是你自己的配置文件目录，把所有的 .ovpn 文件放到该目录下面。 $auth_file是你的账户信息，里面有两行，第一行是你的用户名，第二行是你的密码。格式大概如下面一样，记得把your_name，your_password整个替换成你的用户名和密码。 your_nameyour_password $log_file是openvpn的日志输出文件，控制台会读取这个文件，然后比对字符串，看看是否已经成功连接。openvpn的参数： --config 指定配置文件位置。 --auth-user-pass 指定用户和密码文件 --connect-timeout 10 指定timeout时间，这里表示10秒没有连上就timeout --connect-retry-max 3 指定最多尝试次数，这里尝试3次如果失败就会退出程序" }, { "title": "Linux下自动连接openvpn的bash", "url": "/game-tech-post-old/posts/linux%E4%B8%8B%E8%87%AA%E5%8A%A8%E8%BF%9E%E6%8E%A5openvpn%E7%9A%84bash/", "categories": "openvpn", "tags": "Ubuntu, openvpn, linux, 自动连接, ovpn文件, 指定目录", "date": "2023-03-28 00:00:00 +0800", "snippet": "Linux下的openvpn自动连接bash，自动尝试指定目录下的所有.ovpn文件脚本如下所示：#!/usr/bin/env bash# 存放所有ovpn文件的目录ovpn_dir=\"/media/link/D/config/vpn/config/\"# 存放用户认证信息的文件auth_file=\"/media/link/D/config/vpn/auth.txt\"# 存放临时日志的文件lo...", "content": "Linux下的openvpn自动连接bash，自动尝试指定目录下的所有.ovpn文件脚本如下所示：#!/usr/bin/env bash# 存放所有ovpn文件的目录ovpn_dir=\"/media/link/D/config/vpn/config/\"# 存放用户认证信息的文件auth_file=\"/media/link/D/config/vpn/auth.txt\"# 存放临时日志的文件log_file=\"/media/link/D/config/vpn/temp.log\"process_name=openvpn# 遍历ovpn目录下的所有ovpn文件for file in ${ovpn_dir}/*.ovpn; do echo \"Trying ${file}...\" # 删除旧的日志文件并创建新的 rm -f ${log_file} &amp;&amp; touch ${log_file} # 连接VPN并将所有日志重定向到临时日志文件 sudo openvpn --config ${file} --auth-user-pass ${auth_file} --connect-timeout 10 --connect-retry-max 3 &gt; ${log_file} &amp; while true ; do for line in $(cat ${log_file});do if echo \"${line}\" | grep -q \"Initialization Sequence Completed\"; then echo \"connect success!\" while true; do read -p \"Input 'stop' to exit\" input if [ \"${input}\" == \"stop\" ]; then echo \"Exiting...\" exit 0 fi done fi done sleep 0.2 process_id=$(pidof openvpn) if [[ -z $process_id ]]; then echo \"openvpn exited! try next config!\" break fi done # 如果连VPN接失败，则提示connect fail! echo \"connect fail!\"done这个教程使用的openvpn这个客户端，如果没有这个命令，请先安装openvpn，openvpn的安装方法，请去网上查找。" }, { "title": "针对移动设备修改着色器", "url": "/game-tech-post-old/posts/%E9%92%88%E5%AF%B9%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E4%BF%AE%E6%94%B9%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-03-26 00:00:00 +0800", "snippet": "针对移动设备修改着色器我们在优化着色器这方面已经了解了较多的技术了，现在让我们来了解如何为移动设备编写高效，高质量的着色器代码。对于我们已经写好的着色器代码，通过一些小的修改让他们能在移动设备上高速运行好事比较简单的。这里包含了使用 approxview 或者 halfasview 光照函数变量等知识内容。我们可以减少所需的纹理数量并且对所用的纹理使用更好的压缩方式。这个知识点的最后，对于移...", "content": "针对移动设备修改着色器我们在优化着色器这方面已经了解了较多的技术了，现在让我们来了解如何为移动设备编写高效，高质量的着色器代码。对于我们已经写好的着色器代码，通过一些小的修改让他们能在移动设备上高速运行好事比较简单的。这里包含了使用 approxview 或者 halfasview 光照函数变量等知识内容。我们可以减少所需的纹理数量并且对所用的纹理使用更好的压缩方式。这个知识点的最后，对于移动游戏，我们将会有一个优化很好的法线贴图，高光着色器。 始前准备 在开始前，我们先创建一个新的场景并且创建一些游戏对象用来使用我们的着色器： 创建一个新的场景并且添加一个默认球体和一个方向光。 创建一个新的材质球和着色器，并且把着色器应用到材质。 最后把材质应用到场景中的球体上。 当完成上面的步骤后，你的场景看起来大概更下图差不多： 操作步骤 在这个知识点中，我们会反复斟酌着色器中各种元素从而编写一个对移动平台友好着色器： 1.首先根据所需的纹理修改着色器的 属性块（Properties block）。在这个例子中，我们会使用一个alpha通道带有光滑纹理漫反射纹理，一张法线贴图，一个控制高光强度的滑动条。 Properties{ _Diffuse (\"Base (RGB) Specular Amount (A)\", 2D) = \"white\" {} _SpecIntensity (\"Specular Width\", Range(0.01, 1)) = 0.5 _NormalMap (\"Normal Map\", 2D) = \"bump\" {}} 2.下一个任务是设置 #pragma 申明。这些声明会打开或者关闭 表面着色器（Surface Shader） 的一些具体特性，并且最终影响着色器的性能消耗，是高成本还是低成本。 CGPROGRAM#pragma surface surf MobileBlinnPhong exclude_path:prepass nolightmap noforwardadd halfasview 3.接着我们在 CGPROGRAM 中定义与 属性块（Properties block） 中对应的变量。这次对于高光强度这个滑动条，我们将使用 fixed 类型的变量，从而减少着色器的内存使用： sampler2D _Diffuse;sampler2D _NormalMap;fixed _SpecIntensity; 4.为了能将我们的纹理映射到游戏对象的表面，我们需要获取相应的UV。这个例子里，为了让着色器数据保持最小，我们将仅使用一个UV设置： struct Input{ half2 uv_Diffuse;}; 5.这一步是要完成我们的光照函数，由于在 #pragma 声明中有了一些新的变量，所以这里我们就可以使用它们： inline fixed4 LightingMobileBlinnPhong(SurfaceOutput s, fixed3 lightDir, fixed3 halfDir, fixed atten){ fixed diff = max(0, dot(s.Normal, lightDir)); fixed nh = max(0, dot(s.Normal, halfDir)); fixed spec = pow(nh, s.Specular*128) * s.Gloss; fixed4 c; c.rgb = (s.Albedo * _LightColor0.rgb * diff + _LightColor0.rgb * spec) * (atten * 2); c.a = 0.0; return c;} 6.最后，我们需要创建 surf() 函数并且处理表面的最终颜色： void surf (Input IN, inout SurfaceOutput o){ // Albedo comes from a texture tinted by color fixed4 diffuseTex = tex2D(_Diffuse, IN.uv_Diffuse); o.Albedo = diffuseTex.rgb; o.Gloss = diffuseTex.a; o.Alpha = 0.0; o.Specular = _SpecIntensity; o.Normal = UnpackNormal(tex2D(_NormalMap, IN.uv_Diffuse));} 当完成上面的步骤后，我们完成了这个知识点的部分代码，保存你的着色器代码并且返回Unity编辑等待着色器编译完。如果没有遇到什么错误，你会获得一个类似下图的结果： 原理介绍 所以，让我们开始介绍这个着色器吧，看看它做了什么和没做什么。首先，它排除了后光线通道。也就是说如果你创建了一个连接 后渲染前通道（deferred renderer’s prepass） 的光线函数，那么它将不会使用那个特定的光线函数并且会去寻找默认的光线函数，比如我们这本书目前为止创建的那些默认的光线函数一样。 这个特定的着色器并不受Unity内部的光照贴图系统的光照映射支持。这样的话对于使用了这个着色器的游戏对象来说，可以防止着色器试图去寻找法线贴图，从而可以让着色器有更好的性能表现，因为它不用再执行光线映射检测了。 我们添加了 noforwardadd 声明，这样的话通过单个的方向光我们只要处理逐像素纹理即可。所有其他类型的光将会强制变成逐顶点光并且不会被在 surf() 函数中的任何逐像素操作所涉及。 最后，我们使用 halfasview 声明告诉Unity，我们将不会使用普通光线函数中的 viewDir 参数。取而代之的是，我们将使用 半向量（half vector） 作为视野方向并且处理我们的高光。这样的话着色器的处理将会快很多，因为它是基于逐顶点操作来完成的。当用这个着色器来模拟真实世界中的高光时，其实它并不够精确，但是对于移动设备中的视效来说，它看起来已经很不错了并且着色器也优化的更好。 这些技术可以让着色器更加高效和简洁【codewise 我不知道怎么翻译】。按照游戏的要求，根据你的游戏硬件和视觉质量要求来衡量你到底需要那些数据，最好确保只使用你需要的数据。最后，这些技术最终组成了游戏使用的那些着色器。" }, { "title": "着色器的性能分析", "url": "/game-tech-post-old/posts/%E7%9D%80%E8%89%B2%E5%99%A8%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-03-23 00:00:00 +0800", "snippet": "着色器的性能分析我们现在知道该如何减少色器可能出现的内存消耗，让我们来了解一下在场景中，如何在大量同时运行的游戏对象，着色器和脚本等包含的大量着色器中，找出有问题的着色器。要在整个游戏中去找到某一个单独的游戏对象或者着色器可能会让人有点望而却步，但是Unity给我们提供了它内建的性能分析工具。它可以让我们知道在游戏中每一帧都发生了什么，CPU和GPU资源使用情况。 通过使用性能分析工具，我们...", "content": "着色器的性能分析我们现在知道该如何减少色器可能出现的内存消耗，让我们来了解一下在场景中，如何在大量同时运行的游戏对象，着色器和脚本等包含的大量着色器中，找出有问题的着色器。要在整个游戏中去找到某一个单独的游戏对象或者着色器可能会让人有点望而却步，但是Unity给我们提供了它内建的性能分析工具。它可以让我们知道在游戏中每一帧都发生了什么，CPU和GPU资源使用情况。 通过使用性能分析工具，我们可以使用其界面创建分析作业块，来单独分析诸如着色器、几何图新和一些一般渲染项。我们可以筛选出我们要寻找的影响性能的单个游戏对象。这让我们能够在运行时观察对象执行其功能时对 CPU和GPU的影响。 让我们来看看性能分析工具的不同部分和并且学习如何调试我们的场景，当然更重要的是如何调试我们的着色器。 始前准备 为了使用性能分析器，我们要准备好一些资源并且打开我们的性能分析窗口： 1.我们就使用介绍上一个知识点时的场景，然后通过菜单 Window | Profiler 或 Ctrl + 7 打开性能分析窗口。 2.我们多复制几个球体，看看这样会对渲染有什么影响。 你会看到跟下图类似的一些东西： 操作步骤 使用性能分析工具的时候，你会在该窗口看到一些UI元素。在我们点击运行按钮前，让我们了解一下该如何从性能分析器中获取我们想要的信息： 1.首先，点击 Profiler 窗口中的 GPU Usage，CPU Usage 和 Rendering这几栏。你可以在窗口的左上角找到这几栏： 使用这几栏，我们可以看到跟游戏主要功能相关的不同的数据。CPU Usage 给我们展示的是我们大部分脚本在干什么，当然还有物理运算和总体渲染。GPU Usage 这一栏给我们的是光照，阴影和渲染队列等的详情信息。最后，Rendering 这一栏有每一帧中 drawcall 和游戏场景中集合体的数量这些信息。 点击其中的一栏，我们就可以把在 性能会话（profiling session） 中看到的数据类型单独分离出来分析。 2.现在，我们可以点击性能分析栏中的小颜色块然后点击编辑器的运行按钮或者用 Ctrl + P 快捷键运行场景。 这样选择性的查看，可以让我们更加深入的分析性能会话，因为这样我们可以选择我们想分析的内容。当场景运行的时候，再GPU使用（GPU Usage） 栏中取消其他所有的颜色小块的勾选，然后留下 Opaque 这一勾选。请注意这样我们就可以知道 Opaque 渲染队列中的游戏对象再渲染中花了多长时间了： 3.性能分析窗口中另一个非常好用的功能是可以在图形窗口中进行的拖拽操作。这个操作会自动暂停你的游戏，这样你就可以更细致的分析图形中某一个具体的波峰从而找出引起性能问题的具体项了。你可以在图形区域内点击或者拖拽移动来暂停游戏，从而了解这一功能的具体效果： 4.现在让我们把目光聚焦到性能分析窗口的下半部分，你会发现当我们选中GPU那一栏的时候这里会有一个下拉选择框。我们可以把它展开从而获得更多当前激活的性能会话中的详细信息，这种情况下我们可以知道有关于当前摄像机渲染情况和花费时间的更多信息： 它能让我们全面了解Unity在某一帧中内部工作都在处理什么。在这个例子中，我们能看到场景中的球体和我们优化过的着色器在绘制到屏幕上花了大概0.14毫秒，花了7个drawcall，并且这个处理每帧花费了大概3.1%的GPU时间。通过这些类型的信息我们可以去诊断和解决跟着色器性能相关的问题。让我们准备一个测试，看看如果我们给着色器添加一个额外的纹理并且用 lerp 函数把两张漫反射纹理混合到一块会造成什么样的影响。你将会在在性能分析器中看到清晰的影响。 5.修改着色器的 属性块（Properties block），然后添加下面的代码，这样就可以为我们的着色器添加另一个纹理了： Properties { _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} NormalMap (\"Normal Map\", 2D) = \"bump\" {} _BlendTex (\"Blend Texture\", 2d) = \"white\" {} } 6.然后在 CGPROGRAM 中添加一个变量用来使用这个纹理： CGPROGRAM#pragma surface surf SimpleLambert exclude_path:prepass noforwardaddsampler2D _MainTex;sampler2D _NormalMap;sampler2D _BlendTex; 7.相应的我们也要去修改一下我们的 surf() 函数以便我们能将纹理和漫反射纹理混合到一块： void surf (Input IN, inout SurfaceOutput o){ // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex); fixed4 blendTex = tex2D(_BlendTex, IN.uv_MainTex); c = lerp(c, blendTex, blendTex.r); o.Albedo = c.rgb; o.Alpha = c.a; o.Normal = UnpackNormal(tex2D(_NormalMap, IN.uv_MainTex));} 当你保存了你着色器的修改并且回到Unity编辑器后，你就可以运行我们的游戏并且看看我们的着色器增加的时间消耗。回到Unity后点击运行按钮并且在性能分析器窗口查看结果： 你可以看到场景中我们着色器渲染 Opaque 队列的时间消耗数量从 0.140 毫秒增加到了 0.179 毫秒。从添加了另一张额外的纹理后和使用了 lerp() 函数后，我们的球体的渲染时间增加了。当然这个变化非常的小，但是想象一下如果有20个着色器用不同的工作方式在不同的游戏对象上，那消耗就多了。 利用这里给出的这些信息，你可以更快的精确的定位到引起性能下降的原因并且用上一个知识点介绍的技术解决它们。 原理介绍 描述这个工具内部是如何工作已经完全超出了这本书的范畴，我们可以推测Unity已经给了我们方法观察当游戏运行的时候电脑的运行表现是什么样子。通常来说，这个窗口跟CPU和GPU紧密相关并且实时反馈给我们关于我们的每一个脚本，游戏对象和渲染队列所占用的时间。使用这些信息，我们就可以追踪我们着色器的编写效率从而消除有问题的区域和代码。 额外内容 也可以专门对移动平台进行性能分析。如果build目标平台在 Build Settings 中设置成了Android和IOS，Unity还会给我们提供一系列额外的特性。当游戏运行的时候我们能从移动设备中实时获取信息。这变得非常的有用，因为你可以直接在移动设备上进行性能分析而不是在编辑器上。如果想了解更多关于这个过程的信息，可以参考下面链接中的Unity文档【作者提供的地址已经失效，下面是新的】： https://docs.unity3d.com/Manual/profiler-profiling-applications.html" }, { "title": "移动设备着色器适配", "url": "/game-tech-post-old/posts/%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E7%9D%80%E8%89%B2%E5%99%A8%E9%80%82%E9%85%8D/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-02-26 00:00:00 +0800", "snippet": "第七章 移动设备着色器适配在接下来的两章，我们将着手于让我们写的着色器对不同的平台都有较好的性能表现。我们不会讨论任何一个特殊的平台，我们将会分解着色器内的元素，这样的话我们就可以对它们进行调整，从而让它们对于移动平台有更好的优化并且通常来说对其他任何平台来说也更高效。这些技术涵盖了从 了解Unity提供的一些可以减少着色器内存溢出方面的内建变量 到 学习可以让我们的着色器代码更加高效的方法...", "content": "第七章 移动设备着色器适配在接下来的两章，我们将着手于让我们写的着色器对不同的平台都有较好的性能表现。我们不会讨论任何一个特殊的平台，我们将会分解着色器内的元素，这样的话我们就可以对它们进行调整，从而让它们对于移动平台有更好的优化并且通常来说对其他任何平台来说也更高效。这些技术涵盖了从 了解Unity提供的一些可以减少着色器内存溢出方面的内建变量 到 学习可以让我们的着色器代码更加高效的方法。这一章将会包含下面的这些知识点： 什么是低成本着色器 着色器的性能分析 针对移动设备修改着色器介绍学习如何优化着色器的艺术将会出现在你参与的任何游戏项目中。在任何产品中总有需要优化着色器的时候，或者需要用更少的纹理来产生相同的效果。作为一个技术美术或者着色器编程人员，你必须要理解这些核心的基本原理来优化你的着色器代码从而让你的游戏在提升性能表现的同时又能达到相同的视觉表现。有了这些知识也可以为你自己开始写着色器代码进行铺垫。比如，你知道使用你着色器的游戏将会运行在移动设备中，我们可以自动的设置所有的光照函数使用 half vector 作为视野方向，或者把所有的 浮点型变量类型(float variable types) 都设置成 fixed 类型 或 half 类型。前面提到的这些技术或者很多的其他技术，都可以让你的着色器在目标硬件上更加高效的运行。开始我们的着色器优化学习之旅吧。什么是低成本着色器我们首先问一个问题，什么是低成本的着色器，它回答起来可能有点困难因为有太多的元素可以可以让一个着色器变得更加高效了。它可以是你的变量使用的内存的大小。可以是你的着色器使用的纹理的大小。也可是一个工作良好的着色器，但是我们却只使用了相较之前一半的代码或者数据就获得了相同的视觉效果。我们将会在这个知识点中探索一些这样的技术并且会展示如何将这些技术结合起来从而让你的着色器更快更高效，并且不管是在移动设备还是在PC上都生成当今游戏中每个人都期望的高质量的视觉效果。 始前准备 在开始这个知识点之前，我们需要准备一些资源并且把它们放一块。所以让我们按照下面的几个任务来： 1.创建一个新的场景，并且在场景中添加一个球体和一个方向光。 2.创建一个新的着色器和材质球，并且把着色器应用到材质上。 3.然后把材质球应用到我们刚刚创建的球体。 4.最后，我们修改我们之前创建的着色器让它能使用漫反射纹理和法线贴图，并且创建一个自定义的光线函数。下面的代码展示的是修改后的着色器代码： Shader \"Custom/MSA\"{ Properties { _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _NormalMap (\"Normal Map\", 2D) = \"bump\" {} } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM sampler2D _MainTex; sampler2D _NormalMap; #pragma surface surf SimpleLambert struct Input { float2 uv_MainTex; float2 uv_NormalMap; }; inline float4 LightingSimpleLambert(SurfaceOutput s, float3 lightDir, float atten) { float diff = max(0, dot(s.Normal, lightDir)); float4 c; c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten * 2); c.a = s.Alpha; return c; } void surf (Input IN, inout SurfaceOutput o) { // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; o.Normal = UnpackNormal(tex2D(_NormalMap, IN.uv_NormalMap)); } ENDCG } FallBack \"Diffuse\"} 现在你应该有如下图所示的一个设置。下面的这个设置将让我们初步了解一些在Unity中使用表面着色器进行优化的基本概念： 操作步骤 我们将构建一个简单的漫反射着色器用来了解几种常用的优化着色器的方法。 首先，我们将会优化变量类型从而可以让它们在处理数据的时候使用更少的内存： 让我们从着色器的 输入结构体(struct Input) 着手。当前我们的UV数据是保存在一个 float2 类型的变量中的。我们需要将它改成 half2 struct Input{ half2 uv_MainTex; half2 uv_NormalMap;}; 接下来我们去修改光照函数，通过如下的变量类型的修改从而减少了变量的内存占用： inline fixed4 LightingSimpleLambert(SurfaceOutput s, fixed3 lightDir, fixed atten){ fixed diff = max(0, dot(s.Normal, lightDir)); fixed4 c; c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten * 2); c.a = s.Alpha; return c;} 最后，我们来修改 surf() 函数中的变量类型，这样就完成了这次的优化。代码如下所示： void surf (Input IN, inout SurfaceOutput o){ // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; o.Normal = UnpackNormal(tex2D(_NormalMap, IN.uv_NormalMap));} 现在我们优化了我们的变量，接下来我们将利用Unity内建的 光线函数变量（lighting function variable），这样我们就可以控制光线该如何被着色器处理。通过这样做，我们极大的减少着色器需要处理的光线数量。按照下面的代码修改着色器中的 #pragma 声明： #pragma surface surf SimpleLambert noforwardadd 我们之后还会通过让法线贴图和漫反射纹理共享UV来继续优化着色器。为了这个优化，我们简单的通过在 UnpackNormal() 函数中用 _MainTex 的UV替换掉 _NormalMap 的UV，从而修改着色器的 UV查找（UV lookup）： void surf (Input IN, inout SurfaceOutput o){ // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; o.Normal = UnpackNormal(tex2D(_NormalMap, IN.uv_MainTex));} 由于我们已经不再需要法线贴图的UV了，所以我们需要确保在 输入结构体（Input struct） 中移除掉跟法线贴图UV相关的代码： struct Input{ half2 uv_MainTex;}; 最后，我们通过告诉着色器只需要工作在一些特定的渲染器中从而进一步优化我们的着色器： #pragma surface surf SimpleLambert exclude_path:prepass noforwardadd 优化的最终结果显示我们几乎注意不到视效质量上的不同，但我们却减少了这个着色器在屏幕上绘制的次数。我们在下一个知识点将会学习如何确定着色器的绘制次数，这里我们关心的是我们通过更少的数据消耗而取得了相同的效果。所以当你在创建自己的着色器的时候也要留意这一点。下图向我们展示了我们的着色器的最终效果： 原理介绍 现在我们了解了一些能优化我们着色器的方法，现在我们更进一步的探索，去了解这些技术为什么会起作用，并且看一看一些其他的你自己可以尝试的技术。 我们留意一下每一个变量，当我们定义它们的时候，保存在它们每一个中的数据的大小。如果你熟悉编程，你应该理解你可以定义不同类型大小的值和变量。也就是说一个浮点类型事实上占用了最大的内存消耗。下面的描述向我们更多的陈述了这些变量的细节： Float：一个浮点类型是一个32位精度的值并且是我们看到的三种数据类型中最慢的。它还有与之对应的其他浮点类型值 float2，float3 和 float4。 Half：half 变量类型是一个缩减了位数的16位浮点值，它适合用来保存UV和颜色值，相比于float类型它要快很多。跟上面的浮点类型类似，half类型也有与之对应的其他类型，它们是 half2，half3，和 half4。 Fixed：fixed 类型是三种类型中大小最小的，但它可以用于光线计算和颜色计算，它也有与之对应其他fixed类型：fixed2，fixed3 和 fixed4。 在优化我们的简单着色器的第二个阶段中，我们在 #pragma 声明中定义了一个 noforwardadd。它是一个基础开关，它会自动告诉Unity任何使用这个特定着色器的游戏对象，只会接收单一方向上的逐像素的光。任何其他被这个着色器计算的光线，都会被强制作为逐顶点光线，被Unity自身生成的球谐值处理。当我们在在场景中放置一个其他类型的光线来照射我们的球体的时候，这一点尤其明显，因为我们的着色器是使用法线贴图做的逐像素操作。 这很棒，但是如果你想要在场景中添加很多的方向光，并且想控制使用它们中的哪一个作为主要的逐像素光会怎样呢？很好，如果你又留意的话，每一个光都有一个 Render Mode 下拉框。如果你点击这个下拉框，你会看到你又好几个选项可以设置。它们分别是 Auto，Important 和 Not Important。你可以选中一个光线，通过设置渲染模式为 Important 来告诉Unity，比起逐顶点光，这个光线更应该考虑作为一个逐像素光，反之亦然。如果光线的渲染模式保持 Auto，那就是让Unity来决定最佳的处理方案。 在你的场景中另外再放置一个光源，并且移除掉着色器当前的主纹理。你将会发现第二个点光源【这里不知道作者的这个点光源什么时候加的，操作步骤里面又没有】对法线贴图没有反应，仅有我们最开始创建的方向光有反应。这里的概念是，通过将其他额外的光作为顶点光来计算从而节省了逐像素操作，通过将主要的方向光作为逐像素光来计算从而节省了性能。下图演示了这个概念，可以看到点光源对法线贴图没有反应： 最后，我们做了一些清理并且简单的让法线贴图纹理使用主纹理的UV数据，我们特地删除了为法线贴图拉取数据部分的代码。这总是让你的代码保持简洁和清理不想要的数据的好方法。 我们还在 #pragma 声明处定义了 exclude_pass: prepass 这样的话这个着色器就不会再接受来自后渲染器的任何自定义光了。这意味着，如果在已经设置好的主摄像机中，我们能在前渲染器中高效的使用这个着色器。 只要花一点时间，你就会被着色器尽然可以如此多的优化而震惊。你已经了解到我们是如何将灰度纹理打包到一个单一的RGB纹理中的以及如何使用查找纹理来伪造照明效果。着色器的优化又很多方法，这就是为什么这是一个一开始问起来就模糊不清的问题，但是如果知道这些不同的优化技术，你就可以根据你的游戏和目标平台来定制你的着色器，最终获得一个简洁流畅的着色器和稳定的游戏帧率。 " }, { "title": "在2d游戏中实现水效果的着色器", "url": "/game-tech-post-old/posts/%E5%9C%A82D%E6%B8%B8%E6%88%8F%E4%B8%AD%E5%AE%9E%E7%8E%B0%E6%B0%B4%E6%95%88%E6%9E%9C%E7%9A%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-02-26 00:00:00 +0800", "snippet": "在2D游戏中实现水效果的着色器上一个知识点介绍的玻璃着色器它的效果是静态的；它的扭曲效果永远都不会改变。只要对着色器稍加修改，就可以将它转换成一个有动画的材质，它非常的适合2D游戏中的水体特效。在这个知识点将会使用 第五章，对表面着色器中的顶点使用动画 中类似的技术： 始前准备 这个知识点基于 使用抓取通道 知识点中描述的顶点和片元着色器，因为它很依赖抓取通道。 1.创...", "content": "在2D游戏中实现水效果的着色器上一个知识点介绍的玻璃着色器它的效果是静态的；它的扭曲效果永远都不会改变。只要对着色器稍加修改，就可以将它转换成一个有动画的材质，它非常的适合2D游戏中的水体特效。在这个知识点将会使用 第五章，对表面着色器中的顶点使用动画 中类似的技术： 始前准备 这个知识点基于 使用抓取通道 知识点中描述的顶点和片元着色器，因为它很依赖抓取通道。 1.创建一个新的抓取通道着色器；你可以自己写一个新的着色器或者使用 使用抓取通道 这个知识点中用到的着色器作为开始。 2.为你的着色器创建一个对应的材质球。 3.将材质球应用到一个平面几何图形中，它将用来表示2D中的水。为了让这个效果起作用，您应该在其后渲染一些东西，以便可以看到类似水的扰动效果。 4.这个知识点需要一张噪音纹理，用来获得伪随机的值。选择一个无缝的噪音纹理很重要，比如由可以铺砌的2D的Perlin噪音生成的噪音纹理，如下图所示的那样。这是为了确保材质应用到一个很大的游戏对象中时，不会看到有任何不连续的割裂感。为了让效果起作用，纹理需要以 Repeat 模式导入。如果你想要让你的水体效果看起来平滑和连续，那么在 导入器(Inspector) 那里要设置成 Bilinear。这样设置能确保纹理能从着色器中正确的被采样： 操作步骤 你可以修改着色器中的代码来创建动画效果。请跟着下面的步骤走： 1.将下面的代码添加到着色器的属性块中： _NoiseTex(\"Noise text\", 2D) = \"white\" {}_Colour (\"Colour\", Color) = (1,1,1,1)_Period (\"Period\", Range(0,50)) = 1_Magnitude (\"Magnitude\", Range(0,0.5)) = 0.05_Scale (\"Scale\", Range(0,10)) = 1 2.并且在次通道中添加与属性对应的变量 sampler2D _NoiseTex;fixed4 _Colour;float _Period;float _Magnitude;float _Scale; 3.为顶点函数定义下面 输出结构体(output structure): struct vertOutput{float4 vertex : POSITION;fixed4 color : COLOR;float2 texcoord : TEXCOORD0;float4 worldPos : TEXCOORD1;float4 uvgrab : TEXCOORD2;}; 4.这个着色器需要知道每个片元在空间上的精确位置。为了实现这一过程，将代码 o.worldPos = mul(unity_ObjectToWorld, i.vertex); 添加到顶点函数中去： vertOutput vert(vertInput i){vertOutput o;o.vertex = UnityObjectToClipPos(i.vertex);o.color = i.color;o.texcoord = i.texcoord;o.worldPos = mul(unity_ObjectToWorld, i.vertex);o.uvgrab = ComputeGrabScreenPos(o.vertex);return o;} 5.使用下面的片元函数: fixed4 frag(vertOutput o): COLOR{float sinT = sin(_Time.w / _Period);float2 distortion = float2(\ttex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(sinT, 0) ).r - 0.5,tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(0, sinT) ).r - 0.5);o.uvgrab.xy += distortion * _Magnitude;fixed4 col = tex2Dproj( _GrabTexture, UNITY_PROJ_COORD(o.uvgrab));return col * _Colour;} 6.完整代码： Shader \"Custom/IWS\"{Properties{ _NoiseTex(\"Noise text\", 2D) = \"white\" {} _Colour (\"Colour\", Color) = (1,1,1,1) _Period (\"Period\", Range(0,50)) = 1 _Magnitude (\"Magnitude\", Range(0,0.5)) = 0.05 _Scale (\"Scale\", Range(0,10)) = 1}SubShader{ Tags { \"Queue\" = \"Transparent\" \"IgnoreProjector\" = \"True\" \"RenderType\" = \"Opaque\" } GrabPass { \"_GrabTexture\" } Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag #include \"UnityCG.cginc\" sampler2D _GrabTexture; sampler2D _NoiseTex; fixed4 _Colour; float _Period; float _Magnitude; float _Scale; struct vertOutput { float4 vertex : POSITION; fixed4 color : COLOR; float2 texcoord : TEXCOORD0; float4 worldPos : TEXCOORD1; float4 uvgrab : TEXCOORD2; }; struct vertInput { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; }; vertOutput vert(vertInput i) { vertOutput o; o.vertex = UnityObjectToClipPos(i.vertex); o.color = i.color; o.texcoord = i.texcoord; o.worldPos = mul(unity_ObjectToWorld, i.vertex); o.uvgrab = ComputeGrabScreenPos(o.vertex); return o; } fixed4 frag(vertOutput o): COLOR { float sinT = sin(_Time.w / _Period); float2 distortion = float2 (\ttex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(sinT, 0) ).r - 0.5, tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(0, sinT) ).r - 0.5 ); o.uvgrab.xy += distortion * _Magnitude; fixed4 col = tex2Dproj( _GrabTexture, UNITY_PROJ_COORD(o.uvgrab)); return col * _Colour; } ENDCG }}} 原理介绍 这个着色器跟 实现一个玻璃效果的着色器 知识点中介绍的着色器很像。主要的区别就是这个着色器它时一个有动画的材质；它的扰动效果不是从法线贴图中生成的，而是通过当前的时间来计算出的一个持续的动画。用来扰动抓取纹理的UV数据的代码似乎有点复杂；让我们来理解它的效果时如何生成的。思路是用一个正弦函数来让水晃动。这个效果需要随着时间变化。为了获得这个效果，着色器产生的扭曲效果依赖于当前的时间，而这个时间可以通过内建的 _Time 变量获得。变量 _Period 决定了正弦函数的周期，意味着水波出现的有多快： float2 distortion = float2(tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(sinT, 0) ).r - 0.5,tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(0, sinT) ).r - 0.5); 这里的代码有一个问题，就是在 X 轴和 Y 轴它们的扰动是一样的；结果就是整个抓取纹理以圆形运动旋转，这看起来一点都不像水了。很显然我们需要为此添加一些随机性。 给着色器添加随即行为的最常用的方式就是添加一张噪音纹理。现在的问题就变成了找到一种方法来对纹理进行一个看似随机的采样。为了避免效果看起来有明显的正弦模式，最好的方法就是在噪声纹理的UV数据中使用正弦波作为偏移量： float sinT = sin(_Time.w / _Period);float2 distortion = float2(\ttex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(sinT, 0) ).r - 0.5,tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(0, sinT) ).r - 0.5); 变量 _Scale 用来决定波的大小。这个方案已经很接近最终版本了，但还是有一些问题——如果水体移动，UV数据也会跟着它动然后你就会看到水波跟着材质动而不是锚定在背景上。为了解决这个问题，我们需要使用当前片元的世界坐标作为UV数据的初始位置： float sinT = sin(_Time.w / _Period);float2 distortion = float2(\ttex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(sinT, 0) ).r - 0.5,tex2D(_NoiseTex, o.worldPos.xy / _Scale + float2(0, sinT) ).r - 0.5);o.uvgrab.xy += distortion * _Magnitude; 这种没有任何明显的移动方向的无缝扭曲效果确实让人看起来心情愉悦。 注意 正如所有的这些特效一样，没有完美的方案。这个知识点向你展示了创建类似水的扭曲的技术，但是我们鼓励你多对它进行试验，直到你找到一个符合你游戏美术风格的效果。 " }, { "title": "实现一个玻璃效果的着色器", "url": "/game-tech-post-old/posts/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%8E%BB%E7%92%83%E6%95%88%E6%9E%9C%E7%9A%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-02-10 00:00:00 +0800", "snippet": "实现一个玻璃效果的着色器玻璃是一个非常复杂的材质；没必要对它刚到惊讶，在第四章，向PBR中添加透明度 这个知识点中，通过行为驱动开发创建测试用例和编写场景（Creating Test Cases and Writing Scenarios for Behavior Driven Development in Symfony） 我们已经创建了一个这样的着色器来模拟它了。然而，透明度没有办法复现...", "content": "实现一个玻璃效果的着色器玻璃是一个非常复杂的材质；没必要对它刚到惊讶，在第四章，向PBR中添加透明度 这个知识点中，通过行为驱动开发创建测试用例和编写场景（Creating Test Cases and Writing Scenarios for Behavior Driven Development in Symfony） 我们已经创建了一个这样的着色器来模拟它了。然而，透明度没有办法复现玻璃的扭曲效果。大部分的玻璃自身是不完美的，所以当我们再看玻璃的时候会有扭曲效果。这个知识点我们将教你如何实现这样的效果。这个效果背后的思路是使用顶点和片元着色器以及抓取通道，然后对抓取纹理做一些修改并应用到它的UV数据中，从而实现扭曲效果。你可以从下面的图中看到效果，使用的是Unity标准资源库 （Unity Standard Assets） 中的玻璃染色纹理： 始前准备 这个知识点的步骤跟前一章中的有点像： 创建一个新的顶点和片元着色器。你可以复制前一个知识点 抓取通道 的着色器作为基础。 创建一个材质，用来承载着色器。 将材质球赋值给一个 quad，也可以是其他的扁平的几何图形，用来模拟玻璃。 然后再这个模拟的玻璃后面放一些其他的游戏物体，好观察扭曲效果。 操作步骤【原书有错，下面是纠正后的步骤和代码】 我们开始编辑顶点和片元着色器： 向着色器的属性快 （ Properties block） 中添加4个属性： Properties{ _MainTex(\"Base (RGB) Trans (A)\", 2D) = \"white\" {} _Colour(\"Colour\", Color) = (1,1,1,1) _BumpMap(\"Noise text\", 2D) = \"bump\" {} _Magnitude(\"Magnitude\", Range(0,1)) = 0.05} 在Pass通道中添加下面的这些变量 sampler2D _MainTex;sampler2D _BumpMap;float _Magnitude;sampler2D _GrabTexture;fixed4 _Colour; 将下面的纹理信息添加到输入和输出结构体中： struct vertInput { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0;};struct vertOutput { float4 vertex : SV_POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; float4 uvgrab : TEXCOORD1; }; 将UV数据从输入结构体赋值到输出结构体中： vertOutput vert(vertInput input) { vertOutput o; o.vertex = UnityObjectToClipPos(input.vertex); o.color = input.color; o.texcoord = input.texcoord; o.uvgrab = ComputeGrabScreenPos(o.vertex); return o;} 使用下面的片元函数： half4 frag(vertOutput i) : COLOR{ half4 mainColour = tex2D(_MainTex, i.texcoord); half4 bump = tex2D(_BumpMap, i.texcoord); half2 distortion = UnpackNormal(bump).rg; i.uvgrab.xy += distortion * _Magnitude; fixed4 col = tex2Dproj(_GrabTexture, UNITY_PROJ_COORD(i.uvgrab)); return col * mainColour * _Colour; } 因为这个材质是透明的，所以我们还需要在它的 SubShader 块中改变它的 标签(tags) Tags{ \"Queue\" = \"Transparent\" \"IgnoreProjector\" = \"True\" \"RenderType\" = \"Opaque\" } 接下的工作就是为玻璃设置纹理和法线贴图从而替换掉抓取纹理。 原理介绍 该着色器的核心作用是使用抓取通道来获取已经被渲染在屏幕上的东西。我们在片元函数中实现了扭曲效果的。在这里法线贴图被解析并且用来计算抓取纹理的UV数据偏移： half4 bump = tex2D(_BumpMap, i.texcoord);half2 distortion = UnpackNormal(bump).rg;i.uvgrab.xy += distortion * _Magnitude; _Magnitude 这个滑动条用来控制效果的强弱。 额外内容 这个效果非常的通用；它可以基于法线贴图，通过抓取屏幕来创建扭曲效果。如果想模拟一些更有趣的效果没理由不使用它。有很多游戏会在爆炸中或者一些科幻设备上使用扭曲效果。这个材质也可以应用到球体中，如果使用不同的法线贴图，它还可以很好的模拟爆炸中的冲击波。" }, { "title": "使用抓取通道", "url": "/game-tech-post-old/posts/%E4%BD%BF%E7%94%A8%E6%8A%93%E5%8F%96%E9%80%9A%E9%81%93/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2023-01-02 00:00:00 +0800", "snippet": "使用抓取通道在第四章，向PBR中添加透明度 这个知识点中，通过行为驱动开发创建测试用例和编写场景（Creating Test Cases and Writing Scenarios for Behavior Driven Development in Symfony），我们了解了材质是如何实现透明的。尽管一个透明材质可以在一个场景之上进行绘制，但是它不能改变在场景之下已经绘制的东西。这也意味...", "content": "使用抓取通道在第四章，向PBR中添加透明度 这个知识点中，通过行为驱动开发创建测试用例和编写场景（Creating Test Cases and Writing Scenarios for Behavior Driven Development in Symfony），我们了解了材质是如何实现透明的。尽管一个透明材质可以在一个场景之上进行绘制，但是它不能改变在场景之下已经绘制的东西。这也意味着那些透明着色器（Transparent Shaders） 不能创建像从玻璃或者水里看到的那些常见的扭曲效果。为了模拟它们，我们需要介绍另一种叫做抓取通道（grab pass） 的技术。这个技术可以让我们获取到目前为止，已经绘制在屏幕上的信息，从而让我们的着色器没有限制的去使用（或者修改）它们。为了学习如何使用抓取通道，我们会创建一个材质球，来抓取它背后的渲染信息并且在屏幕上再次绘制它们。这让人感觉有点荒谬，这个材质用了一系列的操作，显示效果还是跟原来一样【作者的意思可能是在这个例子中，使用了抓取通道和没有使用的着色器，它们的显示效果是一样的】。 始前准备 这个知识点需要下面的一系列操作： 创建一个着色器，之后我们会对它进行初始化。 创建一个材质球，用来使用我们的着色器。 将材质球应用到一块扁平的几何图形上，比如Unity中的quad。然后将它放在某个物体的前面，能挡住你看后面的物体。当我们的着色器完成之后，这个quad将会变得透明。 操作步骤 为了能使用抓取通道，请你按照下面的步骤操作： 删除着色器的 属性快（Properties section）；这个着色器将不会使用里面的任何东西。 在 SubShader 中，添加抓取通道： GrabPass{ } 在添加完抓取通道后，我们将需要添加下面这个额外的通道： Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag #include \"UnityCG.cginc\" sampler2D _GrabTexture; struct vertInput { float4 vertex : POSITION; }; struct vertOutput { float4 vertex : POSITION; float4 uvgrab : TEXCOORD1; }; // Vertex function vertOutput vert(vertInput v) { vertOutput o; o.vertex = UnityObjectToClipPos(v.vertex); o.uvgrab = ComputeGrabScreenPos(o.vertex); return o; } // Fragment function half4 frag(vertOutput i) : COLOR { fixed4 col = tex2Dproj(_GrabTexture, UNITY_PROJ_COORD(i.uvgrab)); return col + half4(0.5,0,0,0); } ENDCG } 原理介绍 这个知识点不仅仅介绍抓取通道同时也会介绍顶点着色器和片元着色器；因此，我们必须要分析着色器的各种细节。 到目前为止，所有的着色器代码都是直接放在 SubShader 中的。这是因为我们前面的着色器只需要一个单独的通道。但我们这次需要两个。第一个就是我们的抓取通道，我们简单的通过 GrabPass{} 定义了它。剩余的代码我们放在了第二个通道中，包含在我们的Pass块中。 着色器中第二个通道在结构上跟我们这一章的第一个知识点中所展示没有什么不同；我们使用顶点函数 vert 来获取顶点的位置，之后我们在片元函数 frag 中给它赋予颜色。不同的地方在于方法 vert 计算了另一个重要的细节：抓取通道的UV数据。下面的代码展示了抓取通道自动创建的一个与之相关的纹理： sampler2D _GrabTexture; 为了对纹理进行采样，我们需要它的UV数据。ComputeGrabScreenPos 函数可以的返回之后要用到的数据，这样我们就能对抓取的纹理进行正确的采样。我们可以在片元着色器中用下面这行代码来完成这个操作： fixed4 col = tex2Dproj(_GrabTexture, UNITY_PROJ_COORD(i.uvgrab)); 这是对纹理进行抓取并且把它应用到屏幕正确的位置的一种标准做法。如果每一步都操作正确，这个着色器会简单的把几何图形后面已经渲染的东西简单的克隆。我们将在接下的知识点中了解到如何使用这个技术来创建水或者玻璃这样的材质。 额外内容 当你每一次使用带有 GrabPass {} 的材质球时，Unity都会把屏幕渲染到一张纹理中。这是一个非常消耗性能的操作并且限制了你在游戏中能使用的抓取通道的数量。Cg语言提供了一个稍微不同的方式： GrabPass {\"TextureName\"} 这行代码不仅可以让你对纹理进行取名，并且它能让所有的抓取通道叫做 TextureName 的材质球共享同一个纹理。这意味着如果你有10个材质，Unity将仅使用一个抓取通道并且让它们共享一个纹理。这个技术的主要问题是它不允许效果的叠加。如果你使用这个技术来创建玻璃，你做不到在玻璃后面再有一块玻璃的效果。 " }, { "title": "片元着色器和抓取通道", "url": "/game-tech-post-old/posts/%E7%89%87%E5%85%83%E7%9D%80%E8%89%B2%E5%99%A8%E5%92%8C%E6%8A%93%E5%8F%96%E9%80%9A%E9%81%93/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-12-03 00:00:00 +0800", "snippet": "第六章 片元着色器和抓取通道到目前为止，我们都在折腾表面着色器（Surface Shaders）。它的设计初衷是简化我们的着色器编码工作，为艺术家提供一个有意义的工具。但是如果想让我们的着色器知识更上一层楼，我们就要前往顶点（Vertex）和片元（Fragment）着色器的知识岛屿冒险啦。在这一章节，我们将会学习下面的一些知识点： 理解顶点和片元着色器 使用抓取通道 实现一个玻璃效果的...", "content": "第六章 片元着色器和抓取通道到目前为止，我们都在折腾表面着色器（Surface Shaders）。它的设计初衷是简化我们的着色器编码工作，为艺术家提供一个有意义的工具。但是如果想让我们的着色器知识更上一层楼，我们就要前往顶点（Vertex）和片元（Fragment）着色器的知识岛屿冒险啦。在这一章节，我们将会学习下面的一些知识点： 理解顶点和片元着色器 使用抓取通道 实现一个玻璃效果的着色器 在2D游戏中实现水效果的着色器介绍跟表面着色器（Surface Shaders）相比，顶点和片元着色器少了一些诸如，光是如何在物体表面反射的物理属性信息。所谓有失必有得，这样的话顶点和片元着色器就没有了物理规则的限制并且特别适合实现非真实的效果。这个章节将集中讲抓取通道的技术，这些技术可以让着色器来模拟形变效果。理解顶点和片元着色器理解顶点和片元着色器最好的方法就是你自己亲自创建一个。在这个知识点我们将展示如何编写一个这样的着色器，该着色器简单的将一张纹理应用到一个模型上并且通过给定的颜色进行乘积运算，效果就如同下图一样： 这里展示的着色器非常的简单，只是作为学习其他顶点和片元着色器基础。 始前准备 对于这个知识点，我们将需要一个新的着色器。我们按照下面的步骤来： 1.创建一个新的着色器。 2.创建一个新的材质并且把着色器应用于该材质。 操作步骤 在前面的所有章节中，我们总是能在表面着色器（Surface Shaders）的基础上进行修改。但在这里就不能再那样做了，因为表面着色器和片元着色器在结构上是不一样的。我们需要做如下的修改： 删除着色器上的所有属性，然后用下面的属性替换： Color (\"Color\", Color) = (1,0,0,1) // Red _MainTex (\"Base texture\", 2D) = \"white\" {} 删除 SubShader 块中的所有代码，然后用下面的代码替换： Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag half4 _Color; sampler2D _MainTex; struct vertInput { float4 pos : POSITION; float2 texcoord : TEXCOORD0; }; struct vertOutput { float4 pos : SV_POSITION; float2 texcoord : TEXCOORD0; }; vertOutput vert(vertInput input) { vertOutput o; o.pos = UnityObjectToClipPos(input.pos); o.texcoord = input.texcoord; return o; } half4 frag(vertOutput output) : COLOR { half4 mainColour = tex2D(_MainTex, output.texcoord); return mainColour * _Color; } ENDCG } 后面所有的顶点和片元着色器都会以此为基础。 原理介绍 正如它的名字所提示的那样，顶点和片元着色器的工作步骤分为两步。首先，模型会通过一个顶点函数(vertex function)；之后，获得的结果会输入一个片元函数(fragment function)。这两个函数都直接用 pragma 进行声明： #pragma vertex vert #pragma fragment frag 在这个例子中，我们简单的给这两个函数取名为 vert 和 frag 从概念上来讲，片元（fragments） 跟像素关系紧密；片元这个术语常用于指代那些绘制像素时所必须的数据集。这也是为何顶点和片元着色器常被叫做像素着色器(Pixel Shaders)的原因。 在着色器代码中，顶点函数接收来自于定义的结构体 vertInput 中的输入数据： struct vertInput { float4 pos : POSITION; float2 texcoord : TEXCOORD0; }; 这个结构体的名字可以随便取，但是它里面的内容却不行。其中的每一项都必须使用 绑定语义(binding semantic) 进行修饰。这是Cg语言的一个特性，允许我们标记变量从而能让这些变量能被一些确切的数据初始化，比如 法线向量(normal vectors) 和 顶点位置(normal vectors) 。POSITION 这个绑定语义是说当vertInput 这个结构体输入到顶点函数中时，pos 将会包含当前顶点的位置。这个跟表面着色器中 appdata_full 结构体中的 vertex 项有些类似。两者的主要区别在于 pos 表示的是模型上的坐标（3D物体），这样的话我们需要手动把它转换成视口坐标（屏幕上的坐标）。 注意 在表面着色器中顶点函数一般只用于修改模型的几何形状。而在顶点着色器和片元着色器中，如果要将模型的坐标投影到屏幕上，顶点函数是必须的。 这种转换背后的数学原理超出了该章节的范围。然而我们可以通过Unity提供的一个特殊矩阵：UNITY_MATRIX_MVP，让它对 pos 进行乘运算从而得到一个这样的变换。它通常就是提到的 模型视图投影变换矩阵(model-view-projection matrix)，并且它对于找到顶点在屏幕中的位置来说是必不可少的： vertOutput o; o.pos = mul(UNITY_MATRIX_MVP, input.pos); 注意 如果你使用的是比较新的Unity引擎版本，那么o.pos = mul(UNITY_MATRIX_MVP, input.pos);这行代码会被Unity自动替换成o.pos = UnityObjectToClipPos(input.pos); 另一个初始化数据 textcoord ，它使用了 TEXCOORD0 绑定语义来获取第一张纹理的UV数据。之后就没有额外的处理了并且这个值可以直接传递给 片元函数（fragment function）： o.texcoord = input.texcoord; Unity会帮我们初始化 vertInput，而需要我们初始化的是 vertOutput。尽管如此，它里面的内容依然需要用绑定语义修饰： struct vertOutput { float4 pos : SV_POSITION; float2 texcoord : TEXCOORD0; }; 一旦顶点函数初始化vertOutput后，这个结构就会传递给片元函数。模型的主纹理采样就会跟提供的颜色值进行乘积 可以看到，顶点着色器和片元着色器并没有材质的物理学属性；相比于表面着色器，它们的工作方式更接近于GPU架构。 额外内容 顶点着色器和片元着色器最难理解的一方面就是绑定语义。可以使用的绑定语义不仅数量多并且它们所表达的意义还跟上下文有关。 输入语义 下表的绑定语义可以在 vertInput 中使用，这是Unity给顶点函数提供的结构。被这些语义修饰的部分将会被自动初始化： 绑定语义 描述 POSITION, SV_POSITION 一个顶点在世界坐标中的位置（物体空间） NORMAL 顶点的法线，相对于世界坐标来说的（不是相对于摄像机） COLOR, COLOR0, DIFFUSE, SV_TARGET 保存在顶点中的颜色信息 COLOR1, SPECULAR 保存在顶点中的次要颜色信息（通常是高光反射） TEXCOORD0, TEXCOORD1, …, TEXCOORDi 保存在顶点中的 0-i 的UV数据 输出语义 当进行绑定的时候，会在 vertOutput 结构中使用对应的语义；它们不能保证这些部分会被自动初始化。于此相反的；得由我们自己去给它们初始化。编译器会尽可能确保这些部分会被正确的数据初始化： 绑定语义 描述 POSITION, SV_POSITION, HPOS 顶点在摄像机坐标中的位置（裁剪空间，每个维度从0-1取值） COLOR, COLOR0, COL0, COL,SV_TARGET 正面主要颜色 COLOR1, COL1 正面次要颜色 TEXCOORD0, TEXCOORD1, …,TEXCOORDi, TEXi 保存在顶点中的 0-i 的UV数据 WPOS 窗口中的基于像素的坐标（起点在左下角） 如果出于某种原因，你需要某个包含不同类型数据的部分，你就可以从众多可用的 TEXCOORD 中选择一个去修饰它。编译器不允许某个部分没有修饰语义。 相关补充 你可以参考英伟达官网的手册 NVIDIA Reference Manual，里面有其他的可以在Cg中使用的绑定语义可供参考。" }, { "title": "Xlua框架，unity3d，webgl，报错argumentexception Destination Array Was Not Long Enough", "url": "/game-tech-post-old/posts/XLua%E6%A1%86%E6%9E%B6-Unity3D-WEBGL-%E6%8A%A5%E9%94%99ArgumentException-Destination-array-was-not-long-enough/", "categories": "Unity", "tags": "U3D, WEBGL, XLua, ArgumentException, Destination array was not long enough", "date": "2022-10-31 00:00:00 +0800", "snippet": "Unity使用XLua框架，打WEBGL包，运行时报错：ArgumentException: Destination array was not long enough具体的错误如下： dangerArgumentException: Destination array was not long enough. Check destIndex and length, and the arr...", "content": "Unity使用XLua框架，打WEBGL包，运行时报错：ArgumentException: Destination array was not long enough具体的错误如下： dangerArgumentException: Destination array was not long enough. Check destIndex and length, and the array's lower bounds由于我们UI使用的时FGUI，所以这个错误的具体表现是： 错误表现 在编辑器中运行良好，没有任何问题 打包成WEBGL运行就报这个错，但不是每次都报错， 如果报错，那么UI逻辑是正常的，如果不报错，那么UI逻辑异常，比如按钮的绑定事件错乱 解决办法 我在XLua的Issue中,找到了大佬的解决办法。是XLua在释放资源时的Lock操作引起的。原issue地址。但是大佬的贴的代码，不能直接运行，需要稍加修改才行【大佬可能给的时伪代码】。我在这里把解决步骤归纳一下： 1.添加一个非锁互斥队列【也可以不用添加，就用系统的也行】： using System.Threading;namespace XLua{ public class LockFreeQueue&lt;T&gt; { internal class SingleLinkNode&lt;U&gt; where U : T { public SingleLinkNode&lt;U&gt; Next; public U Item; } static private bool CAS&lt;T&gt;(ref T location, T comparand, T newValue) where T : class { return comparand == Interlocked.CompareExchange(ref location, newValue, comparand); } SingleLinkNode&lt;T&gt; head; SingleLinkNode&lt;T&gt; tail; int count; public int Count { get { return count; } } public bool IsEmpty { get { return count &lt;= 0; } } public LockFreeQueue() { head = new SingleLinkNode&lt;T&gt;(); tail = head; count = 0; } public void Enqueue(T item) { SingleLinkNode&lt;T&gt; oldTail = null; SingleLinkNode&lt;T&gt; oldTailNext; SingleLinkNode&lt;T&gt; newNode = new SingleLinkNode&lt;T&gt;(); newNode.Item = item; bool newNodeAdded = false; while (!newNodeAdded) { oldTail = tail; oldTailNext = oldTail.Next; if (tail == oldTail) { if (oldTailNext == null) newNodeAdded = CAS&lt;SingleLinkNode&lt;T&gt;&gt;(ref tail.Next, null, newNode); else CAS&lt;SingleLinkNode&lt;T&gt;&gt;(ref tail, oldTail, oldTailNext); } } CAS&lt;SingleLinkNode&lt;T&gt;&gt;(ref tail, oldTail, newNode); Interlocked.Increment(ref count); } public bool TryDequeue(out T item) { item = default(T); SingleLinkNode&lt;T&gt; oldHead = null; bool haveAdvancedHead = false; while (!haveAdvancedHead) { oldHead = head; SingleLinkNode&lt;T&gt; oldTail = tail; SingleLinkNode&lt;T&gt; oldHeadNext = oldHead.Next; if (oldHead == head) { if (oldHead == oldTail) { if (oldHeadNext == null) { return false; } CAS&lt;SingleLinkNode&lt;T&gt;&gt;(ref tail, oldTail, oldHeadNext); } else { item = oldHeadNext.Item; haveAdvancedHead = CAS&lt;SingleLinkNode&lt;T&gt;&gt;(ref head, oldHead, oldHeadNext); } } } Interlocked.Decrement(ref count); return true; } public T Dequeue() { T result; if (TryDequeue(out result)) return result; return default(T); } public void Clear() { while (Count &gt; 0) { Dequeue(); } } }} 2.修改XLua源码，添加条件编译，让WEBGL在释放引用的时候不加锁 改下面几个地方： refQueue的定义 #if !UNITY_WEBGL Queue&lt;GCAction&gt; refQueue = new Queue&lt;GCAction&gt;();#else LockFreeQueue&lt;GCAction&gt; refQueue = new LockFreeQueue&lt;GCAction&gt;();#endif equeueGCAction方法 internal void equeueGCAction(GCAction action){#if!UNITY_WEBGL lock (refQueue) {#endif refQueue.Enqueue(action);#if!UNITY_WEBGL }#endif} Tick方法 public void Tick(){#if THREAD_SAFE || HOTFIX_ENABLE lock (luaEnvLock) {#endif var _L = L;#if !UNITY_WEBGL lock (refQueue) {#endif while (refQueue.Count &gt; 0) { GCAction gca = refQueue.Dequeue(); translator.ReleaseLuaBase(_L, gca.Reference, gca.IsDelegate); }#if !UNITY_WEBGL }#endif#if !XLUA_GENERAL last_check_point = translator.objects.Check(last_check_point, max_check_per_tick, object_valid_checker, translator.reverseMap);#endif#if THREAD_SAFE || HOTFIX_ENABLE }#endif} 做完上面的步骤，然后重新编译，重新打webgl包再运行，就不会报错了。因为浏览器运行都是单线程，所以我们这里把加锁操作再webgl平台时去掉，问题就解决了。" }, { "title": "Unity编辑器 Persistentdatapath Datapath Streamingassetspath", "url": "/game-tech-post-old/posts/Unity%E7%BC%96%E8%BE%91%E5%99%A8-persistentDataPath-dataPath-streamingAssetsPath/", "categories": "UnityEditor", "tags": "Unity3D, persistentDataPath, dataPath, streamingAssetsPath", "date": "2022-10-27 00:00:00 +0800", "snippet": "Unity中persistentDataPath, dataPath, streamingAssetsPath在不同的平台对应的路径为了方便以后的开发，自己结合官方资料和自己的实际开发，把上面的路径变量在不同的平台对应的正式路径总结一下 Application.persistentDataPath 官方参考：https://docs.unity3d.com/2020.3/Documen...", "content": "Unity中persistentDataPath, dataPath, streamingAssetsPath在不同的平台对应的路径为了方便以后的开发，自己结合官方资料和自己的实际开发，把上面的路径变量在不同的平台对应的正式路径总结一下 Application.persistentDataPath 官方参考：https://docs.unity3d.com/2020.3/Documentation/ScriptReference/Application-persistentDataPath.html 对app是只读的，对玩家来说读写都可以，如果是IOS或者安卓，该路径指向设备的公共目录 app更新的时候，不会删除该目录，但是用户自己是可以对该目录增删改查的 平台 指向的位置 Windows Store Apps %userprofile%\\AppData\\Local\\Packages\\&lt;productname&gt;\\LocalState Windows Editor and Standalone Player %userprofile%\\AppData\\LocalLow\\&lt;companyname&gt;\\&lt;productname&gt; WebGL /idbfs/&lt;md5 hash of data path&gt; 该路径是URL最后一个斜杠“/”和“？”之间的字符串 Linux $XDG_CONFIG_HOME/unity3d 或者$HOME/.config/unity3d iOS /var/mobile/Containers/Data/Application/&lt;guid&gt;/Documents tvOS 不支持且返回空字符串 Android 通常指向/storage/emulated/0/Android/data/&lt;packagename&gt;/files，有的老机型可能指向SD卡的路径 Mac 指向用户的Library目录，通常该目录是隐藏的，现在Unity是指向~/Library/Application Support/company name/product name Application.dataPath 官方参考：https://docs.unity3d.com/2020.3/Documentation/ScriptReference/Application-streamingAssetsPath.html 对玩家和app都是只读的，是指设备的游戏目录，只能读取 根据不同的平台，游戏目录不一样 平台 指向位置 Unity Editor &lt;项目路径&gt;/Assets Mac player &lt;path to player app bundle&gt;/Contents iOS player &lt;path to player app bundle&gt;/&lt;AppName.app&gt;/Data Win/Linux player &lt;游戏的可执行文件的数据目录&gt; （请注意Linux目录是大小写敏感的，window不是) WebGL 玩家数据目录的绝对URL（没有具体的文件名） Android 通常指向APK，如果你使用的是安卓分包，那么它指向OBB（也就是说游戏数据文件都保存到了OBB文件中） Windows Store Apps 是一个指向玩家数据目录的绝对路径 注意：PC上返回的路径是用反斜杠（“\\”）做分割的 streamingAssetsPath 官方参考： https://docs.unity3d.com/2020.3/Documentation/ScriptReference/Application-streamingAssetsPath.html 对玩家和app都是只读的 都是指向Unity的StreamingAssets文件夹 平台 项目路径 Unity Editor &lt;项目路径&gt;/Assets/StreamingAssets Mac Player &lt;path to player app bundle&gt;/Contents/Resources/Data/StreamingAssets IOS Player &lt;path to player app bundle&gt;/&lt;AppName.app&gt;/Data/Raw Win/Linux player &lt;游戏的可执行文件的数据目录&gt;/StreamingAssets WebGL &lt;玩家数据目录的绝对URL&gt;/StreamingAssets Android Application.dataPath + “!/assets” 如果用UnityWebRequest来获取文件，传入的路径参数 官方参考：https://docs.unity3d.com/Manual/StreamingAssets.html 平台 项目路径 Unity Editor Application.streamingAssetsPath/文件名 Mac Player Application.streamingAssetsPath/文件名 IOS Player “file://” + Application.dataPath + “/Raw/” + 文件名; Win/Linux player Application.streamingAssetsPath + “/” + 文件名 WebGL Application.streamingAssetsPath + “/” + 文件名（Unity会自动把Application.streamingAssetsPath转换为对应的URL） Android “jar:file://” + Application.dataPath + “!/assets/” + 文件名 " }, { "title": "实现范围体爆炸", "url": "/game-tech-post-old/posts/%E5%AE%9E%E7%8E%B0%E8%8C%83%E5%9B%B4%E4%BD%93%E7%88%86%E7%82%B8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-10-23 00:00:00 +0800", "snippet": "实现范围体爆炸对于实现游戏中的艺术效果，有时候需要在画质和运行效率上进行巧妙的权衡。在实现爆炸效果上尤其如此；因为它是很多游戏的核心效果，但是在它之后的一些物理计算通常都会超过现代计算机的算力。爆炸本质上就是一团温度非常高的火红气体；所以正确模拟它的唯一方式就是在游戏中用流体模拟来模拟它。正如你所想的一样，这在运行时是不可行的，在很多的游戏中都是通过粒子来模拟。当一个物体爆炸的时候，通常会同...", "content": "实现范围体爆炸对于实现游戏中的艺术效果，有时候需要在画质和运行效率上进行巧妙的权衡。在实现爆炸效果上尤其如此；因为它是很多游戏的核心效果，但是在它之后的一些物理计算通常都会超过现代计算机的算力。爆炸本质上就是一团温度非常高的火红气体；所以正确模拟它的唯一方式就是在游戏中用流体模拟来模拟它。正如你所想的一样，这在运行时是不可行的，在很多的游戏中都是通过粒子来模拟。当一个物体爆炸的时候，通常会同时产生很多的火花，烟雾和一些散落的碎片，这样可以获得一个比较像的爆炸。不幸的是，这种模拟方法很容易被看破而且可能不是很真实。这里我们会了解一种折中的技术来实现爆炸效果，并且画质更好：范围体爆炸（volumetric explosions）。这个知识点背后的思考是我们不再把爆炸当作是一系列粒子的模拟；它们现在进阶到3D物体了，而不仅仅是扁平的2D贴图。 始前准备 我们通过下面的几个步骤来讲解这个知识点： 为这个效果创建一个新的着色器 创建一个新的材质，并且关联该着色器 把这个材质关联到一个球体模型上。你可以在编辑器上直接创建一个球体模型，通过菜单 GameObject | 3D Object | Sphere。 注意 使用标准的Unity球体就可以很好的演示这个知识点，但是如果你想要更大范围的爆炸，那么你可能需要面数更多的球体。事实上，顶点函数只能修改网格的顶点。所有其他的点都可以通过修改相邻顶点的位置的方式来修改它们。顶点数越少，那么爆炸效果的精细度也就越低。 这个知识点中，你需要一个渐变纹理（ramp texture），这个纹理需要有你爆炸的所有颜色梯度。你可以用GIMP或者PhotoShop工具创建一个跟下面类似的纹理： 当你有了这个图片后，把它导入到你的Unity中。然后在查看面板（Inspector）中，确保Filter Mode设置为Bilinear，然后Wrap Mode设置为Clamp。这两个设置是为了确保对渐变纹理平滑采样。 最后，你还需要一张噪音纹理（noisy texture）。你可以在网上搜索免费的噪音纹理。一般我们都使用Perlin noise。【这里我自己找到一个网站http://kitfox.com/projects/perlinNoiseMaker/】 操作步骤 这个效果我们分两步来实现：通过顶点函数改变几何形状，通过表面函数给与正确的颜色。这两个步骤如下： 添加下面的属性到着色器中： _RampTex(\"Color Ramp\", 2D) = \"white\" {}_RampOffset(\"Ramp offset\", Range(-0.5,0.5))= 0_NoiseTex(\"Noise tex\", 2D) = \"gray\" {}_Period(\"Period\", Range(0,1)) = 0.5_Amount(\"_Amount\", Range(0, 1.0)) = 0.1_ClipRange(\"ClipRange\", Range(0,1)) = 1 添加相应变量，让着色器的Cg代码可以访问到它们： sampler2D _RampTex;half _RampOffset;sampler2D _NoiseTex;float _Period;half _Amount;half _ClipRange; 修改输入结构体（Input structure），这样可以让它接收渐变纹理的UV数据： struct Input { float2 uv_NoiseTex;}; 添加下面的顶点函数： void vert(inout appdata_full v) { float3 disp = tex2Dlod(_NoiseTex, float4(v.texcoord.xy,0,0)); float time = sin(_Time[3] *_Period + disp.r*10); v.vertex.xyz += v.normal * disp.r * _Amount * time;} 添加下面的的表面函数： void surf(Input IN, inout SurfaceOutput o) { float3 noise = tex2D(_NoiseTex, IN.uv_NoiseTex); float n = saturate(noise.r + _RampOffset); clip(_ClipRange - n); half4 c = tex2D(_RampTex, float2(n,0.5)); o.Albedo = c.rgb; o.Emission = c.rgb*c.a;} 我们直接通过 #pragma 来指定我们要使用的顶点函数，通过添加 nolightmap参数来阻止Unity添加真实光照到我们的爆炸效果中： #pragma surface surf Lambert vertex:vert nolightmap 最后一步，给我们球体模型选择我们刚刚创建的材质，然后在查看面板（Inspector）中，为我们的材质添加噪音纹理和渐变纹理。这是一个动画材质，也就是说会随着时间变化。你可以观察材质的变化，只要在编辑器的场景窗口（Scene Window）中点击 Animated Materials： *** 原理介绍 在学习这个知识点的时候，如果你了解表面着色器（Surface Shaders） 和 顶点修饰（vertex modifiers） 的工作原理。这个效果背后的主要思路是以一种混乱的方式修改这个圆球几何图形的表面，然后使它看起来像真正的爆炸。下图所示是在Unity编辑器内这种爆炸看起来的样子。可以看到这个网格已经发生了明显的畸变： 顶点函数我们已经在这一章的 模型挤压 这个知识点介绍过。 不过这里的挤压是通过时间和噪音来决定如何表现的。 注意 在Unity中如果你需要一个随机数，你可以使用随机函数Random.Range()。在着色器中没有获取随机数的标准方法，最简单的方法就是通过对噪音贴图采样了。 这里由于没有标准的方法，所以下面的代码只是举例： float time = sin(_Time[3] *_Period + disp.r*10); 内建的 _Time[3] 变量可以获得着色器内部的时间，disp.r是噪音贴图的红色通道，用于确保每一个顶点的运动都是独立的。三角函数sin()可以让这些顶点上下运动，用于模拟爆炸的混乱表现。接下来的代码是法线挤压： v.vertex.xyz += v.normal * disp.r * _Amount * time; 你可以在运行的过程中调节这些数值直到你找到一个自己比较满意的爆炸的行为模式。 该效果的最后一部分是通过表面函数surface function来获得的。在这里噪音纹理用来从梯度纹理中进行颜色的随机采样。但是这里有额外的两点需要注意。先介绍第一个：_RampOffset。它用来强制爆炸从纹理的左边或者右边进行颜色的采样。如果这个是正数，那么爆炸的表面趋于更灰的色调；也就是爆炸慢慢消融。你可以使用 _RampOffset 来决定爆炸中该含有多少火焰或者烟尘。另一个该注意的是在表面函数中clip()函数的使用。它的作用是从渲染管线rendering pipeline中裁剪（移除）像素。当它的参数为负数时，当前的像素便不会被绘制。这个效果被属性_ClipRange控制，它决定了范围体爆炸中哪一部分将会是透明的。 通过控制属性_RampOffset和_ClipRange，你就可以完全的控制爆炸如何表现以及如何消融。 额外内容 这个知识点涉及的着色器可以让一个球体看起来像爆炸一样。这里只是抛砖引玉，如果你真的想使用它，你应该配合相应的一些脚本来获得更棒的效果。最好是创建一个爆炸物体然后把这个物体做成一个预制体，这样你就可以在任何需要的时候重复使用它。你可以直接拖拽这个球体，把它拖拽到 项目Project 窗口中。完成这一步后，你就创建了这个预制体，然后你就可以通过 Instantiate() 方法创建一些你想要的爆炸了。 然而需要注意的是，所有创建的这些爆炸对象它们的材质都是一样的，所以看起来都一个样。如果你在同一时刻有多个爆炸，那么它们不应该使用同一个材质。当你实例化一个新的爆炸的时候，你还应该再复制一份材质。你可以很容易的做到，下面是参考的代码片段： GameObject explosion = Instantiate(explosionPrefab) as GameObject;Renderer renderer = explosion.GetComponent&lt;Renderer&gt;();Material material = new Material(renderer.sharedMaterial);renderer.material = material; 最后，如果你想在次世代画面表现中使用这个着色器，那么你应该根据你想要创建的爆炸类型，给这个爆炸体添加相应的脚本用于修改它的大小，_RampOffset 和 _ClipRange以达到对应的效果。 相关补充 我们还能做更多的工作来让爆炸效果更加的真实。在这个知识点中我们所展示的方式只是产生了一个爆炸的大体形状而已，爆炸的内部其实是空的。一个简单的技巧就是在爆炸的内部生成粒子。然而，你能做的其实也就这么多了。由Unity官方跟Nvidia和Passion Pictures合作制作的短片 The Butterfly Effect http://unity3d.com/pages/butterfly，是相关的最棒的演示。这个演示效果同样是基于修改球形几何体形状这一概念，不过它是通过一项叫做 体积光线投射算法(volume ray casting) 的技术来渲染的。简单的说，这种技术可以让几何体的渲染看起来像是饱满的。下图展示了一个示例： 如果你在寻找高质量的爆炸效果，可以在Unity的资产商店搜索 Pyro Technix https://assetstore.unity.com/packages/vfx/shaders/pyro-technix-16925。这个资源包括了范围体爆炸并且其中一些还有真实的冲击波效果。" }, { "title": "Windows powershell7.x安装,跟oh My Posh美化", "url": "/game-tech-post-old/posts/windows-powershell7.X%E5%AE%89%E8%A3%85,%E8%B7%9Foh-my-posh%E7%BE%8E%E5%8C%96/", "categories": "PowerShell", "tags": "Windows, powershell7, on-my-posh, 美化", "date": "2022-10-15 00:00:00 +0800", "snippet": "在windows安装powershell7.x，以及oh-my-posh的美化 1.安装Windows Terminal 有下面几种安装方式 直接在windows的商店重搜索windows terminal然后安装即可 通过winget安装 winget install --id=Microsoft.W...", "content": "在windows安装powershell7.x，以及oh-my-posh的美化 1.安装Windows Terminal 有下面几种安装方式 直接在windows的商店重搜索windows terminal然后安装即可 通过winget安装 winget install --id=Microsoft.WindowsTerminal -e 通过Chocolatey安装 choco install microsoft-windows-terminal 2.安装powershell7 可以通过下面几种方式安装 在官网下载msi安装包，直接安装 https://learn.microsoft.com/zh-cn/powershell/scripting/install/installing-powershell-on-windows?view=powershell-7.2 如下图 使用 winget 安装 winget install --id Microsoft.Powershell --source winget 设置默认启动的shell为powershell7 打开windows terminal 在窗口标题栏右键，然后点击设置 然后选择启动，然后选择默认用powershell7启动，如下图 然后关闭windows terminal,重新打开，就可以看到默认是以powershell启动 3.安装oh-my-posh[顺带安装posh-git] 安装oh-my-posh和posh-git 旧教程都是通过在powershell中安装模块的方式安装，但是作者现在已经不推荐那样安装了，具体的原因在这里：原因 新的oh-my-posh的安装方式，也在原因有说明，过程如下： oh-my-posh 首先移除掉之前的一些模块缓存文件 Remove-Item $env:POSH_PATH -Force -Recurse :exclamation: 注意 如果你在这个位置有放自己的一些内容，这些内容会一起被删除，所以在执行上面的命令之前，请一定要记得先保存这些自己的文件 安装oh-my-posh winget install JanDeDobbeleer.OhMyPosh -s winget 这个命令会做下面两件事: 安装 oh-my-posh.exe可执行文件到你的电脑 安装Oh My Posh的最新的主题【如果你有设置自定义的主题，就会使用你自己的】 卸载powershell中的oh-my-posh模块 Uninstall-Module oh-my-posh -AllVersions 从$PROFILE中删掉下面的模块导入命令 Import-Module oh-my-posh posh-git 执行下面的命令: Install-Module posh-git -Scope AllUsers 一些权限需要开启 Install-Module -Name PSReadLine -AllowPrerelease -Scope AllUsers -Force -SkipPublisherCheck 为powershell创建一个配置文件 下面的命令会自动创建一个配置文件，并且打开， if (!(Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force } notepad $PROFILE 在配置中添加下面的命令 Import-Module posh-git ## 在当前打开的 PowerShell 终端中引入 posh-git（已安装，这里只是引入） Import-Module PSReadLine ## 这个工具主要做命令提示管理等操作，默认集成在了 PowerShell 中，不需要安装 Set-PSReadlineKeyHandler -Key Tab -Function Complete ## 设置 Tab 键补全 Set-PSReadLineKeyHandler -Key \"Ctrl+d\" -Function MenuComplete ## 设置 Ctrl+D 为菜单补全和 Intellisense Set-PSReadLineKeyHandler -Key \"Ctrl+z\" -Function Undo ## 设置 Ctrl+Z 为撤销 Set-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward ## 设置向上键为后向搜索历史记录 Set-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward ## 设置向下键为前向搜索历史记录 oh-my-posh init pwsh --config ~/Documents/PowerShell/themes/robbyrussel.omp.json | Invoke-Expression ## 设置主题，如果不喜欢robbyrussel这个主题，到oh-my-posh官方网站（https://ohmyposh.dev/docs/themes）找到自己喜欢的，然后换一下名字就可以 安装主题 去https://github.com/JanDeDobbeleer/oh-my-posh把项目下载下来，把里面的themes文件夹直接复制一份， 放到 ~/Documents/PowerShell 这个目录中去。需要什么主题，修改上面命令的最后一行代码，把主题文件改成你喜欢的就行了。 注意 有可能遇到无法识别 oh-my-posh 的问题，说它不是命令之类的错误，这个时候执行下面的命令 Set-ExecutionPolicy Bypass -Scope Process -Force; Invoke-Expression ((New-Object System.Net.WebClient).DownloadString('https://ohmyposh.dev/install.ps1')) 4.安装nerdfont字体 昨晚上面的步骤，你的美化还没有算完全配置完。因为oh-my-posh使用的是nerd字体，控制台中的各种优美的符号和图标都在这些字体上，所以请去下面的网站安装自己 喜欢的字体，我个人推荐的是JetBrainMono字体 https://www.nerdfonts.com/font-downloads 安装玩字体后，还是要在windows terminal的设置重选择你安装的字体，设置位置在下图: 然后重新打开windows terminal看效果 " }, { "title": "Mac中使用npm的http Server", "url": "/game-tech-post-old/posts/Mac%E4%B8%AD%E4%BD%BF%E7%94%A8npm%E7%9A%84http-server/", "categories": "npm", "tags": "Mac, http-server, https证书, 本地运行, 安装http-server", "date": "2022-10-12 00:00:00 +0800", "snippet": "Mac在本地开发中使用http-server，并且使用https 1.在本地新建一个文件夹，并进入该文件夹 新建一个文件夹www mkdir www 进入文件夹 cd www 2.安装 mkcert brew install mkcert ``` bash brew install nss # if you ...", "content": "Mac在本地开发中使用http-server，并且使用https 1.在本地新建一个文件夹，并进入该文件夹 新建一个文件夹www mkdir www 进入文件夹 cd www 2.安装 mkcert brew install mkcert ``` bash brew install nss # if you use Firefox 3.将 mkcert 添加到本地根 CA mkcert -instal 4.为您的站点(localhost)生成一个由 mkcert 签名的证书 mkcert localhost 5.启动服务[把下面的命令直接放到一个.sh文件中去，直接运行.sh文件] http-server -p 8080 -S -C ./localhost.pem -K ./localhost-key.pem " }, { "title": "在unity编辑器不同位置添加菜单", "url": "/game-tech-post-old/posts/%E5%9C%A8Unity%E7%BC%96%E8%BE%91%E5%99%A8%E4%B8%8D%E5%90%8C%E4%BD%8D%E7%BD%AE%E6%B7%BB%E5%8A%A0%E8%8F%9C%E5%8D%95/", "categories": "UnityEditor", "tags": "Unity3D, 编辑器, 添加菜单, 右键菜单", "date": "2022-09-22 00:00:00 +0800", "snippet": "在Unity编辑器不同位置添加菜单有时候由于自定义工作流的需要，我们需要在编辑器中添加我们自己的菜单，用来执行不同的操作，这里介绍在编辑器的不同位置该如何添加菜单，比如在主菜单添加，Hierarchy，Project，Inspector等位置。主菜单通过下拉列表弹出，Hierarchy，Project和Inspector分别是鼠标右键弹出。 在主菜单中弹出 using Unity...", "content": "在Unity编辑器不同位置添加菜单有时候由于自定义工作流的需要，我们需要在编辑器中添加我们自己的菜单，用来执行不同的操作，这里介绍在编辑器的不同位置该如何添加菜单，比如在主菜单添加，Hierarchy，Project，Inspector等位置。主菜单通过下拉列表弹出，Hierarchy，Project和Inspector分别是鼠标右键弹出。 在主菜单中弹出 using UnityEngine; using UnityEditor; using System.Collections; public class ExampleClass : MonoBehaviour { // Add Example1 has priority of 100 [MenuItem(\"Example/Example1\", priority = 1)] public static void Example1() { print(\"Example/Example1\"); } // Example2 has a priority of 111 which is 11 more than Example1. // This will cause a divider to be created. [MenuItem(\"Example/Example2\", priority = 11)] public static void Example2() { print(\"Example/Example2\"); } } 效果如下图： 注意当两个菜单的 priority 差值大于10【小于等于10不会有】的时候，菜单之间会自动生成一条横线。并且 priority 越大，菜单就会在越下面 在Hierarchy中弹出 using UnityEngine; using UnityEditor; using System.Collections; public class ExampleClass : MonoBehaviour { // Add Example1 has priority of 100 [MenuItem(\"GameObject/Example1\", priority = 1)] public static void Example1() { print(\"Example/Example1\"); } // Example2 has a priority of 111 which is 11 more than Example1. // This will cause a divider to be created. [MenuItem(\"Example/Example2\", priority = 12)] public static void Example2() { print(\"Example/Example2\"); } } 效果如下图： 注意它会出现在两个位置 在主菜单的GameObject子菜单下： 在Hierarchy右键： 在Project中弹出 using UnityEngine; using UnityEditor; using System.Collections; public class ExampleClass : MonoBehaviour { // Add Example1 has priority of 100 [MenuItem(\"Assets/Example1\", priority = 1)] public static void Example1() { print(\"Example/Example1\"); } // Example2 has a priority of 111 which is 11 more than Example1. // This will cause a divider to be created. [MenuItem(\"Example/Example2\", priority = 12)] public static void Example2() { print(\"Example/Example2\"); } } 效果如下图： 出现在两个位置： 在主菜单的Assets子菜单下： 在Project中右键： 在Inspector中弹出 using UnityEngine; using UnityEditor; using System.Collections; public class ExampleClass : MonoBehaviour { // Add Example1 has priority of 100 [MenuItem(\"CONTEXT/Transform/move\", priority = 1)] public static void Example1() { print(\"Example/Example1\"); } // Example2 has a priority of 111 which is 11 more than Example1. // This will cause a divider to be created. [MenuItem(\"CONTEXT/AudioListener/addListener\", priority = 12)] public static void Example2() { print(\"Example/Example2\"); } } 这是在具体的上下文中弹出。 比如在Inspector窗口中，对Transform右键弹出： 比如在Inspector窗口中，在AudioListener右键弹出： " }, { "title": "实现下雪效果着色器", "url": "/game-tech-post-old/posts/%E5%AE%9E%E7%8E%B0%E4%B8%8B%E9%9B%AA%E6%95%88%E6%9E%9C%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-07-17 00:00:00 +0800", "snippet": "实现下雪效果着色器在游戏中模拟下雪效果一直都是一件有挑战的事情。大部分的游戏都会简单的直接在模型的纹理上包含雪，让这些模型看起来雪白。然而要是其中某个模型开始旋转了呢？雪并不是敷衍了事的表面工作；它应该被当做是一些材料的合理的堆积【意思是物体表面的雪是雪花一点一点堆积起来的，而不是简简单单的给它一张白色的贴图】。在这个知识点中将会向你展示如何用一个着色器让你的模型看起来有种下雪的样子。要完成...", "content": "实现下雪效果着色器在游戏中模拟下雪效果一直都是一件有挑战的事情。大部分的游戏都会简单的直接在模型的纹理上包含雪，让这些模型看起来雪白。然而要是其中某个模型开始旋转了呢？雪并不是敷衍了事的表面工作；它应该被当做是一些材料的合理的堆积【意思是物体表面的雪是雪花一点一点堆积起来的，而不是简简单单的给它一张白色的贴图】。在这个知识点中将会向你展示如何用一个着色器让你的模型看起来有种下雪的样子。要完成这个效果有两个步骤。首先，对于朝向天空的三角面我们给它白色。其次，通过挤压顶点来模拟雪的堆积效果。你可以从下图看到最终的效果：注意本知识点并无意去创建那种超真实的下雪效果。它只是抛砖引玉，但在你的游戏当中，最终的效果定位，还是取决于你们的艺术家们，通过他们设置正确的纹理和参数来达到你的要求。 始前准备 这个效果完全基于着色器来实现，所以请按照下面的步骤操作： 1.为雪的效果创建一个新的着色器。 2.为这个着色器创建一个新的材质。 3.把这个材质添加到你想表现雪的效果的模型上去。 操作步骤 为了创建下雪的效果，请打开你的着色器，然后做以下的修改： 1.把下面的属性块替换掉你原来的着色器属性块： _MainColor(\"Main Color\", Color) = (1.0,1.0,1.0,1.0) _MainTex(\"Base (RGB)\", 2D) = \"white\" {} _Bump(\"Bump\", 2D) = \"bump\" {} _Snow(\"Level of snow\", Range(1, -1)) = 1 _SnowColor(\"Color of snow\", Color) = (1.0,1.0,1.0,1.0) _SnowDirection(\"Direction of snow\", Vector) = (0,1,0) _SnowDepth(\"Depth of snow\", Range(0,1)) = 0 2.添加与属性块对应的变量： sampler2D _MainTex; sampler2D _Bump; float _Snow; float4 _SnowColor; float4 _MainColor; float4 _SnowDirection; float _SnowDepth; 3.用下面的代码替换掉原来的 输入结构体（Input structure） struct Input { float2 uv_MainTex; float2 uv_Bump; float3 worldNormal; INTERNAL_DATA }; 4.用下面的表面函数替换掉原有的表面函数。它会让模型着雪的部分变成白色： void surf(Input IN, inout SurfaceOutputStandard o) { half4 c = tex2D(_MainTex, IN.uv_MainTex); o.Normal = UnpackNormal(tex2D(_Bump, IN.uv_Bump)); if (dot(WorldNormalVector(IN, o.Normal), _SnowDirection.xyz) &gt;= _Snow) o.Albedo = _SnowColor.rgb; else o.Albedo = c.rgb * _MainColor; o.Alpha = 1; } 5.配置 #pragma 预编译指令，让我们可以使用顶点修饰： #pragma surface surf Standard vertex:vert 6.添加下面的顶点修饰，这样就可以对被雪覆盖部分的顶点进行挤压： void vert(inout appdata_full v) { float4 sn = mul(UNITY_MATRIX_IT_MV, _SnowDirection); if (dot(v.normal, sn.xyz) &gt;= _Snow) v.vertex.xyz += (sn.xyz + v.normal) * _SnowDepth * _Snow; } 现在你可以去你的模型材质 查看面板（Inspector tab）查看，然后通过调节上面的参数，你可以调节雪的覆盖面积和厚度。 原理介绍 这个着色器按照下面两个步骤工作。 给表面添加颜色 首先是修改朝向天空的三角面的颜色。它会影响所有法线方向跟 _SnowDirection 方向相同三角面。正如前面 第三章，理解光照模型 中介绍的那样，比较两个单位向量相似度可以用 点积（dot product）。当两个向量垂直的时候， 它们的点积是0；当两个向量平行的时候，它们的点积是1。_Snow 这个属性则用来考虑，这个值究竟是多少，才认为是朝向天空的。 如果你仔细观察表面函数，你能发现我们并没有直接算法线跟下雪方向的点积。这是因为它们通常是在不同的坐标系中定义的。下雪的方向来自世界坐标系，而模型的法线通常是相对模型本身来说的。如果我们旋转模型，它的法线不会变，这不是我们 想要的。为了解决这个问题，我们需要把法线从本地坐标转换成世界坐标。这个过程可以用 WorldNormalVector() 这个函数来完成，就如下面的代码一样： if (dot(WorldNormalVector(IN, o.Normal), _SnowDirection.xyz) &gt;= _Snow) o.Albedo = _SnowColor.rgb; else o.Albedo = c.rgb * _MainColor; 这个着色器仅仅只是把模型着雪的地方变成白色；还有更高级的操作，比如在 SurfaceOutputStandard 结构体中用写实的纹理和参数对其进行初始化。 修改几何图形 该着色器的第二个效果是修改几何图形来模拟雪的堆积。首先，我们用了跟表面函数中相同的条件做测试，标记出了那些三角面是白色的。但是在这里比较遗憾的是我们不能使用 WorldNormalVector() 函数，因为在顶点修饰那里 SurfaceOutputStandard 结构体还没有被初始化。我们使用另一种方法来代替，就是把 _SnowDirection 转换成本地坐标： float4 sn = mul(UNITY_MATRIX_IT_MV, _SnowDirection); 接着，我们就可以挤压几何图形来模拟雪的堆积了： if (dot(v.normal, sn.xyz) &gt;= _Snow) v.vertex.xyz += (sn.xyz + v.normal) * _SnowDepth * _Snow; 在强调一遍，这个效果是一个很基础的效果。比如我们可以用一张纹理贴图来精确控制雪的堆积效果，或者一些奇怪的，不平坦的效果表现。 额外内容 如果你的游戏中需要一些高质量的积雪效果或者支持，你可以在Unity的资源商店中看看下面的这些资源： Winter Suite ($30)： 一个比我们这个知识点中更加复杂的雪效果着色器版本[连接已经失效了] https://www.assetstore.unity3d.com/en/#!/content/13927 Winter Pack ($60)： 一个很真实的雪环境的材质和支持 https://www.assetstore.unity3d.com/en/#!/content/13316 " }, { "title": "模型挤压", "url": "/game-tech-post-old/posts/%E6%A8%A1%E5%9E%8B%E6%8C%A4%E5%8E%8B/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-07-11 00:00:00 +0800", "snippet": "模型挤压重复是游戏当中最要命的一个问题之一。在游戏中创建新内容是一项费时的任务，当你要创建成千上万的敌人时，那么有很大的可能这些敌人有可能会看起来一样。这个时候利用着色器修改模型的基本几何图形，从而让模型产生不同的变化，可以说是一种相对来说性能较好的方法。这个知识点中我们会给你演示一种叫做 法线挤压（normal extrusion） 的技术，可以用来创建胖的或者瘦的模型，就比如下图所示的来...", "content": "模型挤压重复是游戏当中最要命的一个问题之一。在游戏中创建新内容是一项费时的任务，当你要创建成千上万的敌人时，那么有很大的可能这些敌人有可能会看起来一样。这个时候利用着色器修改模型的基本几何图形，从而让模型产生不同的变化，可以说是一种相对来说性能较好的方法。这个知识点中我们会给你演示一种叫做 法线挤压（normal extrusion） 的技术，可以用来创建胖的或者瘦的模型，就比如下图所示的来自Unity的demo中的士兵： 始前准备 在这个知识点中，我们需要获取要挤压的模型的着色器。获得该着色器后，复制它，因为这样能安全的编辑拷贝的着色器。我们可以按照下面的步骤进行： 1.找到模型使用的着色器[原着色器就是一个标准的着色器，没有找到就自己新建一个也行]，通过快捷键 Ctrl + D 复制它。 2.复制模型原有的材质，并且将之前复制的着色器添加给它。 3.把这个新的材质添加到模型上，并且开始编辑它。 为了达到效果，你的模型还要有 法线（normals） 。 操作步骤 为了创建这个效果，我们先来编辑刚刚复制的着色器： 1.首先给我们的着色器添加一个属性，用于调整压缩效果。我们这里的调节范围是从 -0.00005 到 0.00005 【书上是-1到1，但实际上书上的范围太大了，各位可以自己试试】，当然你可以根据自己的需要调节这个范围【 _MainTex 是需要的，因为人物是需要贴图的。】： _MainTex(\"Texture\", 2D) = \"white\" {} _Amount (\"Extrusion Amount\", Range(-0.00005, 0.00005)) = 0 2.我们的属性和变量是成对出现的，在着色器中定义下面的变量： float _Amount; 3.修改 pragma 预编译指令让Unity知道我们要使用 顶点修饰（vertex modifier） 。然后在它后面添加 vertex:function_name，function_name就是你自定义的方法名，当我我们这里叫 vert： #pragma surface surf Lambert vertex:vert 4.添加下面的顶点修改代码： void vert (inout appdata_full v) { v.vertex.xyz += v.normal * _Amount; } 5.这样着色器就写好了；这样你就可以在 查看面板（Inspactor） 中通过修改材质上的 Amount 参数来控制士兵的胖瘦了。【书本写的不清楚，其实还有贴图的代码，作者没有交代，所以完整的代码如下：】 Shader \"Custom/Normal Extrusion\" { Properties { _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _Amount (\"Extrusion Amount\", Range(-0.00005, 0.00005)) = 0 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM // Physically based Standard lighting model, and enable shadows on all light types #pragma surface surf Lambert vertex:vert // Use shader model 3.0 target, to get nicer looking lighting #pragma target 3.0 sampler2D _MainTex; struct Input { \tfloat2 uv_MainTex; }; float _Amount; // Add instancing support for this shader. You need to check 'Enable Instancing' on materials that use the shader. // See https://docs.unity3d.com/Manual/GPUInstancing.html for more information about instancing. // #pragma instancing_options assumeuniformscaling UNITY_INSTANCING_CBUFFER_START(Props) \t// put more per-instance properties here UNITY_INSTANCING_CBUFFER_END void vert (inout appdata_full v) { \tv.vertex.xyz += v.normal * _Amount; } void surf (Input IN, inout SurfaceOutput o) { \t// Albedo comes from a texture tinted by color \to.Albedo = tex2D(_MainTex, IN.uv_MainTex).rgb; } ENDCG \t} FallBack \"Diffuse\" } 原理介绍 表面着色器（Surface shader） 分两步来工作。在前面的章节中，我们只是探索了它最后一个步骤：表面函数（surface function。这里我们接触了另一种函数：顶点修饰（vertex modifier）。它接收一个顶点的数据结构 （通常这个数据结构叫做 appdata_full ）并且对它进行转变。它让我们对于模型的几何图形做各种视觉效果给与很大的自由度。我们通过在表面着色器的预编译指令 #pragma 那里添加 vertex:vert 来告知GPU 我们添加了 自己的顶点函数。你可以查看 第六章，片元着色器和抓取通道 来学习怎么在顶点着色器和片元着色器中定义顶点修饰。 法线挤压是改变模型的几何图形中最简单，也是最有效的技术之一。它是利用顶点对法线方向的投影来工作的。它是通过下面的着色器代码来实现的： v.vertex.xyz += v.normal * _Amount; 顶点的位置会被一个朝向法线的 _Amount 单位长度的向量取代。如果 _Amount的数值太大，呈现的效果会让人有点不舒服【脑袋特别大，而且很恐怖】。所以要通过一些比较小的合理的值，这样就可以让你的模型可以获得大量的不同的变体。 额外内容 如果你有多个敌人并且希望每个敌人都有不同的体重【也就是胖瘦不一样】，那么你就要为每个不同的敌人创建不同的材质。这是必要的操作，这是因为模型之间通常共用一个材质，为一个敌人改变了这个材质那么其他所有用了该材质的 的敌人也会跟着改变。这里有几种方法可以为你做这件事。下面的脚本，只要添加到有 Renderer 的游戏对象上，就会自动复制一份它的第一个材质并且自动设置好 _Amount 属性： using UnityEngine; public class NormalExtruder : MonoBehaviour { [Range(-0.0001f, 0.0001f)] public float amount = 0; // Use this for initialization void Start () { Material material = GetComponent&lt;Renderer&gt;().sharedMaterial; Material newMaterial = new Material(material); newMaterial.SetFloat(\"_Amount\", amount); GetComponent&lt;Renderer&gt;().material = newMaterial; } } 添加挤压贴图 这个技术其实还可以进一步的提升。我们可以添加一个额外的纹理（或者使用主纹理的alpha通道）来表示挤压的程度。这样可以让我们对于哪一部分应该隆起或者凹陷有更好控制。下面的代码向你展示了如何获得这种效果： sampler2D _ExtrusionTex; void vert(inout appdata_full v) { float4 tex = tex2Dlod (_ExtrusionTex, float4(v.texcoord.xy,0,0)); float extrusion = tex.r * 2 - 1; v.vertex.xyz += v.normal * _Amount * extrusion; } _ExtrusionTex 的红色通道被用来作为法线挤压相乘的系数。如果是0.5的话模型不会有什么影响；它的暗亮程度会被用于表示顶点的向内或向外挤压。有一点你需要注意的是，如果是用顶点修饰来对纹理采样，tex2Dlod 应该 用 tex2D 来替换。 注意 在着色器中，颜色通道的值的范围值 0 到 1，但有时候你又想用负数（比如你想用负数表示向内挤压）。那么针对这种情况，你可以用0.5表示0，比0.5小的看成负数，比0.5大的看成正数。其实在RGB编码的纹理中，就是用这 中方法来表示法线的。比如UnpackNormal() 函数就被用来作为 (0, 1) 映射到 (-1, 1) 的映射函数。它其实等同于数学表达式 tex.r * 2 -1 。 挤压贴图特别适合用来表现丧尸化的人物，方法就是通过扭曲人物的皮肤来突出皮肤下面的骨头的形状。下图向你展示了如何把一个健康的士兵，通过一个着色器和挤压贴图，变成一具毫无生气尸体的。对比与前面的几个例子，你可以注意到 那些衣服是如何不受影响的【就是挤压贴图里，对衣服进行挤压的数值是0.5】。下图所使用的着色器通过让挤压贴图的某些区域变得更黑，让士兵看起来更加消瘦： " }, { "title": "对表面着色器中的顶点使用动画", "url": "/game-tech-post-old/posts/%E5%AF%B9%E8%A1%A8%E9%9D%A2%E7%9D%80%E8%89%B2%E5%99%A8%E4%B8%AD%E7%9A%84%E9%A1%B6%E7%82%B9%E4%BD%BF%E7%94%A8%E5%8A%A8%E7%94%BB/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-07-09 00:00:00 +0800", "snippet": "对表面着色器中的顶点使用动画我们现在知道了如何访问每个顶点数据的一些基础知识，这次让我们更进一步的了解一些其他类型的数据和顶点的位置。使用顶点函数，我们可以访问网格中每个顶点位置。具体来说就是可以在着色器处理渲染的过程中，这些函数可以让我们单独对每一个顶点进行修改。这个知识点当中，我们会创建一个着色器，并且用三角函数的正弦函数(sine wave)来修改网格当中的每一个顶点。该技术可以用来创...", "content": "对表面着色器中的顶点使用动画我们现在知道了如何访问每个顶点数据的一些基础知识，这次让我们更进一步的了解一些其他类型的数据和顶点的位置。使用顶点函数，我们可以访问网格中每个顶点位置。具体来说就是可以在着色器处理渲染的过程中，这些函数可以让我们单独对每一个顶点进行修改。这个知识点当中，我们会创建一个着色器，并且用三角函数的正弦函数(sine wave)来修改网格当中的每一个顶点。该技术可以用来创建旗子飘动或者海浪等物体动画。 始前准备 我们把资源都放一块儿，这样方便我们为顶点着色器（ Vertex Shader ）编写代码： 1.创建一个新的场景，并且创建一个平面网格（ plane mesh ），把它放在场景正中央，位置归零。 2.然后创建一个新的材质和着色器。 3.最后，把着色器挂到材质上，在把材质挂到平面网格上。 最终，你的场景看起来应该跟下图一样： 操作步骤 场景创建好后，鼠标双击打开刚刚我们创建的着色器： 1.让我们给着色器的属性块下面的预设值： Properties { _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _tintAmount (\"Tint Amount\", Range(0,1)) = 0.5 _ColorA (\"Color A\", Color) = (1,1,1,1) _ColorB (\"Color B\", Color) = (1,1,1,1) _Speed (\"Wave Speed\", Range(0.1, 80)) = 5 _Frequency (\"Wave Frequency\", Range(0, 5)) = 2 _Amplitude (\"Wave Amplitude\", Range(-1, 1)) = 1 } 2.接下来我们通过下面的声明告诉Unity，我们需要使用顶点函数了，添加声明的位置在： #pragma statement： CGPROGRAM #pragma surface surf Lambert vertex:vert 3.为了访问属性块中的值，我们还要在 CGPROGRAM 块中声明与之对应的变量： sampler2D _MainTex; float4 _ColorA; float4 _ColorB; float _tintAmount; float _Speed; float _Frequency; float _Amplitude; float _OffsetVal; 4.我们也将使用顶点位置的变化作为 vert 颜色。因为这样我们可以顺便修改物体的颜色了： struct Input { float2 uv_MainTex; float3 vertColor; } 5.此时，我们要修改顶点的表现了，我们要使用到下面的正选函数和顶点函数，在我们的 Input Struct 后面添加如下代码： void vert(inout appdata_full v, out Input o) { float time = _Time * _Speed; float waveValueA = sin(time + v.vertex.x * _Frequency) * _Amplitude; v.vertex.xyz = float3(v.vertex.x, v.vertex.y + waveValueA, v.vertex.z); v.normal = normalize(float3(v.normal.x + waveValueA, v.normal.y,v.normal.z)); o.vertColor = float3(waveValueA,waveValueA,waveValueA); } 6.最后，我们要使用一个 lerp() 函数对两个颜色进行一个插值，这样我们就可以对新网格的波峰和波谷应用不同的颜色，为了获得这种表现，添加下面的代码让顶点函数起作用： void surf (Input IN, inout SurfaceOutput o) { half4 c = tex2D (_MainTex, IN.uv_MainTex); float3 tintColor = lerp(_ColorA, _ColorB, IN.vertColor).rgb; o.Albedo = c.rgb * (tintColor * _tintAmount); o.Alpha = c.a; } 当你完成了着色器的编写后，回到Unity并且等待着色器编译完成。当编译完成后，你就会看到如下图所示的情形： 原理介绍 这个特定的着色器使用了我们上个知识点的一些概念，但不同的是，我们这里改变的是网格上那些顶点的位置。有时候你不想用骨骼结构（ skeleton structure ）或者是节点结构（ hierarchy of transforms ）来扣动画， 然后在简单的拼接它们，比如旗帜，在旗子上做动画然后跟旗杆组合拼接成旗帜。这个时候你使用这个着色器就特别有用了。 我们简单的使用了正弦函数 sin() 来创建正弦波，这个函数式Cg语言内建的。当计算好正弦值后，我们把这个值赋值给了每个顶点位置的 y，然后就产生了波动的效果。 当然我们还顺便稍微修改了网格上面的法线，让它针对正弦波有更真实的着色。 从这里你也可以知道，通过利用表面着色器内建的顶点参数，来获得一些比较复杂的顶点效果，还是比较容易的。 " }, { "title": "顶点函数", "url": "/game-tech-post-old/posts/%E9%A1%B6%E7%82%B9%E5%87%BD%E6%95%B0/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2022-06-26 00:00:00 +0800", "snippet": "第五章 顶点函数着色器（shader）这个术语最开始源于Cg领域，它主要用于模拟现实中的光照（阴影）在3D模型中的表现。而如今，着色器的用途远不止上面这些。它不仅可以定义物体的外观表现方式，还可以完全重新定义它们的形状。如果你想学习如何通过着色器来修改3D模型的几何形状，这一章的内容非常适合你。在这一章，你将会学习下面这些知识点： 在表面着色器（Surface Shader）中访问顶点颜色...", "content": "第五章 顶点函数着色器（shader）这个术语最开始源于Cg领域，它主要用于模拟现实中的光照（阴影）在3D模型中的表现。而如今，着色器的用途远不止上面这些。它不仅可以定义物体的外观表现方式，还可以完全重新定义它们的形状。如果你想学习如何通过着色器来修改3D模型的几何形状，这一章的内容非常适合你。在这一章，你将会学习下面这些知识点： 在表面着色器（Surface Shader）中访问顶点颜色 对表面着色器中的顶点使用动画 模型挤压 实现下雪效果着色器 实现范围体爆炸介绍在第一章，创建你的第一个着色器中，我们解释了3D模型不仅仅是一些三角形的集合。每一个顶点都包含了要正确渲染这个模型所必须的一些数据。这一章，为了在着色中能使用这些数据，我们将探索如何访问这些信息。而且我们还将探索如何使用Cg代码对物体进行形变的具体细节。在表面着色器中访问顶点颜色在这个章节，让我们来看看如何在着色器中用顶点函数来访问这些模型的顶点信息。这些知识旨在让我利用模型顶点包含的信息元素来创造一些真正实用的和引人入胜的视觉效果。顶点函数中的顶点能返回一些我们想要的信息。你可以用float3这类值来获得顶点的法线方向信息，顶点的位置信息。你甚至可以将颜色值保存在每个顶点中，并且用float4这类值来返回该颜色。这些将是这个知识点我们将要讲的东西。我们需要理解在表面着色器（Surface Shader）中，如何将颜色信息保存到顶点中以及如何获取这些颜色信息。 始前准备 为了编写这个着色器，我们需要准备一些资源。下面这些步骤是我们创建这个顶点着色器（Vertex Shader）的准备和设置： 1.为了能够看见顶点颜色，我们需要一个顶点设置了颜色的模型。当然你可以用Unity来添加这些颜色，这样的话你不得不编写一个工具来单独的应用这些颜色，或者编写一些脚本来获取刚刚添加的颜色。但是在这里，我们简单的利用Maya 来把颜色应用到我们的模型顶点上。但是现在这个模型你可以在这本书的支持页面获得https://www.packtpub.com/books/content/support【实际上这个地址根本没有这个模型，这本书 的代码我放在这里了本书的代码包】 2.创建一个新的场景，并且把导入的模型放到场景中。 3.创建一个新的着色器和一个新的材质。完成创建后，把着色器添加到材质上，然后把材质添加到模型上。 你的场景看起来应该跟下面的屏幕截图一样： 操作步骤 随着我们的场景，着色器，材质这些创建好后，我们就可以开始为我们的着色器编写代码了。我们在编辑器的Project面板中双击我们创建的Shader打开它。然后跟着下面的步骤走： 1.因为我们创建的着色器很简单，所以在着色器的 属性(Properties) 块中没有必要包含任何属性。但我们仍然需要有一个全局的tint颜色，仅仅是为了跟书中的其他着色器形式上保持一致而已。在着色器的属性块中写入以下代码： Properties { _MainTint(\"Global Color Tint\", Color) = (1,1,1,1) } 2.下面这一步中， 是告诉Unity我们将在着色器中包含一个顶点函数： CGPROGRAM #pragma surface surf Lambert vertex:vert 3.跟往常一样，如果我们在属性块中包含了属性，那么我们要确保在 CGPROGRAM 声明中定义与之对应的变量才行。我们在 #pragma 声明的正下方输入下面的代码: float4 _MainTint; 4.接下来我们要关注 输入结构体（Input struct）。我们还要再定义一个新的变量，主要是给我们的 surf() 方法用，用来接收从 vert() 这个函数中返回的数据： struct Input { float2 uv_MainTex; float4 vertColor; }; 5.现在我们可以来实现 vert() 函数了，这个函数可以访问我们每一个保存在网格中的顶点色： void vert(inout appdata_full v, out Input o) { o.vertColor = v.color; } 6.最后，我们可以使用来自 输入结构体（Input struct）的顶点颜色数据，并且通过内建 SurfaceOutput struct 把数据赋值给 o.Albedo 参数： void surf (Input IN, inout SurfaceOutput o) { o.Albedo = IN.vertColor.rgb * _MainTint.rgb; } 7.随着我们的代码写完，现在我们重新进入我们的Unity编辑器，让着色器的代码编译完。如果一切进展顺利，那么你将会看到如下屏幕截图所展示的一样： 原理介绍 Unity通过着色器给我们提供了访问模型的顶点信息的方法。我们也因此有了修改顶点位置和颜色的能力。在这个知识点中，我们从Maya（你用其他任何一个3D软件也行）中导入了一个网格，网格的顶点颜色被添加到了Verts。 在导入这个模型的时候你可能会注意到，默认的材质并不会显示出顶点颜色来。事实上我们不得不写一个着色器来提取出顶点颜色并且把这些颜色显示在模型的表面。当我们在使用表面着色器的时候，Unity其实给我们提供了大量的内 建函数，让我们在提取顶点信息的时候变得非常的快速和高效。 当我们创建着色器的时候，我们的第一个任务是告诉Unity我们将要使用顶点函数。为了达此目的，我们在 CGPROGRAM 的 #pragma 声明中添加了 vertex:vert 参数。这使得Unity在编译着色器的时候会自动去寻找名为 vert 的顶点函数。如果它没有找到，Unity救护抛出一个编译异常并且会要求你添加一个vert函数到着色器中去。 这才让我们有了下一步。我们需要编写 vert 函数，正如第5步中展示的那样。当有了这个函数后，我们就可以访问内建的 appdata_full 数据结构。这个内建的结构体就是保存顶点信息的地方。然后我们通过 o.vertColor = v.color 这行代码提取到了顶点颜色信息，并且传递给了我们的 输入结构体（Input struct）。 变量 o 表示了我们的 输入结构体（Input struct），然后 v 就是我们的 appdata_full 顶点数据。在这个例子中，我们只是简单的从我们的 appdata_full 结构体中拿到颜色信息并且把这个信息放到我们的 输入结构体（Input struct） 中。一旦这个顶点颜色在我们的 输入结构体（Input struct） 后，我们就可以在 surf() 函数中使用它了。在我们这个知识点的该例子中，我们简单的把颜色赋值给了内建的 表面输出（SurfaceOutput） 结构体的 o.Albedo 参数。 额外内容 我们可以从 vert 颜色数据中获得第四个额外信息。如果你有留意的话，我们在Input struct中定义的这个vertColor变量是一个 float4的类型。也就是说我们也传递了顶点颜色的alpha值。知道这一点后，利用这个优点你就可以通过保存第四个 顶点颜色参数用来实现诸如半透明效果或者通过两张纹理来实现遮罩效果。当然我只是在这里稍微提醒一下，你具体要不要使用顶点颜色的第四个参数还是取决于你和你的产品需求。 通过Unity5，我们有能力为DirectX11编写着色器了。这非常好，但也意味着着色器的编译过程也更加严格了。也就是说在着色器中我们需要添加额外的一行代码来合理的初始化输出的顶点信息。如果你要在你的着色器中使用DirectX11的话，那么代码 应该像下面展示的那样编写： void vert(inout appdata_full v, out Input o) { UNITY_INITIALIZE_OUTPUT(Input, o); o.vertColor = v.color; } 通过添加这么一行代码，你的顶点着色器就不会再抛出类似于“它在DirectX11中可能不会被正确的编译”之类的任何异常了。 " }, { "title": "项目中git要忽略的文件", "url": "/game-tech-post-old/posts/%E9%A1%B9%E7%9B%AE%E4%B8%ADGit%E8%A6%81%E5%BF%BD%E7%95%A5%E7%9A%84%E6%96%87%E4%BB%B6/", "categories": "Git", "tags": "要忽略的文件, Unity, C#", "date": "2022-04-22 00:00:00 +0800", "snippet": "项目中Git要忽略的文件红框框起来的部分即为要忽略的文件 1 Unity项目中 要忽略的文件如下图： 2 Visual Studio项目中 要忽略的文件如下图： ", "content": "项目中Git要忽略的文件红框框起来的部分即为要忽略的文件 1 Unity项目中 要忽略的文件如下图： 2 Visual Studio项目中 要忽略的文件如下图： " }, { "title": "向github中提交大文件(lfs)", "url": "/game-tech-post-old/posts/%E5%90%91GitHub%E4%B8%AD%E6%8F%90%E4%BA%A4%E5%A4%A7%E6%96%87%E4%BB%B6(LFS)/", "categories": "Git", "tags": "LFS, 大文件, GitHub", "date": "2022-04-22 00:00:00 +0800", "snippet": "向GitHub中提交大文件 LFS出于某些原因，我们想向GitHub中提交某些比较大的文件，比如项目中的一些音频视频这样的媒体文件，游戏中的大场景，亦或者只是单纯的想把自己项目的压缩文件上传到GitHub上保管等等。但是GitHub在仓库上有下面的一些限制：先了解一些大小限制条件：仓库总大小： 官方建议小于1G，最大不能超过5G，如果大于1G，会收到官方的警告文件仓库中单个文件大小： 官方建...", "content": "向GitHub中提交大文件 LFS出于某些原因，我们想向GitHub中提交某些比较大的文件，比如项目中的一些音频视频这样的媒体文件，游戏中的大场景，亦或者只是单纯的想把自己项目的压缩文件上传到GitHub上保管等等。但是GitHub在仓库上有下面的一些限制：先了解一些大小限制条件：仓库总大小： 官方建议小于1G，最大不能超过5G，如果大于1G，会收到官方的警告文件仓库中单个文件大小： 官方建议小于50M，最大不超过100M，如果大于50M也会收到警告单个LFS： GitHub最大支持的LFS文件大小是2G，所以如果有单个文件大小大于2G，要用压缩文件分包，每个包大小最好小于或等于1G官方的说明文档https://docs.github.com/cn/repositories/working-with-files/managing-large-files/about-large-files-on-github由于上面的这些限制，所以我们最好还是选择LFS来提交这些文件，由于我是用的不是命令行，是SourceTree，所以这里讲的是用SourceTree提交LFS的步骤。SourceTree中提交LFS的步骤 1.项目初始化 1.首先在GitHub创建一个自己的仓库，并且把它拉取到本地 2.把自己的大文件用 7z 或者 WinRar 之类的软件进行分包，每个大小小于或者等于1G 3.把这些文件复制到本地仓库中，如下图所示： 2.在SourceTree中LFS初始化 在SourceTree中选择 仓库-&gt; Git LFS -&gt; 初始化仓库 接着会弹出窗口，选择 开始使用Git LFS 然后在弹出的窗口中选择添加，在下拉列表中选择合适的扩展名，比如.7z ，然后点确定。 如果是分包，可能扩展名下拉列表中不会有对应的选项，这个时候你可以手动写上去，比如我的.001 这样的分包后的扩展名， 然后再点确定。最后点击窗口的确定按钮，那么这些扩展名就会加入LFS提交 策略中了。之后会在项目中生成一个 .gitattributes 后缀的文件，这个要跟LFS文件一起提交。 3.在SourceTree中选中那些文件【只支持一个一个的选】，右键，然后选择跟踪Git LFS的文件类型 把所有要执行跟踪的LFS文件都执行一遍上面的操作，然后选择这些LFS文件外加一个.gitattributes 文件一起暂存，随后提交。 之所以要这样做，是如果不执行上面的跟踪步骤，在暂存提交的时候会收到警告。 4.用SourceTree推送，第一次可能会有红色警告，没关系，关掉窗口，再点提交按钮，再提交一下就OK了" }, { "title": "C#实现全局的事件管理器", "url": "/game-tech-post-old/posts/C-%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80%E7%9A%84%E4%BA%8B%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8/", "categories": "C#", "tags": "C#, EventManager, 事件管理器, 事件统一管理", "date": "2022-04-21 00:00:00 +0800", "snippet": "C#构建一个全局的事件管理器管理器有两个主要部分组成 1.EventManager 2.DataArgs EventManager类 EventManager 是事件管理器的核心类，采用单例模式实现，有三个主要的成员方法，负责事件的添加，删除和触发。 AddEventListener添加事件 RemoveEventListenter删除事件 ...", "content": "C#构建一个全局的事件管理器管理器有两个主要部分组成 1.EventManager 2.DataArgs EventManager类 EventManager 是事件管理器的核心类，采用单例模式实现，有三个主要的成员方法，负责事件的添加，删除和触发。 AddEventListener添加事件 RemoveEventListenter删除事件 EventFire触发事件事件保存在一个字典eventsDict中, 以事件的名称作为字典的key，Value是一个列表，用来保存要触发执行方法public class EventManager{ private Dictionary&lt;string, List&lt;Action&lt;DataArgs&gt;&gt;&gt; eventsDict = new Dictionary&lt;string, List&lt;Action&lt;DataArgs&gt;&gt;&gt;(); private static EventManager instance = null; public static EventManager Instance { get { if(instance == null) { instance = new EventManager(); } return instance; } } public void AddEventListener(string eventName, Action&lt;DataArgs&gt; func) { if (eventsDict.ContainsKey(eventName) &amp;&amp; eventsDict[eventName].Contains(func)) { Debug.WriteLine(\"event aready exist eventName=\" + eventName + \", func=\" + func.Method.Name); return; } if (!eventsDict.ContainsKey(eventName)) { eventsDict.Add(eventName, new List&lt;Action&lt;DataArgs&gt;&gt;()); } List&lt;Action&lt;DataArgs&gt;&gt; list = eventsDict[eventName]; list.Add(func); } public void RemoveEventListenter(string eventName, Action&lt;DataArgs&gt; func) { if (!eventsDict.ContainsKey(eventName)) { return; } eventsDict[eventName].Remove(func); } public void EventFire(string eventName, DataArgs arg) { if (!eventsDict.ContainsKey(eventName)) { Debug.WriteLine(\"event doesn't add yet! eventName=\" + eventName); return; } List&lt;Action&lt;DataArgs&gt;&gt; list = eventsDict[eventName];\t\tfor (int i = 0; i &lt; list.Count; i++)\t\t{ list[i](arg);\t\t} }}DataArgs 事件传递的参数数据DataArgs 有一个数据字典data用来存放要传的数据，并且暴露了两个方法Set 和 Get 用来设置要传递的数据和获取传过来的数据public class DataArgs{\tprivate Dictionary&lt;string, object&gt; data = new Dictionary&lt;string, object&gt;();\tpublic void Set(string key, object value)\t{\t\tif (data.ContainsKey(key))\t\t{\t\t\tdata[key] = value;\t\t}\t\telse\t\t{ \t\t\tdata.Add(key, value);\t\t}\t}\tpublic object Get(string key)\t{\t\tobject value;\t\tdata.TryGetValue(key, out value);\t\treturn value;\t}}添加一个静态类CommonEvent 来定义事件public static class CommonEvent{ public static string ON_GENERATE_BALL_EVENT = \"ON_GENERATE_BALL\"; public static string ON_RESET_BALLMACHINE_EVENT = \"ON_RESET_BALLMACHINE\"; public static string ON_RANDOM_TICK_EVENT = \"ON_RANDOM_TICK_EVENT\"; public static string ON_GENERATE_BALL_TICK_EVENT = \"ON_GENERATE_BALL_TICK_EVENT\"; public static string ON_GET_RESULT_EVENT = \"ON_GET_RESULT_EVENT\";}用法举例注册事件 1.采用lambda表达式，适合永久监听的事件，因为没有办法移除掉 EventManager.Instance.AddEventListener(CommonEvent.ON_GENERATE_BALL_EVENT, (data) =&gt; { GenerateBall();}); 2.函数传参, 把已有的函数作为参数protected void InitEvents(){ EventManager.Instance.AddEventListener(CommonEvent.ON_RANDOM_TICK_EVENT, this.OnRandomBallTick); EventManager.Instance.AddEventListener(CommonEvent.ON_GENERATE_BALL_TICK_EVENT, this.OnGenerateBallTick); EventManager.Instance.AddEventListener(CommonEvent.ON_GET_RESULT_EVENT, this.OnGetResult);}删除事件protected void Release(){ EventManager.Instance.RemoveEventListenter(CommonEvent.ON_RANDOM_TICK_EVENT, this.OnRandomBallTick); EventManager.Instance.RemoveEventListenter(CommonEvent.ON_GENERATE_BALL_TICK_EVENT, this.OnGenerateBallTick); EventManager.Instance.RemoveEventListenter(CommonEvent.ON_GET_RESULT_EVENT, this.OnGetResult);}触发事件 1.不传参数 EventManager.Instance.EventFire(CommonEvent.ON_GENERATE_BALL_EVENT, null); 2.传参数 DataArgs randomTickData = new DataArgs();//主要是为了避免频繁的new操作randomTickData.Set(\"randomIndex\", randomIndex);randomTickData.Set(\"randomNum\", randomNum);EventManager.Instance.EventFire(CommonEvent.ON_RANDOM_TICK_EVENT, randomTickData); " }, { "title": "范围内获取不重复的随机数", "url": "/game-tech-post-old/posts/%E8%8C%83%E5%9B%B4%E5%86%85%E8%8E%B7%E5%8F%96%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0/", "categories": "算法", "tags": "随机数, 范围内, 不重复, C#", "date": "2022-04-16 00:00:00 +0800", "snippet": "C#范围内生成不重复随机数范围为 [startNum, endNum] , 其中0&lt;=startNum&lt;endNum 。生成的个数为needNum,并且needNum &lt;= endNum - startNum + 1因为C#的Random类不进行种子设置的话是伪随机，所以我们要改进一下Random类的Next方法，让它尽可能朝着真随机靠近。优化后的代码如下： public ...", "content": "C#范围内生成不重复随机数范围为 [startNum, endNum] , 其中0&lt;=startNum&lt;endNum 。生成的个数为needNum,并且needNum &lt;= endNum - startNum + 1因为C#的Random类不进行种子设置的话是伪随机，所以我们要改进一下Random类的Next方法，让它尽可能朝着真随机靠近。优化后的代码如下： public static int Random(int starNum, int endNum) { byte [] randomBytes = new byte[4]; RNGCryptoServiceProvider rngProvider = new RNGCryptoServiceProvider(); rngProvider.GetBytes(randomBytes); Int32 iSeed = BitConverter.ToInt32(randomBytes, 0); Random random = new Random(iSeed); return random.Next(starNum, endNum + 1); } public static bool IsParameterValid(int startNum, int endNum, int needCount) { if (startNum &lt; 0 || endNum &lt;0 || startNum &gt; endNum || needCount == 0 || needCount &gt; endNum - startNum + 1) { return false; } return true; } 方法一 使用两个数组，从第一个数组中随机位置抽取一个，放到第二个数组中，并且在第一个数组中删除这个值， 接下来从第一个数组的剩余数据中重复上面的步骤，直到第二个数组中获得了目标个数的值停止。 代码如下： public static List&lt;int&gt; PickMethod1(int startNum, int endNum, int needCount) { if (!IsParameterValid(startNum, endNum, needCount)) { return null; } List&lt;int&gt; posList = new List&lt;int&gt;(); List&lt;int&gt; newPosList = new List&lt;int&gt;(); for (int i = 0; i &lt;= endNum - startNum; i++) { posList.Add(i); } int count = 0; while (count &lt; needCount) { int pickPos = Random(0, posList.Count -1); newPosList.Add(posList[pickPos]); posList.RemoveAt(pickPos); count++; } return newPosList; } 优点：从剩余的数据中随机取值，不用判断重复，相对于方法二来说速度会更快，特别是needNum 很接近 endNum - startNum + 1的时候，会更加明显 缺点：需要一个额外的数组，需要更多的内存 方法二 使用HashTable，在一个循环中不停地在范围内随机的取值，并且检查检查这个值是否在HashTable中，如果不存在则存放到Hashtable中， 如果存在则重复前面的步骤，直到Hashtable的Count数量达到想要的数量值。 代码如下： public static List&lt;int&gt; PickMethod2(int startNum, int endNum, int needCount) { if (!IsParameterValid(startNum, endNum, needCount)) { return null; } Hashtable tb = new Hashtable(); while (tb.Count &lt; needCount) { int pickPos = Random(0, endNum - startNum); if (!tb.ContainsKey(pickPos)) { tb.Add(pickPos, pickPos); } } List&lt;int&gt; posList = new List&lt;int&gt;(); foreach (int key in tb.Keys) { posList.Add(key); } return posList; } 优点：只需要一个Hashtable就可以解决，节省空间，需要的内存更少，算法也更简洁。 缺点：每次随机获取一个数据，都需要判断是否已存在，这会加大计算量，特别是needNum 很接近 endNum - startNum + 1的时候，会更加明显 完整代码：MathTools.cs" }, { "title": "在unity的hierarchy面板上添加鼠标右键菜单", "url": "/game-tech-post-old/posts/%E5%9C%A8Unity%E7%9A%84Hierarchy%E9%9D%A2%E6%9D%BF%E4%B8%8A%E6%B7%BB%E5%8A%A0%E9%BC%A0%E6%A0%87%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95/", "categories": "UnityEditor", "tags": "Unity, 编辑器, Hierarchy, 右键菜单", "date": "2021-05-25 00:00:00 +0800", "snippet": "在Unity的Hierarchy面板上添加右键菜单这里添加的是复制一个模型的节点信息的功能，从子节点自身开始复制，一直到模型的父节点终止。因为有时候模型的子节点比较多，一个一个的去点开查找比较麻烦，或者想查看子节点的路径对不对。记得priority要写。代码如下：public static class EditorTool{ [MenuItem(\"GameObject/Edito...", "content": "在Unity的Hierarchy面板上添加右键菜单这里添加的是复制一个模型的节点信息的功能，从子节点自身开始复制，一直到模型的父节点终止。因为有时候模型的子节点比较多，一个一个的去点开查找比较麻烦，或者想查看子节点的路径对不对。记得priority要写。代码如下：public static class EditorTool{ [MenuItem(\"GameObject/EditorTool/CopyPath\", priority = 0)] static string CopyPath() { if (Selection.gameObjects.Length == 1) { GameObject selectObj = Selection.gameObjects[0]; StringBuilder pathSB = new StringBuilder(selectObj.name); while (selectObj.transform.parent != null) { pathSB.Insert(0, selectObj.transform.parent.name + \"/\"); selectObj = selectObj.transform.parent.gameObject; } GUIUtility.systemCopyBuffer = pathSB.ToString(); return pathSB.ToString(); } return \"\"; }}" }, { "title": "烘培场景中的光", "url": "/game-tech-post-old/posts/%E7%83%98%E5%9F%B9%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%E5%85%89/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-05-21 00:00:00 +0800", "snippet": "烘培场景中的光渲染光照的过程是非常消耗新能的。即使是目前最好的[state-of-the-art]1GPU，要准确的计算光的运动(light transport) [是指光在物体表面之间反射]也要花好些小时。 为了在游戏中让这个过程可行，光的实时渲染是必须要有的。如今的游戏引擎会在画面和效率上采取一个合理的折中方案；大部分的计算都在一个叫光烘焙(light baking)过程中事先计算好了。...", "content": "烘培场景中的光渲染光照的过程是非常消耗新能的。即使是目前最好的[state-of-the-art]1GPU，要准确的计算光的运动(light transport) [是指光在物体表面之间反射]也要花好些小时。 为了在游戏中让这个过程可行，光的实时渲染是必须要有的。如今的游戏引擎会在画面和效率上采取一个合理的折中方案；大部分的计算都在一个叫光烘焙(light baking)过程中事先计算好了。这一个知识点将会讲解光烘焙是如何工作的并且你该如何充分的利用它。 始前准备 光的烘焙需要你先准备一个场景。里面要有一些几何体，当然光也一定要有。这个知识点我们会基于Unity的标准特性，所以没有必要创建新的着色器或者材质。为了更好的控制这个过程，你可能需要访问Lighting窗口。如果你没有看见这个窗口，可以通过菜单 Window | Lighting打开，并且停靠到一个你方便使用的位置。 操作步骤 光的烘培需要一些自定义的配置。你需要做三个必要的独立步骤。 场景中静态几何体的配置 配置的时候必须按照下面的步骤： 确认好你的场景中所有不会改变位置，大小和材质的游戏物体。一般可能的是建筑物，墙，地形，道具，树木等等。 在场景中选择这些类型的游戏对象，并且在检查器面板(Inspector tab)中勾选Static这个勾选框，就如下图所示。如果任何一个被选择的对象有子对象，Unity编辑器会询问是否想把这些子对象也作为静态对象。如果它们也满足（固定的位置，大小和材质），则在弹出的对话框中选择 是，子对象也变为静态(Yes change children)： 如果想让光照即影响静态游戏对象又影响非静态游戏对象，请确认把Baking属性设置为Mixed。如果只希望影响到静态游戏对象，那么把它设置为Baked。 光探针的设置 在你的游戏场景中有些游戏对象是会移动的，比如主角，敌人和NPC(non-playable characters)。如果它们进入了一个被照亮的静态区域，那么你也许想要放置一些光照探针在他们的周围。为了做到这些，请按下面的操作步骤走： 在编辑器菜单中，依次选择GameObject | Light | Light Probe Group。一个名为光探针组(Light Probe Group)的新游戏对象就出现在检查器面板(Inspector tab)中了。 一旦你选中这个光探针组，八个相互链接球体会出现。点击选中它，并且在场景中移动它，让它尽可能把你的角色会进入的静态区域围起来。 下图展示的就是如何用光照探针把静态的办公区域空间给围起来的例子： 选择会进入光照探针区域的移动游戏对象。 在检查面板(Inspector tab)中，展开渲染组件(renderer component) [通常是网格渲染器(Mesh Renderer)] 并且确认Use Light Probes这个选项被勾选了（如下图所示）： 决定什么时候和什么情况下去使用光照探针是一个很关键的问题；关于此的更详细信息会在原理介绍部分介绍。 光的烘培 请按照下面的步骤进行光照的烘焙： 终于到了烘焙光照了，打开光照(Lighting)窗口并且选择光照贴图面板(Lightmaps tab)。 如果自动(Auto)勾选框勾选了，Unity编辑器将会在后台自动执行烘培过程。如果没有勾选，那就自己点击Build按钮手动烘培。注意即使是为相对较小场景进行光的烘培也可能会花费几个小时。如果你不断移动静态游戏对象或者光线，Unity就会从头开始光的烘培过程，这会让Unity编辑器的运行异常的慢。你可以在通过窗口Lighting | Lightmaps取消勾选Auto的勾选框来阻止Unity自动烘培，这样你就可以手动开始这个烘培过程。 原理介绍 光线的传输是渲染中最复杂的部分。 在这个阶段中，GPU会计算光线是如何在物体之间反射的。 如果一个游戏对象和它所在的光线环境不会变化，那么这个计算可以只计算一次就行了，因为在游戏中它们永远都不会变化。把游戏对象标记为静态(Static)就是告诉Unity可以做上面说的那样的优化。 笼统的讲，光照的烘培是关于静态游戏对象的全局光照的计算过程并且把计算的结果保存在一个叫lightmap的数据文件中。当烘培过程结束后，Lightmaps就可以在Lighting窗口中的Lightmaps页签中找到： 光的烘焙会消耗大量的内存。其实这是给这些静态表面贴上了新的纹理，这些纹理包含了光照信息。让我们想象一下，假如我们有一片森林，森林中所有的树木都共享同一个纹理。当我把这些树木都设置为静态对象，这样每一棵树都会有它独有的纹理【前面共享纹理的一部分】。可想而知，如果不思考而无差别的使用光的烘焙，不仅会增加游戏的大小，还会大量增加内存对纹理的消耗。 在这个知识点中要讲的另一个方面是光探针(Light probing)。光的烘焙可以为静态的几何图形生成质量非常高的光照结果，但是对于运动的物体却不行。如果你的游戏角色正在进入一个静态的区域，那么他看起来跟环境就有种莫名其妙的割裂感。它们的阴影跟周围看起来并不匹配，导致整体的美术表现看起来不尽人意。还有另外一些物体，比如一些带蒙皮的网格渲染器，即使把它们设置为静态物体，它们也不会受到全局光照的影响。所以在实时渲染中使用烘焙光照是不可能的，所以我们需要光照探针这个有效的替代方案。每一个光照探针会在空间中的一个特殊点对全局光照进行采样。而一组光照探针就可以在空间中的多个点采样，这样的话就可以在一个特殊的空间中修改全局光照。这样我们在移动的物体上就可以投射更好的光照表现，即使全局光照仅仅是计算了仅有的几个点。有个很重要的点是记得用这些光照探针把这个特殊的空间包裹起来，这样光照探针才能起作用。最好把这些光照探针放在光照条件经常突然发生变化的区域。和光照贴图一样，光照探针也会增加内存的消耗，同时摆放的位置也要巧妙。记住，它只为非静态图形存在。 尽管我们使用了光照探针，但在Unity的全局光照中我们仍然有些方面没有讲到。比如说非静态物体不能在其他物体上反射光线。 额外内容 你可以从下面的连接中阅读关于光照探针的更多额外内容 http://docs.unity3d.com/Manual/LightProbes.html 注意这并不是指某个具体的GPU，而是指目前位置最好的GPU，参考翻译来自于 state-of-the-art Model，并不是特指某个具体的模型，而是指在该项研究任务中，目前最好/最先进的模型 &#8617; " }, { "title": "Unity 5.x shaders and effects cookbook中文版翻译（第二版）", "url": "/game-tech-post-old/posts/Unity-5.x-Shaders-and-Effects-Cookbook%E4%B8%AD%E6%96%87%E7%89%88%E7%BF%BB%E8%AF%91-%E7%AC%AC%E4%BA%8C%E7%89%88/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-05-21 00:00:00 +0800", "snippet": "​\t\t我打算试着翻译这本技术书，目的又两个，1.希望自己能帮助英文不太好的朋友，2.希望自己也学到这些知识，顺便帮助自己提升英语水平。我英语水平不是很好，接下来如果有什么错误的地方，有看到的朋友还请帮忙纠正。我不会web前端技术，我想试着学学markdown语法，尽量让页面好看些但是最重要的还是内容。Unity 5.x Shaders and Effects Cookbook中文版（第二版）...", "content": "​\t\t我打算试着翻译这本技术书，目的又两个，1.希望自己能帮助英文不太好的朋友，2.希望自己也学到这些知识，顺便帮助自己提升英语水平。我英语水平不是很好，接下来如果有什么错误的地方，有看到的朋友还请帮忙纠正。我不会web前端技术，我想试着学学markdown语法，尽量让页面好看些但是最重要的还是内容。Unity 5.x Shaders and Effects Cookbook中文版（第二版）目录表鸣谢关于作者www.PacktPub.com 电子书, 优惠, 还有其他 为什么需要订阅? 前言 这本书包含哪些内容 学习的过程中你需要准备的 本书的适合人群 内容结构 始前准备 操作步骤 原理介绍 额外内容 相关补充 本书的一些文体说明 读者反馈 客户支持 示例代码下载 本书一些彩图的下载 勘误表 盗版声明 本书有问题请联系 1.创建你的第一个着色器 介绍 创建一个基本的标准着色器 始前准备 操作步骤 原理介绍 额外内容 如何把Unity 4的旧着色器迁移至Unity 5 始前准备 操作步骤 着色器版本的自动升级 使用标准着色器 迁移用户自定义的着色器 原理介绍 额外内容 给着色器添加属性 始前准备 操作步骤 原理介绍 额外内容 使用表面着色器的属性 操作步骤 原理介绍 相关补充 额外内容 2.表面着色器和纹理映射 介绍 漫反射的着色处理 始前准备 操作步骤 原理介绍 使用包组 操作步骤 压缩矩阵 额外内容 向着色器添加纹理 始前准备 操作步骤 原理介绍 相关补充 额外内容 通过改变UV值来移动纹理 始前准备 操作步骤 原理介绍 法线贴图 始前准备 操作步骤 原理介绍 相关补充 创建一个带透明度的材质 始前准备 操作步骤 原理介绍 创建一个有全息效果的着色器 始前准备 操作步骤 原理介绍 相关补充 额外内容 纹理的压缩和混合 始前准备 操作步骤 原理介绍 在地形的表面绘制一个圆 始前准备 操作步骤 在表面移动这个圆 原理介绍 3. 理解光照模型 介绍 创建一个自定义的漫反射光照模型 始前准备 操作步骤 原理介绍 创建一个Toon风格的着色器 始前准备 操作步骤 原理介绍 相关补充 创建一个Phong类型类型的高光反射着色器 始前准备 操作步骤 原理介绍 创建 BlinnPhong 类型的高光反射着色器 始前准备 操作步骤 原理介绍 额外内容 创建各向异性类型的高光反射着色器 始前准备 操作步骤 原理介绍 4.Unity 5中基于物理原理的渲染 介绍 理解金属质感的设置 始前准备 操作步骤 原理介绍 额外内容 向PBR中添加透明度 始前准备 操作步骤 半透明材质 物体如何消失 如何在显示物体中挖一个孔 额外内容 创建镜子和反射面 始前准备 操作步骤 原理介绍 额外内容 烘培场景中的光 始前准备 操作步骤 场景中静态几何体的设置 光探针的设置 光的烘培 原理介绍 额外内容 5.顶点函数 介绍 在表面着色器中访问顶点颜色 始前准备 操作步骤 原理介绍 相关补充 对表面着色器中的顶点使用动画 始前准备 操作步骤 原理介绍 模型挤压 始前准备 操作步骤 原理介绍 相关补充 添加形变纹理 实现下雪效果着色器 始前准备 操作步骤 原理介绍 为物体表面设置颜色 修改几何体 额外内容 实现范围体爆炸 始前准备 操作步骤 原理介绍 相关补充 额外内容 6.片元着色器和抓取通道 介绍 理解顶点和片元着色器 始前准备 操作步骤 原理介绍 相关补充 顶点的输入语义 顶点的输出语义 额外内容 使用抓取通道 始前准备 操作步骤 原理介绍 相关补充 实现一个玻璃效果的着色器 始前准备 操作步骤 原理介绍 相关补充 在2D游戏中实现水效果的着色器 始前准备 操作步骤 原理介绍 7. 移动设备着色器适配 介绍 什么是低成本着色器? 始前准备 操作步骤 原理介绍 着色器的性能分析 始前准备 操作步骤 原理介绍 相关补充 针对移动设备修改着色器 始前准备 操作步骤 原理介绍 8.通过Unity渲染纹理实现屏幕效果 介绍 设置屏幕效果脚本系统 始前准备 操作步骤 原理介绍 相关补充 在屏幕效果中使用亮度, 饱和度和对比度 始前准备 操作步骤 原理介绍 在屏幕效果中使用基础的类Photoshop混合模式 始前准备 操作步骤 原理介绍 相关补充 屏幕效果中的覆盖混合模式 始前准备 操作步骤 原理介绍 9.游戏和屏幕效果 介绍 创建一个老电影屏幕效果 始前准备 操作步骤 原理介绍 额外内容 创建一个夜视仪效果的屏幕效果 始前准备 操作步骤 原理介绍 相关补充 10.更高级的着色器技术 介绍 使用Unity内建的CG包含文件功能 始前准备 操作步骤 原理介绍 CG包含文件功能如何让着色器模块化 始前准备 操作步骤 原理介绍 实现一个毛皮效果的着色器 始前准备 操作步骤 原理介绍 相关补充 如何通过数组来实现热图 始前准备 操作步骤 原理介绍 鸣谢本书作者Alan ZucconiKenneth Lammers审稿Kenneth Lammers组稿编辑Priya Singh策划编辑Rahul NairErol Staveley项目内容编辑Mehvash Fatima技术编辑Pranil PathareDanish Shaikh文字编辑Tasneem Fatehi项目助理Kinjal Bari校对员Safis Editing索引员Monica Ajmera Mehta图像Kirk D’PenhaDisha Haria制作协调员Nilesh Mohite封面设计Nilesh Mohite关于作者Alan Zucconi 是一个充满激情的开发者, 作者, 和一个激励的演讲者, 是开发者领域的佼佼者。 有着过去10年来相关领域的专业技能积累，并且决定在今后把精力都放在学术领域和游戏产业领域。作为一名自由职业者，他以非凡的创造力去探索如何让游戏更好的与艺术结合。 在此之前，他在伦敦帝国理工学院工作，在这里他发现了他教学和写作的激情。 他的头衔包括了 gravity puzzle, 0RBITALIS, 和the upcoming time travel platformer, Still Time（这些单词实在不知道怎么翻译了，应该是游戏名字）.Kenneth Lammers 在游戏领域有超过15年的经验, 担任过角色艺术家，技术美术，技术美术总监，和程序员。这让他有机会参与《使命召唤3》《除暴战警2》 《心灵杀手》和《Kinect星球大战》等众多著名游戏的开发。他现在跟他的商业伙伴Noah Kaarbo一起运营自己的Ozone 工作。，同时，他们也跟亚马逊，Eline Media，IGT和微软也有过合作。他之前为微软游戏工作室，动视和Surreal工作过。现如今他离开了哪些工作室，一手开办了自己的 CreativeTD 和 Ozone 工作室（感觉翻译成互动娱乐更好）。Kenny通过Packt Publishing出版社写了他的第一版 《Unity Shaders and Effects Cookbook》书，整个过程非常的愉快。www.PacktPub.com这是一个电子书的网站，等于是帮这个网站宣传了吧，大家直接点击超链接进去看就行了。一般来说，你只要在上面买了电子书，特别是技术书籍，相关的代码，附件也可以从上面下载。电子书, 优惠折扣, 额外信息**Packt **电子书网站拥有包含pdf和ePub格式的所有已经出版的书籍的电子书。你可以在www.PacktPub.com 更新你的电子书版本并且如果你购买过相应的纸质书籍的话，可以在购买对应的电子版本时享有折扣。你可以通过 customercare@packtpub.com 这个邮箱向我们了解优惠的详细信息。你可以在 www.PacktPub.com 阅读一系列免费的技术文章，现在在网站注册可以获知最新的免费和折扣信息https://www2.packtpub.com/books/subscription/packtlib （告诉大家一个不幸的消息，上面这个网址已经过期了）你是否因为IT技术问题缺乏具体的示例而苦恼，上面这个网站也许可以帮到你，这是一个在线的数字图书馆。你可以在这个数字图书馆上搜索，获取资料和阅读Packt电子书网站为你准备的丰富的电子书。为什么希望你订阅?可以查阅所有 Packt网站发布的的书籍可以拷贝，打印所有书籍可以通过浏览器查找你最需要的资料前言Unity 5.x Shaders and Effects Cookbook这本书能让你在Unity5引擎中创建着色器和特效更加得心应手，能让你入门起来比较容易，学会创建大部分基础的着色器，并且学会如何组织你的着色器代码。本书的章节安排是循序渐进的，每一章节的基础知识，旨在后面让你能实现更高级的技术技巧，比如实现范围体爆炸效果，毛皮特效等。这本书是专门在Unity5这个游戏引擎下讲解的，希望帮助你掌握诸如基于物理原理的渲染和全局光照等知识，让你尽可能获得照片级的效果。在每一章的结尾，你都会获得一些新的技巧，这些技巧有助于提高你的着色器质量并且让你在写着色器的时候更加有效率。 为了让你能从入门到专家，每一个章节的特殊技巧和知识点都是我们为你精心编排的。对于着色器的初学者来说，你也可以通过一个章节一个章节的阅读，逐渐丰富你的着色器知识。不管怎样，通过本书的知识点，可以让你的游戏在次世代看起来更棒。当你完成这本书的学习之后，在Unity3d创建游戏的过程中，你就可以有各种各样的着色器用于你的游戏，并且了解怎么向你的游戏中去添加它们，怎么向你的游戏添加各种特效，怎么去优化你的游戏。让我们开始吧。这本书包含哪些内容第一章,创建你的第一个着色器, 向你介绍如何在unity4和unity5中编写着色器代码（我会试着在unity2018上去实验，保证shader代码的正常执行，不限于unity4和5）。第二章, 表面着色器和贴图映射, 介绍了一些如何实现表面着色器的通用且实用的技术，比如如何给游戏模型使用纹理和法线贴图。第三章, 理解光照模型，带你深入理解在给模型使用着色器时光带来的影响，这一章会教你一些如何实现自定义的光照模型的技术技巧，以便于你去实现一些独特的特效，比如Toon着色器效果。第四章, Unity 5中基于物理原理的渲染, 这一章为你介绍在unity5中基于物理原理的标准渲染技术，这些技术主要是为了在你的游戏中实现次世代的画面（直译就是看起来跟现实世界一样）。会向你解释如何尽可能的模拟这种现实，让你对透明度，反射表面和全局光照有更深入的理解。第五章, 顶点函数,向你介绍如何使用着色器来修改游戏中物体的几何特性；想知道范围体爆炸，着色器模拟下雪等特效嘛？这一章里的着色器操作顶点的技术技巧会告诉你如何实现第六章, 片元着色器和抓取通道, 这一章会解释如何使用半透明材质和抓取通道来实现扭曲形变效果第七章, 移动设备着色器适配，主要介绍如何针对移动设备进行优化。第八章, 通过Unity 渲染纹理实现屏幕效果,介绍了通过该技术才能更容易实现的视觉特效的实现方式。第九章, 游戏和屏幕效果,向你介绍一些游戏后处理特效，让游戏模拟的更加真实，比如夜视仪特效。第十章, 更高级的着色器技术,介绍一些向毛坯特效的着色器，热图渲染等本书会涉及的大部分高级技术技巧学习的过程中你需要准备的下面列举了在学习本书知识的过程中必须的工具软件和可选的工具软件: Unity5引擎 一款3D建模软件，比如Maya，3DMax，或Blender (可选l) 一款2D图片编辑软件，比如PS或者Gimp (可选)本书的适合人群本书适合色器编程初学者，或者想通过专业的后处理特效让游戏更棒的开发者。当然开发者本身需要对Unity游戏引擎有比较深入的理解。内容结构在本书中， 会经常出现一系列的小标题 (始前准备，操作步骤，原理介绍，额外内容 ，相关补充)。主要功能是对每一个知识点进行说明，如何完成该知识点的掌握。下面说明具体的用法： 始前准备 这个部分会告诉你这个知识点会学习什么，怎么安装和设置对应的软件。 操作步骤 这个部分包含了学习该知识点包含那些步骤。 原理介绍 该部分通常是为了详细解释“操作步骤”这个部分的知识原理，上面的每一步到底做了什么。 额外内容 为了让读者了解更多与该知识点相关的额外知识，我们才准备了这个额外信息让读者阅读。 相关补充 如果想了解更多与该知识点相关的信息，这里还额外提供了一些相关链接。 本书的一些文体说明在书中你可以发现很多种不同的文本样式用来表示不同的信息内容。这里列举几个来解释一下。（需要说明一下的是，我在翻译的过程中，代码的字体样式可能会跟书本上不一样，我主要是用markdown的代码块来表示。然后它的粗体，比如强调，那我就用markdown中的强调标签来表示，说声抱歉了，希望大家能看的懂）代码块，数据库表名，文件夹名字 ，文件名字，文件扩展名，路径名称，虚拟URL（觉得这个翻译不准确），用户输入，推特账号等会按照如下表示：“请输入下面的代码到你的着色器属性块（**Properties **）中”void surf (Input IN, inout SurfaceOutput o) { \tfloat4 c; \tc = pow((_EmissiveColor + _AmbientColor), _MySliderValue); \to.Albedo = c.rgb; o.Alpha = c.a;} 当我们想提醒你代码块中的特别部分，那么对应的代码行或者语句会用粗体标记,比如那个void：(代码块中我不知道怎么加粗，下面这个就不用代码块了)void surf (Input IN, inout SurfaceOutputStandard o){​\tfixed4 c = pow((_Color + _AmbientColor), _MySliderValue);​\to.Albedo = c.rgb;​\to.Metallic = _Metallic;​\to.Smoothness = _Glossiness;​\to.Alpha = c.a;}新的术语 和 非常重要的词语 都应该用粗体表示.像出现再电脑屏幕中的菜单和弹窗中的文本，也会用粗体加以强调。比如：“在Unity编辑器的菜单栏中的“项目(Project),在资产(Assets)文件夹上右键单击和在菜单中选择创建(Create)|文件夹(Folder)。” （中文后面括号里的是英文版的编辑器中菜单项的名字）注意(Note)警告或者很重要的注意会像这样，有个注意(Note)提醒你。提示(Tip)提示和小技巧会像这样，有个提示(Tip)提示你。读者反馈非常欢迎来自各位读者的反馈。这能让我们知道你们是否喜欢这本书。你们给与的重要反馈可以让我们写出更适合且对你们更有帮助的内容。通常最简单的反馈方式是通过feedback@packtpub.com邮箱给我们发邮件，然后在反馈邮件的标题中告诉我们书标题。如果在本书中有你擅长领域的话题想跟我们讨论，或者你愿意把你专长领域的知识贡献给本书，也可以通过这个网址 www.packtpub.com/authors的指引进行操作客户支持很高心您能拥有此书，为了让您物有所值，我们还为你准备了很多东西（很搞不懂这也要搞一个章节出来，就一句话）。示例代码下载通过这个网站http://www.packtpub.com，你可以用自己的账号下载本书的实例代码(其实我本人是建议自己手动敲一遍，我试了一下，代码是可以直接在这个网站下载的，就算你没有购买这本书也是可以的。但是需要注册一个账号才行，然后搜索到这本书，这本书的页面下面就有下载代码的链接)。如果你在别的地方购买了这本书，那么你可以浏览网站 http://www.packtpub.com/support注册一个账号，然后在该页面直接通过书名搜索，也能找到这些文件的下载链接。代码文件可以通过下面的步骤获得： 通过邮箱和账号密码在我们的网站上登陆或者注册。 把网页拉到最下面，点击支持主页(Support Home)（这本书出了很久了，网页早就改版了，这是我实际打开网页的操作步骤）。 然后点击该页面左边的代码下载&amp;勘误表(Code Downloads &amp; Errata)。 然后在搜索(Search)框中输入你的书名（不用输入完整的书名，支持模糊搜索）。 选择那本你想要下载代码的书。 然后在下面的下拉菜单中选择你是从哪儿购买本书的（不要紧，随便选一个，然后下拉菜单的下面就会有一个下载链接）。 然后点击代码下载（链接早就生成了，为了方便大家，我贴出链接，点击就可以下载了，不清楚是否是永久链接） 下载好后，请自行解压，然后就可以获得本书的代码了。本书一些彩图的下载这本书中的彩图，比如说屏幕截图/示意图我们都把他放在了一个PDF文件中。希望这些图片可以让你更好的理解屏幕输出图像的变化。 你可以通过下面的链接下载这个PDF文件https://www.packtpub.com/sites/default/files/downloads/Unity5xShadersAndEffectsCookboo勘误表尽管我们非常注意本书内容的准确性，但还是会有不小心出错的地方。如果您在我们出版的书中（不限本书）找到了错误，有可能是文字错误或者代码错误，我们非常欢迎您将这些错误报告给我们。如此善举，既解他人之惑，亦可助改善此书。如果您发现任何勘误，请通过链接https://www.packtpub.com/support/errata （原书写的链接失效了）向我们报告。当您的勘误确认后，您提交的勘误将会被接受并且勘误会上传至我们的网站和任何已存在的勘误名单中。 如果您想看看之前的勘误提交，可以访问https://www.packtpub.com/support/code-downloads（原书的网址失效了，现在是这个），然后输入书名搜索，你想要的信息会出现在下面的勘误部分。盗版声明在网上，所有媒体的版权资料盗版问题从未停歇。 在Packt网，我们非常重视保护我们的版权和许可证。如果你在英特网上看到任何来自我们工作成果的 非法拷贝，不管来自那里，还请你提供给我们地址或者网址，这样我们可以挽回我们的损失。还请通过copyright@packtpub.com邮箱联系我们。我们非常感激您帮助我们保护作者和保护我们继续给你带来有价值的内容。本书有问题请联系如果您对本书有任何层面的问题，您可以通过邮箱questions@packtpub.com联系我们，我们会尽己所能改善这些问题。第一章 创建你的第一个着色器在这一章我们包含了一些在当今游戏开发着色器管线中更通用的漫反射技术基础。在这一章我们将会学习下面的知识点: 创建一个基础的标准着色器 从Unity4迁移旧着色器至Unity5 为着色器添加属性 在表面着色器中使用属性介绍让我在脑海中想象一个完全由白色绘制立方体。尽管立方体的每一个面的颜色都是相同的，但是由于不同方向的光线照射和我们看这个立方体的角度的不同，我们总能发现立方体不同的白色阴影。这种层级的逼真场景就是通过3D图形学中的着色器实现的，它是一种模拟光的作用原理的特别的程序。一个木质的立方体和一个金属的立方体也许可以是同一种3d模型，之所以让他们看起来一个是木质的，一个是金属的，就是因为它们使用了不同的着色器的缘故。我们循序渐进，第一章将会向你介绍如何在Unity中进行着色器编码。如果你从来没有编写着色器的经验，那么在这一章，你将会了解着色器是什么，他们如何工作和如何自定义着色器。 接着在这一章的结尾，你将会学习如何构建拥有基础操作的基础着色器。有了这些知识后，那么你将可以创建任何的表面着色器。创建一个基本的标准着色器每一个Unity游戏开发者应该都对组件(components)这个概念非常熟悉。游戏中的对象都有很多的组件，这些组件决定了游戏中的对象看起来是什么样子和会有什么样的行为。然而游戏脚本(scripts ) 定义的是游戏对象会有怎样的行为，渲染器(renderers )决定游戏对象如何出现在屏幕中。 对于我们想要看到游戏对象类型，Unity本身提供了一些渲染器。每一个3D模型通常都有一个网格渲染器。一个游戏对象应该只能有一个渲染器，但是一个渲染器它可以包含多个材质(materials)。 每个材质封装了一个着色器–3D图形的最后一环。这些组件的关系可以用如下的示意图表示：理解这些组件之间的不同之处对于理解着色器的工作原理是很有必要的 始前准备开始学习这个知识点之前，你需要打开你的Unity5并且创建一个新的项目。本书的内容讲解都会在这个项目中开展，随着学习的深入你之后自己创建的着色器都可以放在这。这一步完成之后—-欢迎来到着色器实时编程的精彩世界。 操作步骤 在创建我们的第一个着色器前，让我们为实验着色器创建一个简单游戏场景。首先我们导航到Unity的菜单栏，然后选择游戏对象|创建空对象。然后在Unity编辑器的层级面板(Hierarchy)选中刚刚创建的空对象，在上面创建一个平面作为地面，再创建几个球体用来应用我们的着色器，然后在场景里面创建平行光源。当场景弄好后，我们接下来就按步骤开始着色器的编写： 在编辑器的项目(Project)窗口中，直接右键选择创建(Create)|文件夹(Folder)。【这里的文件夹名字我就直接用英文了，大家在自己开发的过程中也尽量用有意义的英文文件夹吧】注意如果你导入了本书提供的项目文件（就是你从网站上下载的代码，他是一个unitypackage包，导入之后这个文件自动就有了），你可以直接跳至步骤4。 选择该文件夹，右键然后选择重命名(Rename)，把这个文件夹命名成Shaders。或者你也可以选中该文件夹，然后按F2，重命名为Shaders。 用上面同样的方法创建一个Materials的文件夹，用来放材质文件的。 右键Shaders文件夹，然后在出的窗口中选择创建(Create)|着色器(Shader)|标准表面着色器(Standard Surface Shader)（这里注意跟原文不一样，创建一个着色器要三步，书中只有两部）。接着我们创建一个材质，右键Materials文件夹，然后在弹窗中选择创建(Create)|材质(Material)。 把刚刚创建的着色器和材质都命名成StandardDiffuse。【各位，文件名也用英文呀，因为怕Unity对中文的支持不好】 然后用Visual Studio 2015或者Visual Studio Code打开StandardDiffuse这个着色器【这里我不建议用MonoDevelop这个编辑器，原文是用这个，不好用，强烈建议用各位用Visual Studio Code打开，这个编辑器很好用，一定要去试试】 注意 打开着色器你会发现Unity其实已经为我们的着色器生成了一些基本的代码。这些基础代码给了你一个基础的漫反射着色器，而且可以传入一张纹理。我们会在后面的步骤修改这些着色器代码，创建自己的着色器。 首先我们给自己的着色器一个自定义的文件夹【这不是传统的文件夹，我更倾向理解为材质选择路径】，这样方便使用时可以按照这个文件夹找到它。着色器的第一行代码是一段描述，这段描述的作用是当我们为材质选择着色器时，这段描述会会转换成选择路径，给材质添加我们自己的着色器。我们把这个路径重写为 Shader “CookbookShaders/StandardDiffuse”。当然你也能在任何时间把它命名为任何路径。不用特别在意这个路径名。然后记得保存我们的代码，然后切换回Unity编辑器。当Unity编辑器检测到着色器代码有更新，它会自动重新编译着色器。修改后的着色器代码如下所示： Shader \"CookbookShaders/StandardDiffuse\" { Properties { _Color (\"Color\", Color) = (1,1,1,1) _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _Glossiness (\"Smoothness\", Range(0,1)) = 0.5 _Metallic (\"Metallic\", Range(0,1)) = 0.0 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM // Physically based Standard lighting model, and enable shadows on all light types #pragma surface surf Standard fullforwardshadows // Use shader model 3.0 target, to get nicer looking lighting #pragma target 3.0 sampler2D _MainTex; struct Input { float2 uv_MainTex; }; half _Glossiness; half _Metallic; fixed4 _Color; void surf (Input IN, inout SurfaceOutputStandard o) { // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // Metallic and smoothness come from slider variables o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a; } ENDCG }FallBack \"Diffuse\" } 专业一点说，这是一个基于物理原理渲染(physically-basedrendering)的表面着色器，只是Unity5把它作为了一个内建的标准着色器。根据这种着色器的字面意思，这是一种根据现实中光的物理原理，来模拟游戏中光照射到物体时所表现的物理特性，通过这种模拟，来虚拟现实。 如果你用的时早期版本的着色器（比如Unity4），那么你的着色器代码跟现在的会有比较大的差别。相比于现在的基于物理原理的着色器技术而言，Unity4使用的技术还是相对比较简单的。所有的这些着色器类型我们会在本书后面的章节介绍。 当你的着色器创建好后，我们需要将它与材质关联起来。选中我们之前在步骤4创建的StandardDiffuse材质，然后看检查器面板(Inspector tab)。然后再着色器(Shader)下拉列表中选择CookbookShaders | StandardDiffuse。（如果你在第7步修改的路径跟书上不一样，那么这里的选项也不一样）通过上述步骤，你的着色器就会跟这个材质关联起来，你现在可以把这个材质添加到一个游戏对象中去了。 注意 你可以在项目窗口(Project tab)选中这个材质，然后直接拖拽到你在游戏场景中的游戏对象身上。当然你也可以直接选中这个材质，然后拖拽到Unity编辑器的检查器面板(Inspector tab)上，把这个材质应用到这个游戏对象上，前提是你要先选中这个游戏对象，然后再拖拽，这样检查器面板(Inspector tab)显示的才是游戏对象的属性。 下面时这个示例的屏幕截图：【各位按照自己的情况来就行了，不一定非要找一个跟书本一样的模型】 看起来很简陋, 但是着色器开发环境搭建好了，接下来我们可以开发自己想要的着色器了 原理介绍 Unity帮助你简化了着色器运行的环境配置，你很多时候只需要点击鼠标就可以完成。但事实上这些简单的操作背后有着大量的各种各样的工作，只是Unity引擎替你做了。Unity 使用CG着色器语言，并且它在背后做了大量的工作【unity会自动生成相应的CG代码】，让你在写着色器的时候非常高效。用表面着色器格式的语言来写着色器更加方便。比如处理你自己的纹理的坐标或者线性变换矩阵，这些功能都已经准备好，不用再从头开始。以前写着色器，你必须重新创建一个着色器然后一遍又一遍的重新很多代码。随着你对表面着色器的深入理解，你可能会越想了解CG语言更底层的功能以及Unity是如何处理那些更底层的图形处理单元(graphics processing unit (GPU))任务的。 注意Unity项目中的所有文件都有自己的引用，跟它在你电脑上具体的某个文件夹上没有关系。我们在编辑器上，你可以可以随便移动着色器文件和材质文件，它们之间不会有关联信息丢失的风险。但你千万不要在编辑器外面移动这些文件，【比如直接打开项目文件夹，在电脑上直接移动这些文件】这样的话Unity编辑器不能够更新这些文件之间的关联，可能会发生丢失的情况。 我们通过简单的修改着色器的路径属性可以给着色器一个我们想要的名字，我们在Unity环境中进行了基础的漫反射着色器的研究，包括光呀，阴影呀之类的。而这些，仅仅是通过改变一行代码。 额外内容 在Unity5中内建的着色器的源码通常被隐藏起来了，你不能像打开自己的着色器代码那样打开它。在你的Unity安装目录Unity45\\Editor\\Data\\CGIncludes，你能找到大部分的Unity内建的CG功能代码。在这个目录下面，你能找到被Unity隐藏起来的一些着色器。经过多年的迭代，它们已经发生了很多的改变；如果你想查阅Unity不同版本之间的色器源码发生了那些变化，下面这个网站也许是个好去处：https://unity3d.com/get-unity/download/archive。选择你的Unity版本，然后在下拉列表中选择内建着色器(Built in shaders) ，如下图所示。 此时我们需要留意其中的三个文件—UnityCG.cginc，Lighting.cginc和UnityShaderVariables.cginc。我们现在学习的着色器都只要用到这三个相关的文件： 第十章.更高级的着色器技术, 我们将会深层次探索如何使用GcInclude进行模块化的着色器编程 如何把Unity 4的旧着色器迁移至Unity 5不可否认，在过去10年中图形学在电子游戏中获得了惊人的发展。每一个新游戏带来的尖端技术让我们的游戏画面更加接近现实。随着Unity引擎版本的不断迭代，它的着色器技术也自然而然的经历了相当大的变化。这也是为什第一次接触着色器的时候感到困惑的原因。在Unity5还没有推出之前，Unity自带了两种不同的着色器，分别是：漫反射(Diffuse)和高光反射(Specular)。正如其名字所描述，它们分别用来模拟表面粗糙和表面光滑的材料。如果你现在使用的Unity5，那么你其实可以跳过这个知识点。该知识点会讲解如何在Unity5中重现这些效果。 始前准备 要开始这个知识点，前提时你有个用Unity4版本作为开发引擎工作空间，并且你使用了这个版本内建的一些着色器。当你开发新游戏的时候，毫无疑问你应该改选择最新版本的Unity引擎。然而如果你的项目已经使用了旧版的Unity引擎开发，那么你在迁移着色器前应该三思。引擎背后可能又很多东西都不一样了，即使有时候内建的着色器表面看起来可以正常工作，但是你写的脚本可未必能。所以如果你要迁移整个项目空间，这个时候首先要做的事情就是备份。但是要注意噢，仅仅只是保存Assets资源和场景可不够，同时所有的.meta文件也要一并保存，因为大多数Unity的配置信息保存在元数据中。在迁移项目的过程中最稳妥的办法还是要把整个项目空间所在文件夹都复制一份。最好的是物理拷贝一份，如果是windows就在资源管理器物理复制，如果是Mac就在Finder中物理复制。【建议大家将这个项目目录用压缩工具【如winrar】打包一份】。*** 操作步骤 如果你想要迁移你的内建着色器，有两个主要选择：采用自动升级的方式或者切换至标准着色器 着色器版本的自动升级 这种选择是最操作起来最简单的。Unity5可以导入使用旧版内建着色器的项目并且自动升级。你需要主义的是一旦升级完成后，那么你在Unity4中就不能再使用它们了。尽管这个过程并没有直接改变你的Assets资源，但是Unity的元数据已经被转换过了。要进行这个过程，你需要打开Unity5引擎，然后点击文件(File)|打开项目(Open Project)来打开你就项目所在的文件夹。然后回有提示问你是否愿意转换；然后点击升级(Upgrade)执行改过程。Unity就会重新导入所有的Assets资源并且重新编译所有的游戏脚本。如果你的项目非常巨大，这个过程可能回持续几个小时。一旦转换完成，来自Unity4的内建的旧着色器会被相应的替换掉。 你可以通过检查器面板验证这个转换，材质实例中从原来的Bumped Diffuse变为了Legacy Shader/Bumped Diffuse。 注意 尽管Unity4版本的漫反射，高光反射和其他内建的着色器现在已经已弃用了，但是Unity5依然向后对它们保持兼容。它们在材质的Legacy Shaders路径下的下拉列表中依然可以看到。 使用标准着色器 相比于使用旧版本的着色器，你可能想使用Unity5新的内建标准着色器替代它们。但是这么做之前，请留意新旧两个版本的着色器是基于不同的光照模型的，你的材质很可能看起来不一样。Unity4总共有8个不同的内建着色器，它被划分进了6个大类(法线(Normal)，透明(Transparent)，透明剪切(Transparent Cutout)，自发光(Self-Illuminated)和反射(Reflective))。但在Unity5中，它们都被上一个知识点所讲的那些标准着色器所替代了。不幸的是，没有什么很好的办法能够将旧着色器完美的迁移只新版本的着色器。但是你可以通过下面这个表格着重理解如何通过配置标准着色器去模拟unity4的旧着色器的效果： Shader Unity 4 Unity 4 (Legacy) Unity 5 Diffuse Diffuse Lambert Legacy Shader/Diffuse Lambert Standard Physically-based rendering: Metallic Workflow Specular Specular Blinn-Phong Legacy Shader/Specular Blinn-Phong Standard (Specular setup) Physically-based rendering: Specular Workflow Transparent Specular Blinn-Phong Legacy Shader/Transparent Vertex-Lit Standard Rendering Mode: Transparent Transparent Cutout Vertex-Lit Legacy Shader/Transparent Cutout Vertex-Lit Standard Rendering Mode: Cutout 你可以在旧材质的检查器面板(Inspector)上通过着色器(Shader)下拉菜单改变它所使用的着色器。所有你需要做的就是简单的选择适当的标准材质。如果你的旧着色器使用了纹理，颜色和发现题图，那么在新版本的标准着色器上也会自动使用。当然为了更好的接近之前旧版本着色器的光照模型，你可能需要配置标准着色器的相关参数。 下图展示的是常见的斯坦福兔(Stanford bunny )，它们分别使用旧版本的漫反射着色器(右)，被转换的标准着色器(左)，和把平滑度(Smoothness)设置成0的标准着色器(中)： 迁移用户自定义的着色器 如果你以前在Unity4上有写自定义的着色器，很有可能在Unity5中能直接正常使用。即使如此，Unity也有可能在着色器的工作原理上做了细小的改动，这些改动是可能引发一些错误和不一致性。有个变化最明显的重要参数就是光的强度。 光在Unity5中是原来亮度的两倍。所有的旧版本着色器在重写的的时候都应该考虑到这一点；如果你升级了你的着色器或者切换到标准着色器，你不会发现有任何的不同。但是如果你是自己写的光照模型，那么你就要注意确认光的强度不能再乘以二了。我们就用下面的代码举例来确认这种变化： // Unity 4c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten * 2);// Unity 5c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten); 如果你还没有写过着色器，大可不必惊慌：光照模型会在第三章，理解光照模型 中全面详细的讲解。 注意 Unity5对着色器的处理相比于Unity4来说还有一些其他的变化，你可以下面这个网址中查看所有着色器在Unity5中的处理方式的变化 http://docs.unity3d.com/Manual/UpgradeGuide5-Shaders.html。 原理介绍 着色器的编写需要权衡画面表现和效率；效果逼真的着色器需要极大的计算量，可能导致严重的延迟。所以，有一点很重要，就是只使用我们确切需要的效果：如果一个材质不需要高光反射，那么就不要在着色器中去计算它们。这也是在Unity4中把这些效果拆分成了很多不同着色器的主要原因。 新版本的标准着色器有潜力替换掉先前旧版本的着色器，因为它把法线贴图，透明度和反射都包括在内了。然而，这个标准着色器经过巧妙的优化，使它能够只去计算用到的效果，没用到的效果就不计算。尽管这样，标准着色器主要还是设计用于模拟现实的材质。相比较而言，漫反射和高光反射着色器并不是为模拟现实的材质设计的。 这就是为什么从旧版本的着色器切换到标准着色器时，游戏对象在渲染的时候通常回发生一些细小的变化的原因。 额外内容 第三章， 理解光照模型, 将会深入探索漫反射和高光反射着色器的作用原理。尽管在Unity5中，它们已经被弃用了，但是如果你想要设计新的光照那么理解它们还是有必要的。 第四章，Unity 5中基于物理原理的渲染 ，将会介绍如何在Unity5中展现标准着色器的潜力。 给着色器添加属性着色器的属性对于着色器管线来说时非常重要，因为艺术家或者用户想要添加纹理或者调整着色器的值都是通过著色器的属性来修改的。着色器的属性在材质的检查器面板(Inspector )中会提供GUI，提供图形界面让玩家去调整一个着色器，不用打开额外的编辑器。用Visual Studio Code打开你的着色器代码，从第2行到第7行的代码块就是着色器的属性(Properties )。当前的这个着色器，他会有一个叫_MainTex的属性。如果你查看使用了这个着色器的材质，你能注意到着色器的检查器面板(Inspector )中有一个纹理(texture )的GUI元素。着色器中的这行代码为我们创建了这个GUI元素。还有就是，Unity工作人员通过编码方式和努力的迭代，让你改变属性的这个过程非常快速高效。 始前准备 让我们来了解一下这个过程在标准漫反射(StandardDiffuse)着色器中是如何工作的，为此我们要创建自己的属性并且学习更多相关的着色器语法。比如我们会修改之前创建的着色器。在这个修改的着色器中，不适用纹理，而是仅仅使用能从检查器面板(Inspector)直接修改的颜色和其他的属性。开始之前，我们先复制一个标准漫反射(StandardDiffuse)着色器。你可以在项目(Project)面板中选中它，然后按Ctrl + D。这样就会复制一份新的StandardDiffuse 1的着色器。【书上的写法有问题，在Inspector面板根本不能选中复制，应该在项目面板中选中在复制】注意你最好给你复制的这个着色器在第一行代码处给它一个恰当的名字。比如，Shader “CookbookShaders/StandardDiffuse”可以告诉Unity这个着色器叫StandardDiffuse并且把它分组到CookbookShaders这个着色器组。如果你是通过Ctrl + D复制的着色器，你新复制的这个着色器跟被复制的着色器就会用相同的名字和分组。为了避免混淆，一定要记得复制着色器代码之后，在第一行那里修改着色器的名字，给一个不会重复的名字。 操作步骤 当StandardDiffuse2这个着色器准备好后，我们就可以开始修改它的属性了： 在着色器的属性(Properties )块中，删除着色器中下面的属性代码，整行删除： _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} 当我们移除这个必要的属性后，着色器不会被编译直到所有跟_MainTex的代码都被移除。然我们删除另外有引用的代码： sampler2D _MainTex; 原始的着色器使用_MainTex给游戏模型上色。为了改变这个，我们替换掉surf()方法的第一行代码，通过如下代码： fixed4 c = _Color; 当你修改完成之后，返回Unity，然后着色器会被重新编译， 之后我们的材质检查器面板中就没有纹理选择这一选项了。 为了完成这个着色器的调整，让我们添加一个额外的属性给着色器，看看会有什么效果。输入下面的代码： _AmbientColor (\"Ambient Color\", Color) = (1,1,1,1) 我们在材质的检查器面板中添加了另一个颜色选项。现在，让我们来额外添加另一种类型的属性来找找属性语法的感觉。添加下面的代码到属性代码块中： _MySliderValue (\"This is a Slider\", Range(0,10)) = 2.5 我们创建了其他两种不同类型的GUI元素，它们可以让我们与着色器进行可视化的交互。我们这次创建了一个叫做This is a Slider的滑动条，就如下图所示： 着色器的属性让你可以通过可视化的方式调整着色器，而不用在着色器自己的代码中调整。 下一个知识点将会为你介绍如何利用这些属性创建一些更有趣的着色器。注意尽管属性属于着色器，但是着色器上属性的值却是保存在材质上的。不同的材质可以很安全的共用相同的着色器。从另一方面说，修改材质上的属性的值，将会影响到所有使用了该材质的游戏对象的外观。 原理介绍 每一个Unity的着色器都有它想要的内建的代码结构。属性代码块就是Unity所期望的功能之一。属性代码块的目的是让着色器编程人员能快速的创建GUI交互元素，并且将GUI元素与着色器代码相关联起来。那些你在着色器属性面板中申明的属性，能让你在着色器代码中使用，从而修改着色器中的一些值，颜色和纹理。 定义一个属性的语法[也可以叫语义，也可以叫语法糖]如下： 让我们来解释一下这个示意图。 当你第一次开始写一个新的属性时，你需要给这个书信一个变量名(Variable Name)。这个变量名能让着色器使用并且能让着色器代码获得来自该变量名绑定的GUI元素的值。这给我们节约了大量的时间因为我们不用自己来创建这么一个系统。属性的下一个元素时检查器面板GUI名称( Inspector GUI Name )和属性的类型(Type)，这两个元素放在一对括号中。当玩家想要交互和调整着色器时，检查器面板GUI名称( Inspector GUI Name )将会在材质的检查器面板(Inspector tab)中展示。类型(Type)就是这个属性想要控制的数据类型。在Unity着色器中，有很多属性可以使用的类型。下面这个表展示了我们在着色器中可以使用的变量类型： Surface Shader property types Range (min, max) 创建一个浮点类型的滑动条属性，值从最小值到最大值[min最小值，max最大值] Color 在检查器面板(Inspector tab)中创建一个颜色选取框，当你打开的时候会弹出一个调色板，颜色值(R,G,B,A)[四个浮点数，分别表示红，绿，蓝，透明度] 2D 创建了纹理选取框的GUI元素，可以让玩家通过拖拽的方式给着色器一张纹理 Rect 创建一个非2次幂纹理[NPOT]选取框，功能更2D属性类似 Cube 在检查器面板(Inspector tab)创建一个立方体纹理[大家想想天空盒],可以让玩家拖拽立方体纹理到着色器中 Float 在检查器面板(Inspector tab)中创建一个浮点型的值，但是没有滑动条 Vector 创建一个有四个值的属性，能让你表示方向或者颜色 最后就是这些属性的默认值(Default Value)了。可以在着色器代码中简单的给着色器的属性设置特定的值。在上一个图片属性改成颜色属性的列子中，属性 _AmbientColor的默认值是一个Color类型的默认值，其值为1，1，1，1。这个颜色属性需要一个RGBA或者float4或者r,g,b,a=x,y,z,w赋值。颜色属性第一次创建的时候默认值时白色。 额外内容 着色器属性的文档在Unity手册中的位置在http://docs.unity3d.com/Documentation/Components/SL-Properties.html *** 使用表面着色器的属性现在我们已经为着色器创建了一些属性，这里我们将要正式的把这些属性跟着色器关联起来，这些属性就像着色器的调节器一样，可以让材质拥有更好的交互性。我们可以在材质的检查器面板(Inspector tab)使用着色器属性的值，因为我们为这个属性添加了一个变量名，但是如果你在着色器代码中想要通过这个变量名来获得这个值，我们仍然还有很多事情要做。 操作步骤 下面的步骤展示了如何在表面着色器中使用属性： 开始之前，我们先删除下面的行的代码,就好像我们在章节创建一个基本的标准着色器中删除属性的操作步骤一样，删除_MainTex属性： _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} sampler2D _MainTex; fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; 下一步，添加下面这些行的代码到着色器代码中，添加到CGPROGRAM下面, add the following lines of code to the shader, below the CGPROGRAM line: float4 _AmbientColor;float _MySliderValue; 当第二部完成之后，我们就可以在着色器中使用属性的值了。我们把_Color属性的值与_AmbientColor值相加，并且把两者的结果赋值给o.Albedo。为了达成目的，我们需要在着色器代码中的surf()方法中添加如下代码： void surf (Input IN, inout SurfaceOutputStandard o) { fixed4 c = pow((_Color + _AmbientColor), _MySliderValue); o.Albedo = c.rgb; o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a;} 最终你的代码将会是如下所示。如果你在你的VSCode中保存好然后返回Unity编辑器，你的着色器将会重新编译。 如果没有什么错误，那么现在你可以修改材质的环境光和自发光的颜色，当然也可以通过滑动条增加最终颜色的饱和度。听巧妙的噢。 Shader \"CookbookShaders/StandardDiffuse3\" { // We define Properties in the properties block Properties { _Color (\"Color\", Color) = (1,1,1,1) _AmbientColor(\"Ambient Color\", Color) = (1,1,1,1) _MySliderValue(\"This is a Slider\", Range(0,10)) = 2.5 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 // We need to declare the properties variable type inside of the //CGPROGRAM so we can access its value from the properties block. CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 struct Input { float2 uv_MainTex;}; fixed4 _Color; float4 _AmbientColor; float _MySliderValue; void surf (Input IN, inout SurfaceOutputStandard o) { // We can then use the properties values in our shader fixed4 c = pow((_Color + _AmbientColor), _MySliderValue); o.Albedo = c.rgb; o.Alpha = c.a; } ENDCG } FallBack \"Diffuse\"} 提示下载示例代码你可以在Packt网站登陆后，下载所有已购买书籍的所有示例代码文件，下载地址：http://www.packtpub.com。如果你是在别处购买的书，那么请访问：http://www.packtpub.com/support然后注册，以便通过邮件直接获取相关的代码文件。 注意pow(arg1, arg2)这个方法是内建的，他的功能跟数学的幂函数power是等价的。第一个参数是底数，第二参数是指数 。想了解更深入的了解pow()方法，请去看Cg语言的教程。下面这个网址提供了非常棒的资源，能让你学习更多有关着色器的知识，并且里面有Cg着色器语言的所有函数的表：http://http.developer.nvidia.com/CgTutorial/cg_tutorial_appendix_e.html 下面的屏幕截图展示了通过材质的检查器面板(Inspector tab)来控制材质的属性，从而控制材质的颜色和饱和度： 原理介绍 当你在属性(Properties )代码块中声明一个新的属性时，等于是在材质的检查器面板( Inspector tab)给着色器添加了可以访问调整值[tweaked value]的方式。这个值存储在这个属性的变量名中。在这个例子中，_AmbientColor，_Color 和_MySliderValue这三个变量就是我们用来保存调整值的。为了让你能够在SubShader{} 这个代码块中使用这些值，你需要在这个代码块中对应创建三个变量，而且这三个变量的名字要跟属性代码块中的变量名保持一致。这样的话Unity会自动把SubShader{}代码块和属性代码块中的变量关联起来，然后让着色器知道这些变量使用的是相同的数据。另外，这个属性声明同时也告诉我们在SubShader{}代码块中对应的变量的数据类型，在后续有关着色器的优化相关的章节中，会用到这些。 当你再subshader代码块中创建好变量后，接下来你就可以再surf()方法中使用它们的值。在这个例子中，_Color，_AmbientColor与_MySliderValue这三个变量获得了来自材质的检查器面板(Inspector tab) 对应的值。变量_Color跟变量_AmbientColor这两个值相加，并且把这个值当作底数，_MySliderValue的值当作指数，进行幂运算。 大多数着色器都是从一个标准着色器开始，然后一步一步修改它直到它们符合设计的样子。我们现如的这个例子为以后需要散射组件的表面着色器打好了基础。 注意材质时一种资源(assets)。这意味着，当你的游戏在编辑器中运行时，你对它的任何改变都将会是永久的[这里解释一下，一般在Unity编辑器运行时，你对游戏做的修改，在停止运行后，又会恢复到运行之前的状态，这里材质不一样，修改之后，即使停止运行，它也不会恢复]。如果你不小心错误修改了属性的值，你可以通过快捷键Ctrl + Z取消这个修改。 相关补充 跟其他一些编程语言一样，Cg也是不允许有错误。如果你的着色器代码中有错误的话，着色器将不会起作用。当着色器不起作用时，你的材质会因为没有着色器而以品红的方式渲染： 当一个脚本没有被编译，Unity引擎会禁止你的游戏导出或者运行。 然而，着色器中有错误，Unity并不会阻止你运行你的游戏。如果你的着色器呈现出品红色，那么就应该检查一下到底哪里出现了问题。当你在Unity的编辑器中选中这个报错的着色器，那么你可以在检查器面板(Inspectortab)中看到一大串错误： 尽管错误提示展示了错误所在的行，但是通常不一定是引起错误的正真原因。上一张示例图所展示的错误是因为删除了了SubShader{}代码块中的sampler2D _MainTex变量引起的。 然而报错的地方是试图去访问这个未定义的变量所在的代码行。找到错误并且修复的过程就是我们常说的debug。你最常用的一些错误检查如下： 忘记括号匹配。 如果忘记用花括号对代码块进行配对匹配，那么编译器就会在代码文档的最后，开始或者新的代码块中提示错误。 忘记写分号结束语句。这是最常见的错误，同时也是最容易定位和修复的错误。通常会在下一行开始产生一个错误。 在属性(Properties)代码块中定义了一个属性，但是没有在SubShader{}代码块中定义对应的变量。【这两者是需要成对出现的，也就是说在属性(Properties)块里面定义了一个新的属性，那么在SubShader{}代码块中就需要声明一个与之对应的变量】 更Unity中的C#脚本不一样，Cg语言中的浮点值不需要在后面加f来表示浮点类型：浮点值1.0就写作1.0，而不是1.0f。 着色器中提示的错误很具有误导性，特别是因为它们那严格的语法约束。如果看不懂错误什么意思，那就直接百度或者谷歌。 或者去Unity的论坛搜索一下看看，里面可能就有跟你遇到相同问题（修复了相同问题）的开发者。 额外内容 在第二章，表面着色器和纹理映射，我们会了解如何去掌握表面着色器(Surface Shaders)跟它们的属性(properties )。如果使用着色器的所有潜能和特性，到底能做些什么？如果你对这个问题感兴趣，你应该去看一看第十章，更高级的着色器技术 。里面有本书的一些最高级的着色器技术。 第二章 表面着色器和纹理映射 在这一章节，我们将会探索表面着色器的使用。我们会用一个非常简单的磨砂材质开始讲起，然后会在后面讲解全息投影和高级的地形混合。 我们将能够使用纹理制作动画效果，混合等，或者用着色器去驱动我们想要的属性。在这一章你将会学习下面一些表面着色器的使用方法： 漫反射的着色处理 使用包组 向着色器添加纹理 通过改变UV值来移动纹理 法线贴图 创建一个带透明度的材质 创建一个有全息效果的着色器 纹理的压缩和混合 在地形的表面绘制一个圆 ***介绍我们在第一章，创建你的第一个着色器 已经介绍了表面着色器，这是Unity引擎中的主要着色器类型。在这一章我们将更详细的向你展示它到底是什么以及它具体是如何工作的。通常来说，每个表面着色器都有两个重要的步骤。 首先，你需要在材质中描述你想指定的物理属性，比如漫反射的颜色，光滑度和透明度等。 这些属性将会在一个叫表面函数 surface function的函数中初始化并且保存在一个叫表面输出 surface output的结构体中。其次，表面输出 surface output结构体传入到一个光照模型 lighting model中。这是一个特殊的函数，这个函数会获取场景周围的光照信息。所有获得的这些信息将会被用于去计算你的模型最终在每一个像素点上最终呈现出来的颜色。这个光照函数就是着色器真正进行计算的地方，而正是这部分代码，决定了使用这个着色器材质的光照表现。下面的示意图简单的总结了表面着色器时如何工作的。在第三章，理解光照模型 将探索自定义光照模型，当学习到第五章，顶点函数 会着重讲解顶点修改器：漫反射的着色处理在我们开始学习纹理映射之前，了解漫反射材质时如何工作的显得尤为重要。具体的一些物体也许会有统一的光照和光滑的表面，但是可以还是不够光滑来反射光线。磨砂材质是漫反射着色器使用的一个典型代表 。然而我们现实世界中，完全漫反射材质是不存在的；漫反射着色器是一种成本相对比较低的实现方式并且在低多边形风格中有着大量的应用。 始前准备 有好几种方式来创建你自己的漫反射着色器。最快的一个方式是在Unity5中创建一个表面着色器然后编辑它，移除所有的纹理，跟我们前面学习的第一章，创建你的第一个着色器 类似。 操作步骤 让我们开始创建我们的标准着色器，首先在Unity中新建一个标准着色器，然后按照下面的步骤进行修改： 首先在着色器的属性列表移除除_Color之外的所有属性： _Color (\"Color\", Color) = (1,1,1,1) 在SubShader{}代码块中，移除_MainTex，_Glossiness和_Metallic这三个变量。但是你不能删除uv_MainTex 这个变量，因为Cg着色器语言不允许输入结构体为空。这个值会被Unity简单的忽略。 删除surf()函数内代码内容并且把下面代码放在里面： o.Albedo = _Color.rgb; 最终，你的着色器代码应该如下所示： Shader \"CookbookShaders/Diffuse\" { Properties { Color (\"Color\", Color) = (1,1,1,1) } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 struct Input { float2 uv_MainTex; }; fixed4 _Color; void surf (Input IN, inout SurfaceOutputStandard o) { o.Albedo = _Color.rgb; } ENDCG } FallBack \"Diffuse\"} 当这个着色器从标准着色器修改调整之后，那么这个着色器将会使用基于物理原理的渲染去模拟光在模型表面的表现。如果你想试着获得一个看起来不那么真实表现的话，你可以直接修改#pragma部分，这样着色器就可以使用Lambert而不是Standard。如果你这样修改了的话，那么你还应该用SurfaceOutput替换掉**SurfaceOutputStandard **。按照书上的意思，应该是改成下图所示： 原理介绍 通过表面输出surface output，着色器可以让你材质的渲染属性跟光照模型lighting model进行沟通。 它基本封装了光照模型需要的所有参数。很明显，不同的关照模型肯定有着不同的表面输出结构。下表列出了在Unity中使用的三种主要的输出结构以及它们能如何使用： Type of shaders Unity 4 Unity 5 Diffuse Any Surface Shader:SurfaceOutput Standard:SurfaceOutputStandard Specular Any Surface Shader:SurfaceOutput Standard (Specular setup):SurfaceOutputStandardSpecular 表面输出SurfaceOutput结构体所包含的属性如下： fixed3 Albedo: 材质的漫反射颜色 fixed3 Normal: 空间中法线的切线，如果有法线的话 fixed3 Emission:这是材质指定的光的颜色 （如果是标准着色器Standard Shaders的话，它会被定义为half3类型） fixed Alpha: 这是材质的透明度 half Specular: 这是高光反射度【就是看起来多像高光？】，值的变化是从0到1 fixed Gloss: 这是高光强度 标准表面输出SurfaceOutputStandard结构体包含以下的属性： fixed3 Albedo: 这是材质的基本颜色(不管是高光反射还是漫反射) fixed3 Normal：空间中法线的切线，如果有法线的话 half3 Emission: 跟表面输出结构体一样的意思，不过在这里定义为half3类型，而在表面输出结构体中定义为fixed3类型。 fixed Alpha：同表面输出结构体 half Occlusion: 这个是遮挡（默认是1） half Smoothness: 这个是光滑度 (0 = 粗糙, 1 = 光滑) half Metallic:金属质感 0 = 无金属质感, 1= 金属 标准高光表面输出SurfaceOutputStandardSpecular结构拥有如下属性： fixed3 Albedo：同上 fixed3 Normal：同上 half3 Emission：同上 fixed Alpha：同上 half Occlusion：同上 half Smoothness：同上 fixed3 Specular: 这个是高光反射的颜色，这个跟表面叔叔结构体中的高光反射有很大的不同，因为这里是用颜色表示，而在表面输出结构体中只是一个简单的值 正确的给表面输出结构体赋值，初始化，是使用表面着色器的前提。 使用包组笼统的讲，显示器上每一个像素点都至少会执行一次。这也是为什么GPU要设计高度优化的并行架构的原因。同样的在Cg语言的标准变量类型和操作符中，这种设计哲学也很明显。理解它们，不仅仅是为了正确的使用着色器，同时也是为了能够写出更高效的着色器。 操作步骤 在Cg语言中有两种类型的变量：单精度值single和包组packed arrays。后者很容易辨别因为这种类型通常会以数字结尾，比如float4，int4等等。正如它们的名字所表示的一样，这些类型的变量跟我们编程语言中的结构体structs类似，这也意味着每一个这样的变量包含了多个单精度值。在Cg语言中我们称之为包组packed arrays，尽管它们并非真的是传统意义上的数组。 在包组中的元素能像常见的结构体那样访问。通常它们表示成x，y，z 和w 。然而Cg语言还有另一种表示，就是r，g，b，a。尽管你使用x或者r去表示都是可以的，但是对于代码阅读者来说它们之间的区别就非常的大了。事实上，在着色器编程中，经常涉及到的就是位置和颜色的计算。你可能对下面的标准着色器代码中的代码片段还有印象吧： o.Alpha = _Color.a; 在这里，o是一个结构体而_Color就是一个包组。这也是为什么Cg要禁止上面提到的两种表示进行混用的原因：你不能使用_Color.xgz。 这里还有一个很重要的包组的特性，这种特性在C#中没有：swizzling[这个不知道怎么翻译]。Cg允许仅通过简单的一行代码就对包组内的元素进行寻址和重新排序。又是下面在标准着色器中熟悉的代码片段： o.Albedo = _Color.rgb; Albedo 是一个 fixed3类型，也就是说它里面包含了三个fixed类型的值。 然而_Color 是一个fixed4类型的定义。由于_Color定义包含的元素比 Albedo定义包含的元素要多，直接赋值的话，由于不匹配，肯定会产生一个编译错误。如果用C#代码来进行同样的操作，代码如下所示： o.Albedo.r = _Color.r;o.Albedo.g = _Color.g;o.Albedo.b = _Color.b; 相比于C#代码，在Cg语言中，我们可以用如下代码简写： o.Albedo = _Color.rgb; Cg语言也允许对元素进行重新排序。比如，通过_Color.bgr这个代码去交换红色和蓝色通道的颜色。 最后要讲一点，当一个单精度值赋值给包组时，这个值会被复制到包组的所有元素中去： o.Albedo = 0; // Black =(0,0,0)o.Albedo = 1; // White =(1,1,1) 这个就是Cg语言中的smearing特性。 Swizzling还可以被用作表达式的左值，不过仅当包组的具体元素能被这样使用： o.Albedo.rg = _Color.rg; 上面这种特性，叫做masking. 压缩矩阵真正发挥swizzling特性潜力的是在它应用于压缩矩阵的时候。Cg语言允许像float4x4这种类型，这是一个四行四列的矩阵。你可以使用_mRC标记访问矩阵中的单个元素，R表示元素所在的行而C表示元素所在的列： float4x4 matrix; // ... float first = matrix._m00; float last = matrix._m33;_mRC标记还可以接连使用： float4 diagonal = matrix._m00_m11_m22_m33;如果要获取矩阵的整行，可以使用中括号： float4 firstRow = matrix[0]; // Equivalent to float4 firstRow = matrix._m00_m01_m02_m03; 额外内容 包组是Cg语言中最棒的特性之一，你可以从下面的连接获得关于包组的更多信息： http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter02.html 向着色器添加纹理 通过纹理，可以很容易让着色器变得生动起来，获得非常真实的效果。为了更有效的使用纹理，我们需要了解一张2D图片是如何映射到3D模型中去的。 这个映射的过程称之为纹理映射texture mapping，为了完成映射，我们在使用的模型和着色器上还有额外的工作。模型实际上是由很多的三角形拼接而成的；而三角形的每个顶点都保存有着色器可以访问的各种数据。 其中很重要的一个信息就是UV信息 (UV data)。 它包含两个坐标，U和V，其取值范围是0到1。这两者表示2D图片的像素点坐标的XY位置信息，而这些信息将会映射到顶点中去。 UV数据只为顶点表示[意思可能也等价于：UV数据只存在顶点中]； 当三角内的点需要被纹理映射时，GPU会插值最接近的UV值，从而从相应的纹理中找到正确的像素点。下面的图片展示了一张2D纹理映射到3D模型中的三角形中的情况：UV数据保存在3D模型中并且需要3D模型工具去编辑它们。有些模型缺少UV组件，因而它们不支持纹理映射。比如3D模型软件中的默认的那个兔子模型，就没有提供这么一个组件。 始前准备 学习这个知识点的时候，你需要一个有UV数据和纹理的3D模型。然后把它们都导入到Unity中。也可以直接拖拽到Unity编辑器中，会自动导入。因为标准着色器支持默认的纹理映射。我们会用到这一点，而后会详细的介绍它是如何工作的。 操作步骤 用标准着色器给你的模型添加一张纹理异常的简单，按照下面步骤： 创建一个叫TexturedShader标准着色器。 创建一个名为TexturedMaterial的材质球。 通过拖拽的方式，把着色器赋值给材质，把着色器拖到材质上即可。 选择刚才的材质，然后拖拽模型对应的纹理到一个叫Albedo(RGB)的矩形区域中的空白部分。如果你正确的执行了上述步骤，你的材质检查器面板(Inspector )会如下图所示： 标准着色器知道如何通过UV信息把2D图像映射到3D模型中 . 原理介绍 当通过材质的检查器面板使用标准材质的时候，纹理映射背后的处理过程对于开发者来说是透明的。如果我们想了解它是如何工作的，那我们需要更加详细的了解我们刚才创建的TexturedShader着色器。在着色器的属性Properties部分，我们可以看到Albedo (RGB)的纹理跟代码的关联如下代码所示： MainTex:_MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} 在我们着色器代码中的CGPROGRAM代码块部分，纹理被定义为sampler2D类型，这是一种标准的2D纹理类型： sampler2D _MainTex; 紧接着下一行给我们展示了Input这个结构。这个结构就是surface 函数中得输入参数并且这个结构包含了一个叫做uv_MainTex的包组数组： struct Input {\tfloat2 uv_MainTex;}; 每一次调用surf()函数的时候，对应3D模型中的包含_MainTex **这个UV的Input 结构都需要被渲染。标准着色器会知道uv_MainTex 跟_MainTex **是关联的，并且会自动初始化它。如果你真的很想了解到底UV是怎么从3D模型映射到2D纹理的话，你可以看看第三章, 理解光照模型。 终于，UV数据被用来在**surface **函数中展示成一张纹理： fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; 注意 U和V的取值范围都是从0到1，(0,0)和(1,1)相当于两个相对的角[可以想象成一个是左下角，一个是右上角]。如果你的纹理出现了颠倒的情况，试着把V的值也颠倒就能解决了。 相关补充 当你把纹理导入到Unity的时候，你就会默认设置一些sampler2D类型将要使用的一些属性。 最重要的就是筛选模式Filter mode，它决定了一张纹理显示的时候颜色是如何插值的。跟UV数据会准确的指向像素的正中心非常不同；在一些其他的情况中，你也许想对最近的像素之间进行颜色插值从而获得更一致的颜色。下图是示例纹理在检查器面板Inspector tab的截屏： 对于多数的应用程序来说，双线性Bilinear提供了一种性能消耗低而且高效方法来对纹理进行平滑的处理方式。然而如果你是创建一个2D游戏，双线性Bilinear模式可能会产生模糊块。在这种情况下，你可以使用**点Point **模式来删除来自纹理采样的所有插值。 当以一个很大的倾斜角去观看一张纹理时，贴图采样似乎会呈现一种看起来不舒服的人工制品。你可以通过设置更高的**Aniso Level **的值来减少这种感觉。这一点对地板贴图和天花板贴图特别有用，可以解决一些小瑕疵导致的贴图观感不连续性的问题。 额外内容 如果你想了解更多关于贴图时如何映射到3D模型表面的内部工作原理，你可以通过下面的网址了解相关信息[可能需要用梯子才能访问]： http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter03.html。 如果想了解导入一张2D贴图时完整的可选择项列表，可以通过下面这个相关的网址查询：http://docs.unity3d.com/Manual/class-TextureImporter.html 通过改变UV值来移动贴图在当惊的游戏产业中，一个很常见的游戏贴图技术就是允许你对游戏物体表面的贴图进行滚动。这种技术可以让你创建很多效果，比如瀑布，河流，流动的沿江等等。同时这些技术也是制作动画精灵特效的基础，我们会在这一章节的一系列知识点中来讲解这些内容。 首先，让我们来看看在表面着色器(SurfaceShader)如何创建一个简单的贴图滚动效果。 始前准备 在这个知识点开始之前，需要你创建一个新的着色器文件和材质。这么做的目的是为了有个干净的着色器，然后我们可以更加方便的学习和观看滚动效果。 操作步骤 闲话少说，我们打开刚才创建的的着色器[着色器的名字文章中没有说，就自己取一个启动的名字吧]，然后输入下面每个步骤所展示的代码： 这个着色器需要两个控制贴图滚动的新属性。所以我们添加一个速度属性控制X方向的滚动，添加另一个速度属性控制Y方向的滚动，如下面的代码所示： Properties { _MainTint(\"Diffuse Tint\",Color) = (1,1,1,1) _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _ScrollXSpeed(\"X Scroll Speed\",Range(0,10)) = 2; _ScrollYSpeed(\"Y Scroll Speed\",Range(0,10)) = 2; } 修改CGPROGRAM代码块中的Cg属性中的变量，创建新的变量[把原来的都删掉，用下面展示的代替]，这样我们就能访问来自着色器属性的值了： fixed4 _MainTint;fixed _ScrollXSpeed;fixed _ScrollYSpeed;sampler2D _MainTex; 修改表面函数surface function从而修改传递给tex2D()函数的UV值。然后，使用内建的_Time变量来对UV进行循环播放的动画，这样的话当我们点击Unity中的运行按钮的时候，我们就能看到动画效果了： void surf (Input IN, inout SurfaceOutputStandard o) { // Create a separate variable to store our UVs // before we pass them to the tex2D() function fixed2 scrollUV = IN.uv_MainTex; // Create variables that store the individual x and y // components for the UV's scaled by time fixed xScrollValue = _ScrollXSpeed * _Time; fixed yScrollValue = _ScrollYSpeed * _Time; // Apply the final UV offset scrollUV += fixed2(xScrollValue,yScrollValue); // Apply textures and tint half4 c = tex2D(_MainTex,scrollUV); o.Albedo = c.rgb * _MainTint; o.Alpha = c.a; } 下面的图片中的示例就是利用滚动UV的系统来创建的一个自然环境中河流的动画，你可以注意到场景中叫ScrollingUVs的特效就是来自于本书提供的代码： 原理介绍 这个贴图滚动的着色器中，定义了一系列的属性，这些属性允许玩家增加或者减少滚动效果的速度。这里的关键点是，来自材质的检查器面板Inspector tab的一些浮点值会输入到着色器的表面函数surface function中去。如果你想了解属性的更多信息，可以去看第一章，创建你的第一个着色器 。 一旦我们获得了来自材质检查器面板Inspector这些浮点值后，我们就可以在着色器中利用它们来对UV值进行偏移修改。 但是在此之前，我们首先把UV值保存在了一个叫做scrolledUV的独立变量中。这个变量需要是float2/fixed2类型，因为从Input结构传过来给我们的UV值是下面这样的： struct Input{\tfloat2 uv_MainTex;} 一旦拿到了游戏网格的UV，我们就可以用我们的滚动速度和着色器内建的_Time变量偏移修改它们。这个内建的变量会返回float4类型的变量，也就是说这个变量的每一个部分都包含了不同的时间值，这个时间来自游戏内的时间。 关于这个独特的时间值，可以通过下面的链接查看它的完整描述： https://docs.unity3d.com/Manual/SL-UnityShaderVariables.html 这个_Time变量根据Unity的游戏时钟增量过的浮点值。所以我们能使用这个值，根据UV的两个方向移动我们的UV，并且根据我们的滚动速度对这个时间进行缩放： // Create variables that store the individual x and y// components for the uv's scaled by timefixed xScrollValue = _ScrollXSpeed * _Time;fixed yScrollValue = _ScrollYSpeed * _Time; 通过时间算出了正确的UV偏移量，接着就可以添加新的偏移量的值到原来的UV位置中去。这也是我们为什么在下一行要用+=操作符的原因。我们想要拿到原来的UV位置，对这个位置加上新的偏移量，然后再把这个值传给tex2D()这个函数作为贴图的新UV。这个过程让我们创建了贴图在游戏对象表面移动的效果。 表面上来看，我们的效果好像在移动贴图，但实际上我们是在修改UV而已： scrolledUV += fixed2(xScrollValue, yScrollValue);half4 c = tex2D (_MainTex, scrolledUV); 法线贴图3D模型的每一个三角面都有一个朝向facing direction，这个朝向就是它向前的指向。它通常用一个垂直并且放置在三角面正中心的一个箭头来表示。这个朝向对于光在表面反射中来说非常的重要。如果相邻的两个三角面朝向不同的方向，那么它们对光的反射也会朝向不同的角度，也就是在着色器中它们的处理方式会不一样。对于曲面物体来说，这里有个疑问：很显然这些拥有曲面的几何体仍然是由平面三角形构成的，那光线改如何处理？为了避免这个问题，对应三角面的光的反射计算方式此时不根据它的朝向计算，而是根据它的法线方向normal direction方向计算。前面向着色器添加纹理那个知识点讲到，顶点是保存有数据的。法线方向信息也是继UV信息之后，保存在顶点中最有用的信息。这是一个单位长度的向量，并且它表示了顶点的朝向。不考虑朝向的话，那么三角面内的每一个顶点都有它自己的法线方向，只不过这个法线方向是一个存储在顶点中的线性插值。这给了我们用低模模拟高模的能力。下面示例图展示了同一个几何形状在不同的顶点插值密度下的表现。在左边，法线垂直于由顶点表示的面；很明显每个面之间有明显的的割裂感。再看看最右边的几何体，它的法线是通过他的面线性插值得到的，可以看出来的是，尽管它的表面看起来还是很粗糙，但是光线的反射看起来却似乎很光滑。很容易看出来尽管这三个物体的几何体都相同，但是它们的光线反射却不一样。尽管都是由平面三角形构成，但是右边物体的光线反射似乎看起来像曲面反射。一个有着粗糙的边的光滑物体很明显的表示单位顶点的法线肯定进行了线性插值。如果我们对保存在每个顶点的法线按其方向进行绘制，我们就能够看到它们，正如下图所展示的那样。你应该注意的是每个三角形仅有三条法线，但是相连的三角形有相同的顶点，会看到不止有一条法线从中绘制出来。法线贴图在计算3D模型的法线技术中脱颖而出。跟纹理贴图类似，法线方向也可以用一张额外的纹理表示，我们把它们叫做法线贴图normal map或者凹凸贴图bump map。 法线贴图通常是一张RGB图片，里面的RGB通常分别用来表示法线方向中的X，Y，Z方向。现在有很多种技术方法来创建一张法线贴图。比如这些应用程序，CrazyBump(http://www.crazybump.com/)跟NDO Painter(http://www.crazybump.com/)可以把2D数据转换成法线数据。其他的应用程序比如Zbrush 4R7(http://www.pixologic.com/)和AUTODESK(http://usa.autodesk.com)可以把雕刻数据转换成法线贴图。如何创建法线贴图完全超出了本书的范畴，但上面的内容对你了解相关相应的知识还是有好处的。在Unity中向着色器添加法线的过程很简单，因为在表面着色器中有着UnpackNormals()这样的方法给你调用。就让我们看看这是怎样的一个过程。 始前准备 分别创建一个新的材质和着色器，并且把它设置到场景视图Scene view中的游戏对象中去。这样的话，我们的项目非常简单，好让我们仅仅是观察法线贴图这项技术。 这个知识点中你需要一张法线贴图，但是我们这本书附带的Unity工程中包含了一张。[当然，你也可以从我这里把这张图片下载下来，如下图] 操作步骤 下面就是创建法线贴图着色器的步骤了： 让我们设置好我们的属性块，从而可以获得颜色和贴图： Properties{\t_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)\t_NormalTex (\"Normal Map\", 2D) = \"bump\" {}} 注意 因为用的是bump来初始化了属性的贴图类型，这等于是告诉了Unity_NormalTex包含了法线贴图。如果这个贴图没有被设置， 那么会默认给它设置一张灰色的贴图。颜色值会用(0.5,0.5,0.5,1)，然后看不出一点凹凸感。 在CGPROGRAM下面的SubShader{}块中声明下面两个变量，让这两个变量跟属性块中的两个属性关联起来： CPROGRAM#pragma surface surf Lambert// Link the property to the CG programsampler2D _NormalTex;float4 _MainTint; 我们需要修改输入结构体Input struct的名字，从而让我们可以让我们通过模型的UV来访问法线贴图： // Make sure you get the UVs for the texture in the structstruct Input{\tfloat2 uv_NormalTex;} 最后，我们通过内建的UnpackNormal()函数从法线贴图中提取出我们需要的法线信息。接着，你只要把这些新的法线应用到表面着色器的输出上即可： // Get the normal data out of the normal map texture// using the UnpackNormal functionfloat3 normalMap = UnpackNormal(tex2D(_NormalTex, IN.uv_NormalTex));// Apply the new normal to the lighting modelo.Normal = normalMap.rgb; 下图展示了我们的法线贴图着色器的最终效果： 注意 着色器可以同时拥有纹理贴图和法线贴图。用UV数据同时来关联这两种贴图并不少见。然而，也可以在特有的顶点数据(UV2)中提供第二个UV的参数设置来设置法线贴图。 原理介绍 法线贴图效果背后的数学原理完全超出了本书的范畴，不过Unity已经为我们做了这一切。由于Unity为我们创建了各种方法所以我们不用一遍又一遍的做重复劳动。这也是为什么说表面着色器是编写着色器代码的高效方式的另一个原因。 如果你在Unity的安装文件夹下的Data文件夹下的UnityCG.cginc文件中查找的话，你可以找到UnpackNormal()这个函数的定义。当你在表面着色器声明这个函数的时候，Unity会通过提供给它的法线贴图进行处理并且返回给你正确类型的数据，这样你就可以逐像素光照函数中使用它们。这为你节约了大量的时间！当对一张纹理[法线贴图]进行采样时，你可以获得从0到1取值范围的RGB值；然而，法线方向向量的取值范围确实-1到1。通过UnpackNormal()函数就可以给法线方向向量获取合理的值。 当你通过UnpackNormal()函数对法线贴图进行了处理后，你把处理后的结果返回给了SurfaceOutput结构体，这样你才能在光照函数中使用它们。这是通过着色器中o.Normal = normalMap.rgb;这条语句实现的。我们会在第三章理解光照模型这一章中会看，法线究竟是怎么用于计算每一个像素点最终颜色的。 相关补充 你也可以在你的法线贴图着色器中添加一些控制从而可以让用户修改法线贴图的强度。这一点很容易通过改变法线贴图变量的x和y元素然后把它们全部返回来办到。在法线贴图着色器中的属性块中添加另一个属性，名称为NormalMapIntensity： _NormalMapIntensity(\"Normal intensity\", Range(0,1)) = 1 把解包出来的法线贴图数据的x和y都乘以这个属性然后把这个得到的新的值返回给法线贴图变量： fixed3 n = UnpackNormal(tex2D(_BumpTex, IN.uv_ uv_MainTex)).rgb;n.x *= _NormalMapIntensity;n.y *= _NormalMapIntensity;o.Normal = normalize(n); 注意 法线向量的长度最好是等于1。当它们乘以_NormalMapIntensity后会改变它们的长度，所以对它进行标准化[归一化]是很有必要的。 现在你可以让使用者在材质的检查器面板Inspector tab修改法线贴图的强度了。 下图为我们展示了法线贴图在不同强度参数下的不同表现： 创建一个带透明度的材质到目前为止我们所看到的着色器似乎都有一个共同点——它们都用于了固体材质。如果你想要的提升你的游戏的视觉效果，那么带透明度的材质通常是一个好的开始。它们用途广泛，从火焰效果到窗户的玻璃都会用到它们。但稍微麻烦的是，它们用起来要复杂一点点。在渲染固体模型之前，Unity会根据它们离摄像机的距离(这个叫Z ordering)进行排序，并且跳过渲染所有背朝摄像机的三角面(这个是剔除技术culling)。当渲染带透明度的几何物体时，这些含有两个面的几何物体就会产生问题。这次的知识点将会为你展示：当我们创建有透明度的表面着色器时，我们如何解决这个过程中产生的这些问题。我们在第六章,片元着色器和抓取通道我们还会着重回顾这个话题，真实渲染中的玻璃和水体着色器都会涉及到。 始前准备 这个知识点需要一个新的着色器，我们就叫它Transparent吧。同时也需要一个新的材质，这样才能把着色器应用于游戏物体。因为这个物体需要成为一个透明的玻璃窗，那么我们最好用Unity中的quad或者plane来做。我们当然也需要一些不透明的其他游戏对象来对比测试效果。在这个例子中，我们会使用一张PNG图片作为玻璃纹理。这张图片的alpha通道将会用于控制玻璃的透明度。这样的PNG图片大家自行自作，软件不限。但是需要遵守下面的这些步骤： 找一张要用于你窗户玻璃的图片。 用照片编辑软件打开这样图片，比如GIMP或者Photoshop。 选择图片中你想要变成半透明的部分。 在这张图片上创建一个空白(full opacity[抱歉我不懂PS，不知道这个参数的含义])图层 选择上一步创建的图片，以黑色来填充这个图层。 保存图片然后导入到Unity中。 这个知识点中，我们用来试验的图片是一张来自圣斯德望主教座堂 Meaux Cathedral in France(https://en.wikipedia.org/wiki/Stained_glass)的花窗玻璃。 如果遵循了上面的图片制作步骤，那么你也会获得如下类似的一张图片（RGB通道在左图，A通道在右图）： 操作步骤 正如我们前面提醒的，我们在使用透明度着色器时需要注意几个方面： 在着色器的SubShader{}代码块中，添加下面的标签告知着色器这是用于透明度的： Tags{\t\"Queue\" = \"Transparent\"\t\"IgnoreProjector\" = \"True\"\t\"RenderType\" = \"Transparent\"} 由于这个着色器是为2D 材料设计的，所以确保你的模型的背面不会被绘制，通过添加下面的这个代码： Cull Back 告诉着色器这个材料是半透明的并且需要跟屏幕中绘制的什么内容混合： #pragma surface surf Standard alpha:fade 使用这个表面着色器来决定玻璃的颜色和透明度： void surf(Input IN, inout SurfaceOutputStandard o){\tfloat4 c = tex2D(_MainTex, IN.uv_MainTex) * _Color;\to.Albedo = c.rgb;\to.Alpha = c.a;} 原理介绍 这个着色器中介绍了几个新的概念。首先，标签Tags用于添加一些关于游戏对象是如何渲染的信息。但是这次这里真正让人感兴趣的是Queue。Unity默认会根据物体距离摄像机的距离来对游戏对象进行排序。所以当一个物体距离摄像机越近，那么它就会比所有离摄像机更远的物体先绘制。在大多数情况下，它对游戏来说都没有问题，但是有些情况下你可能想要自己控制游戏场景中物体的渲染顺序。Unity已经有提供给我们一些默认的渲染队列，每一个队列都有一个单独的值好让Unity按照这个顺序在屏幕中绘制游戏物体。这些内建的渲染队列分别叫做[这些参数就不翻译了] Background，Geometry，AlphaTest，Transparent， 和 Overlay。 这些队列并不是随意创建的；创造它们是为了让我们能更容易的编写着色器代码和跟实时渲染进行交互。下表描述了每一个不同的渲染队列的作用： 渲染队列 队列描述 渲染队列值 Background 这个渲染队列最先渲染。它被用于天空盒等等。 1000 Geometry 这个是默认的渲染队列。大多数游戏对象都用这个 。不透明物体使用这个队列。 2000 AlphaTest Alpha-tested几何体使用这个队列。跟 Geometry队列不同的是在所有的固态物体都被渲染的情况下，它在渲染alpha-tested游戏对象上效率更高。 2450 Transparent 这个队列在Geometry队列和AlphaTest队列之后，并且是由后向前渲染顺序。任何的alpha渲染（着色器不会写入深度buffer）都应该在这个队列，比如玻璃效果和例子效果。 3000 Overlay 这个渲染队列是为叠加效果准备的。所有在最后渲染的东西都用此队列，比如镜头光晕。 4000 所以，一旦你知道你的游戏对象属于哪个渲染队列后，那么你就可以给它设置渲染队列。我们这次的着色器用到了Transparent队列，所以我们在代码中用到了Tags{“Queue”=”Trasparent”}.这样的标签。 注意 事实上Transparent队列在Geometry队列后渲染并不是意味着玻璃会出现在其他所有固态物体的上面。Unity会在最后再绘制玻璃，同时也并不会渲染任何一个被其他物体遮住部分的游戏对象的像素点。这样的控制可以用一种叫ZBuffering的技术实现。更多关于模型是如何被渲染的资料可以在下面的链接找到： http://docs.unity3d.com/Manual/SLCullAndDepth.html。 标签IgnoreProjector可以让这个游戏对象不受Unity的投影的影响。最后，RenderType扮演了一个着色器替换的角色，这个话题在 第九章，游戏和屏幕效果中会简略的谈一下这个话题。 最后一个要介绍的概念就是alpha:fade。这表示这个材质中的所有像素点会根据它们的alpha值决定必须要先跟屏幕中的什么物体混合渲染。如果没有用这个指明的话，像素会按照正确的顺序绘制，但是它们不会有任何的透明度。 创建一个有全息效果的着色器近些年来太空主题的发行的越来越多。科幻游戏中很重要的一个部分就是在游戏中集合了来自未来的各种技术。全息投影就是其中的典型代表。全息投影尽管有很多种形式，但是通常用一种半透明，看起来很薄的投影来呈现。这次的这个知识点将会向你展示如何创建一个这样的着色器来模拟这样的效果。我们首先想到：要创建一个优秀的全息投影特效，你需要能够添加噪音，扫描动画和和震动。下图就展示了一个全息投影效果的列子： 始前准备 正如全息投影效果展示的知识物体的轮廓，所以我们可以把我们的这个着色器命名成Silhouette[轮廓的意思]。把它跟材质关联起来并且把它应用到你的3D模型中去。 操作步骤 根据下面的步骤可以将我们的当前的着色器修改为有全息投影效果的着色器： 在着色器中添加下面的属性： _DotProduct(\"Rim effect\", Range(-1,1)) = 0.25 并且添加跟属性对应的变量到CGPROGRAM块中去： float _DotProduct; 因为这个材质是有透明度的，所以需要添加下面的标签： Tags{\t\"Queue\" = \"Transparent\"\t\"IgnoreProjector\" = \"True\"\t\"RenderType\" = \"Transparent\"} 注意 根据你将会使用的游戏对象类型，你可能想要它的背面也能看到。如果是这种情况，那么我们就需要在代码中添加Cull Off，从而让模型的背面不会被剔除。 这个着色器并不会尝试去模拟真实世界的材质，所以这里就没有必要再使用PBR关照模型了。我们将会用性能消耗更少的Lambertian 反射来代替它。另外，我们应该使用nolighting来关闭所有的光线并且用alpha:fade来告诉Cg我们得着色器是一个有透明度的着色器： #pragma surface surf Lambert alpha:fade nolighting 修改输入结构体从而能让Unity输入当前的视口方向和世界的法线方向： struct Input{\tfloat2 uv_MainTex;\tfloat3 worldNormal;\tfloat3 viewDir;}; 修改你的表面函数surface function成下面的样子。请记住因为这个着色器使用Lambertian反射作为光照函数，所以表面输出结构体的名字也要相应改成SurfaeOutput，这是SurfaceOutputStandard类型的实例。 void surf(Input IN, inout SurfaceOutput o){\tfloat4 c = tex2D(_MainTex, IN.uv_MainTex) * _Color;\to.Albedo = c.rgb;\tfloat border = 1 - (abs(dot(IN.viewDir, IN.worldNormal)));\tfloat alpha = (border * (1 - _DotProduct) + _DotProduct);\to.Alpha = c.a * alpha;} 现在你可以使用Rim effect这个滑动条来选择全息投影效果的强度。 原理介绍 正如前面提到的，这个着色器仅仅是展示了物体的轮廓。如果我们从不同的角度看这个物体，它的轮廓也会改变。从几何学的角度上讲，模型的所有边都包含在法线方向normal direction垂直于视口方向view direction的三角形上。输入结构体Input structure声明了这些变量，分别是worldNormal和viewDir这两个参数。 要知道两个向量是否垂直可以用点积dot product进行判断。她是一个操作符，接收两个向量作为参数，如果这两个向量垂直，会返回零。我们使用参数DotProduct来控制点积趋近于零的程度从而控制那些三角形应该完全消失。 这个着色器的另一方面，我们用了_DotProduct(不可见)来确定模型的边（完全可见）和角度之间消失的力度。这个线性插值是通过下面的代码实现的： float alpha = (border * (1 - _DotProduct) + _DotProduct); 最后，贴图原来的alpha值乘以一个计算好的系数后，我们获得了最终的样子。 相关补充 这种技术非常的简单并且性能消耗相对较低。不过这种着色器还可以用于其他的各种各样的特效，比如下面的这些： 科幻游戏中包裹星球的浅色大气层 被选中的游戏物体的边或者当前鼠标下的物体 鬼魂或者幽灵 引擎冒出的烟 爆炸的冲击波 太空战舰被攻击时的防护罩 额外内容 在反射计算中向量的点积dot product扮演着非常重要的角色。我们在 第三章，理解光照模型 这个章节中会详细的介绍它是如何工作的以及为什么会广泛的用于很多的着色器中。 纹理的压缩和混合纹理的作用并不仅仅只是我们通常认为的保存加载的数据或者像素颜色，同时还有像素点在x和y方向以及RGBA通道的各种设置。我们能把多张图片压缩进一张单独的RGBA纹理中并且使用它们各自的R，G，B和A元素，因为我们可以在着色器中把它们各自纹理中的这些元素分别解压出来。将各自的灰度图压缩进一张单独的RGBA纹理的结果可以通过下图看出来：为什么说这会有用呢？在你的应用程序实际消耗的大部分中内存当中，贴图占了很大的一部分。所以如果你想要减少应用程序的大小的话，我们能在着色器中查看所有使用的图片并且想想我们是否能将这些纹理合并到一张单独的纹理中。任何灰度的纹理都可以压缩进另一张有RGBA通道的纹理。第一次听起来可能有点怪怪的，但我们接下来会用这个知识点来演示纹理压缩的用法并且在我们的着色器中使用这张压缩过的纹理。举其中一个纹理压缩用法例子，比如你想把一套纹理[有好几张]混合进一张单独的纹理中。这在地形类着色器中很常见，在我们的例子中，我们会用一些排好序的控制纹理或者压缩过的纹理，很好的混合进另一张纹理中。这个知识点会讲到这个技术的，同时还会告诉你如何开始编写好这样一个混合四张纹理的着色器。 始前准备 在我们Unity的着色器文件夹中创建一个新的着色器同时创建一个新的材质与之对应。这两者的命名怎么方便怎么来，不过尽量保证组织和引用方便吧。 建好着色器和材质后，再创建一个新的场景，好给后面做测试。 收集好四张你打算混合在一起的纹理。我们直接用它们展示这几张纹理是如何放到物体表面的。 我们可以用一些非常复杂的混合纹理在地形网格上创建一个非常真实的地形分布纹理，如下所示： 操作步骤 我们通过下面代码来学习如何使用压缩纹理。 我们在着色器的属性Properties块中添加一些属性。我们需要5个sampler2D类型的游戏对象或纹理，2个颜色属性： Properties{_ MainTint (\"Diffuse Tint\", Color) = (1,1,1,1) //Add the properties below so we can input all of our textures _ColorA (\"Terrain Color A\", Color) = (1,1,1,1) _ColorB (\"Terrain Color B\", Color) = (1,1,1,1) _RTexture (\"Red Channel Texture\", 2D) = \"\"{} _GTexture (\"Green Channel Texture\", 2D) = \"\"{} _BTexture (\"Blue Channel Texture\", 2D) = \"\"{} _ATexture (\"Alpha Channel Texture\", 2D) = \"\"{} _BlendTex (\"Blend Texture\", 2D) = \"\"{}} 接下来我们在SubShader{}块中创建一些变量，记住要跟上一步的属性块对应。 CGPROGRAM#pragma surface surf Lambert float4 _MainTint;float4 _ColorA; float4 _ColorB;sampler2D _RTexture;sampler2D _GTexture;sampler2D _BTexture;sampler2D _BlendTex;sampler2D _ATexture; 我们现在获得了纹理属性后把它们传递给SubShader{}函数。为了能够让使用者可以控制每个纹理的截取比例，我们需要修改输入结构体Input struct。这样我们就可以使用每个纹理的截取和偏移量等参数: struct Input{ float2 uv_RTexture; float2 uv_GTexture; float2 uv_BTexture; float2 uv_ATexture; float2 uv_BlendTex;}; 注意[译者添加] 如果遇到Too many texture interpolators would be used for ForwardBase pass错误，因为是Input中定义的材质uv变量太多了，当前版本的shader model不支持造成。此时将shader model改为更高的版本可以解决。如果你的#pragma target 3.0不支持3个材质，可以改为#pragma target 4.0试试吧。 如果非要用#pragma target 3.0，只能通过共用uv_MainTex或者使用屏幕坐标来解决了。 然后再surf()函数里，为了便于理解，我们把纹理的信息都分别保存到它们各自的变量中： //Get the pixel data from the blend texture//we need a float 4 here because the texture//will return R,G,B,and A or X,Y,Z, and Wfloat4 blendData = tex2D(_BlendTex, IN.uv_BlendTex);//Get the data from the textures we want to blendfloat4 rTexData = tex2D(_RTexture, IN.uv_RTexture);float4 gTexData = tex2D(_GTexture, IN.uv_GTexture);float4 bTexData = tex2D(_BTexture, IN.uv_BTexture);float4 aTexData = tex2D(_ATexture, IN.uv_ATexture); 我们用lerp()函数把每一个纹理混合到一起。这个函数接收三个参数，lerp(value : a, value : b, blend: c)。lerp()函数用前面两个参数的纹理跟最后一个浮点型参数进行混合： //No we need to contruct a new RGBA value and add all//the different blended texture back togetherfloat4 finalColor;finalColor = lerp(rTexData, gTexData, blendData.g);finalColor = lerp(finalColor, bTexData, blendData.b);finalColor = lerp(finalColor, aTexData, blendData.a);finalColor.a = 1.0; 最后，我们把混合后的纹理乘以颜色并且用红色通道来决定到底该用这两个地形颜色的哪一个： //Add on our terrain tinting colorsfloat4 terrainLayers = lerp(_ColorA, _ColorB, blendData.r);finalColor *= terrainLayers;finalColor = saturate(finalColor);o.Albedo = finalColor.rgb * _MainTint.rgb;o.Alpha = finalColor.a; 下图展示了我们通过混合四张地形纹理贴图，并且创建一个地形的技术： 原理介绍 这里代码量好像有点多，但是混合后面的概念是比较简单的。为了展示混合的技术，我们使用了来自CgFX标准库中的内建函数lerp()。这个函数允许我们以第三个参数作为混合量，获得一个介于第一个参数和第二个参数之间的数： 函数 描述 lerp(a,b,f) 这里其实是线性插值： (1 – f )* a + b * f 这里的a和b需要时向量或者标量。但是f只能是跟a和b类型一样的标量或者向量。 我们举例子来演示，比如我们想要获得一个介于1和2之间的中间值，我们此时可以给lerp()函数的第三个参数传一个0.5那么这个函数就会返回1.5。这刚好能满足我们混合纹理的需求，因为在RGBA纹理中的每一个通道的值都是一个浮点值，这些值得取值范围通常都是0到1。 在这个着色器中，我们都简单的从需要混合的纹理中，拿了一个通道的值，来控制用lerp()函数获得的颜色值，这些值最终在赋值给每一个像素点。比如我们用草的纹理和泥土的纹理，再加上我们混合纹理中的红色通道，把这些值分别传递给lerp()函数的第一，二，三个参数。这样我们就能获得地表中每一个像素正确混合后的颜色。 下图更直观的向我们展示了当我们使用lerp()函数时，到底发生了什么： 着色器代码简单的使用了混合纹理的四个通道和所有的颜色纹理，最终创建了一个混合后的纹理。这个最终的纹理的颜色用于跟漫反射的光进行相乘的操作。 [这里找不到这个项目的代码，只能随机应变翻译，没有项目可以跑] 在地形的表面绘制一个圆在很多的RTS类型的游戏中，通过围绕被选中的单位绘制一个圆圈来表示距离（攻击范围，可移动距离，视野等等）。如果地面是平坦的，那么可以用通过对一张绘制有圆圈的矩形纹理进行缩放就能简单的做到。但是如果地面并不平坦，那么这个矩形的纹理就很有可能被高出的山丘或者其他几何物体遮住。接下来的知识点将展示如何编写一个着色器，让你可以在任何复杂的物体表面绘制一个圆圈[且不会被遮住]。如果你想对这个圆圈移动或者执行动画，那么我们就需要有着色器和C#代码才行。下图展示了用着色器在一个丘陵地形中绘制一个圆圈的例子： 始前准备 这里的着色器主要是用于地形的，对于其他的游戏对象不适用。所以我们首先要做的是在Unity中创建好一个地形。 我们先分别建立一个着色器和材质，名字分别是RadiusShader和RadiusMaterial。 当你的角色物体准备好后；我们会绕着它绘制一个圆圈。 在Unity的菜单[这里的菜单操作我就不翻译了，翻译了感觉反而不好，怕翻译错了，大家找不到]，选择 GameObject | 3D Object | Terrain 来创建一个新的地形。 为地形创建一些几何面。你可以导入一个已存在的地形或者自己用地形工具画一个新的。(Raise/Lower Terrain, Paint Height, SmoothHeight )[括号里面这些都是Unity地形编辑器中的工具] 地形是Unity中特殊的游戏对象，它表面的纹理映射方式跟传统的3D模型不一样。你不能通过在着色器定义一个_MainTex来提供纹理，因为在地形中需要直接由地形自己提供。这一步骤可以通过在地形编辑器中选择Paint Texture 然后点击Add Texture…: 完成上面步骤后，纹理就设置好了。你必须修改地形的材质这样就可以在地形中使用我们提供的自定义的着色器。在 Terrain Settings中, 把Material一栏的属性改为Custom，接着把我们的Radius material材质拖拽到Custom Material栏上。 接下来就要准备你自己的着色器了。 操作步骤 让我们开始编辑着色器RadiusShader 的代码: 在新的着色器中, 添加下面四个属性: _Center(\"Center\", Vector) = (0,0,0,0)_Radius(\"Radius\", Float) = 0.5_RadiusColor(\"Radius Color\", Color) = (1,0,0,1)_RadiusWidth(\"Radius Width\", Float) = 2 然后在CGPROGRAM块中添加它们各自的变量与之对应： float3 _Center; float _Radius; fixed4 _RadiusColor; float _RadiusWidth; 所以现在输入表面函数的数据不仅仅是纹理的UV数据了，还包括地形的中每一个点的位置(这个位置是基于世界坐标的)。 为了拿到这个参数我们需要修改输入结构体 Input struct，如下所示： struct Input { float2 uv_MainTex; // The UV of the terrain texture float3 worldPos; // The in-world position }; 最后我们在表面函数中使用这个参数： void surf(Input IN, inout SurfaceOutputStandard o) { float d = distance(_Center, IN.worldPos); if (d &gt; _Radius &amp;&amp; d &lt; _Radius + _RadiusWidth) o.Albedo = _RadiusColor; else o.Albedo = tex2D(_MainTex, IN.uv_MainTex).rgb; } 通过上面的步骤，你就可以在地形中绘制一个圆。你可以通过材质的检查器面板Inspector tab去改变这个圆的位置，半径和颜色。 在表面移动这个圆 如果你想让圆跟着你的角色移动，那就还需要一些额外的工作： 创建一个叫Radius的C#脚本。 在脚本中添加下面这些属性： public Material radiusMaterial;public float radius = 1;public Color color = Color.white; 在Update()方法中，添加下面这些代码： radiusMaterial.SetVector(\"_Center\", transform.position);radiusMaterial.SetFloat(\"_Radius\", radius);radiusMaterial.SetColor(\"_RadiusColor\", color); 然后把这个脚本挂在到你的角色身上。 最后把Radius material这个材质拖拽到C#脚本中的Radius Material中去[是在检查器面板Inspector tab中]。 现在你可以移动你的角色，并且这个圆能很好的跟随玩家。并且修改脚本中的半径也能修改圆圈的半径大小。 原理介绍 绘制这个圆的相关参数是中心点，半径和颜色。它们分别可以在着色器中的_Center, _Radius, 和 _RadiusColor中获得。 通过在输入结构体Input structure 添加一个worldPos的变量，这等于是让Unity提供给我们像素点的位置，这些位置是用世界坐标来表示的。 这是编辑器中一个游戏对象的确切位置。surf()函数是这个圆真正绘制的地方。 它会计算绘制点到中心点的距离，然后判断这个绘制点是否处于_Radius 和_Radius + _RadiusWidth之间；如果满足就使用对应的颜色。如果不是就不修改，跟我们以前遇到的情况一样对纹理贴图取样即可。 理解光照模型在前面的那些章节中，我们介绍了表面着色器并且还理解了如何修改一些物理属性(比如Albedo和Specular)来模拟不同的材质。这些到底是如何工作的呢？每个表面着色器中最重要的部分一一光照模型lighting model。它的功能就是接受这些参数然后计算每一个像素点的最终着色。Unity通常会对开发者隐藏这部分，因为如果想要编写一个光照模型的话，你就必须要去理解光在物体表面是如何反射和折射的。这个章节中我们会毫无保留的向你展示光照模型是如何工作的，并且给你介绍一些你自己创建光照模型所需要的一些基础知识。这一章中，我们会学习下面所列的知识点： 创建一个自定义的漫反射光照模型 创建一个Toon风格的着色器 创建一个Phong类型类型的高光反射着色器 创建 BlinnPhong 类型的高光反射着色器 创建各向异性类型的高光反射着色器 介绍 想要模拟光的工作方式是一项非常具有挑战性的工作，同时也非常消耗计算资源。在之前的很早一段时间内，游戏中使用的都是一些非常简单的光照模型，效果看起来差到难以置信。尽管现在的3D游戏引擎已经使用了基于物理原理的渲染器，但是有些更简单的光照模型技术还是值得我们去探索的。但有时，我们不得不面对资源紧张的现实，没有办法在这些资源有限的设备上完整实现光照模型，比如我们的移动设备。所以你想在这上面实现自己的光照模型，那么你就很有必要了解这些简单的光照模型。 创建一个自定义的漫反射光照模型如果你对Unity4很了解的话，你应该知道Unity提供的默认的着色器是基于一个叫Lambertian reflectance的光照模型。我们会在这个知识点向你展示如何创建一个自定义的光照模型，并且解释它后面的数学原理和实现方式。下面的两张图分别展示了标准着色器Standard Shader (右)和diffuse Lambert着色器对同一个几何体进行渲染后，不同的显示效果：基于Lambertian reflectance光照模型的着色器是典型的非真实渲染着色器；我们现实生活中没有物体会看起来像那样。然而Lambert 着色器依然能在一些低多边形风格的游戏中经常看到，因为跟一些复杂的几何体比起来，它们的三角面数量对比非常明显。用于计算Lambertian反射的光照模型非常高效，这特别适合移动端的游戏。Unity其实已经提供了光照函数给我们，好让我们能在着色器中使用。它就是Lambertian光照模型。它是光反射模拟的一种更基础更有效率的形式，你能在当今的很多游戏中看到它的存在。 因为它们已经内建在了Unity的表面着色器语言中，所以我从这个开始和基于它开始构建也不失为一个好的选择。你也可以在Unity用户手册中找到一个例子，但我们还是会更深入学习，从而向你解释这些数据是从哪里来的以及为什么它是那样工作的。这些可以为设置光照模型打下一个很好的基础，这些知识将来也能在后面的章节中对我们有帮助。 始前准备 让我们从实现下面几个步骤开始： 创建一个新的着色器并且给它命名好。 创建一个新的材质球，命名好，并且把上一步新建的着色器应用于该材质。 接下来，创建一个球形对象，并且把它大致放在场景中间的位置。 最后，我们创建一个方向光源，让光找到游戏对象上。 当你在Unity中设置好这些资源后， 你就会有一个类似于下图的场景： 操作步骤 Lambertian反射可以在着色器中修改下面的代码实现： 首先在着色器的属性Properties块中添加下面的属性： _MainTex(\"Texture\", 2D) = \"white\" 修改着色器的#pragma指示符，从而让着色器使用我们自定义的光照模型，而不是标准Standard： #pragma surface surf SimpleLambert 使用一个非常简单的表面函数surface function，这个函数仅仅通过它的UV数据对纹理进行采样： void surf (Input IN, inout SurfaceOutput o){ o.Albedo = tex2D(_MainTex,IN.uv_MainTex).rgb;} 添加一个叫做LightingSimpleLambert()的函数，这个函数包含了下面实现Lambertian反射的代码： half4 LightingSimpleLambert(SurfaceOutput s,half3 lightDir,half atten){ half NdotL = dot(s.Normal,lightDir); half4 c; c.rgb = s.Albedo * _LightColor0.rgb * (NdotL*atten*1); c.a = s.Alpha; return c;} 原理介绍 如我们前面 第一章，创建你的第一个着色器 所看到的那样，#pragma指示用于指定我们该用哪个表面函数。选择不同的光照模型都是按照下面同一种方法：SimpleLambert 会强制Cg 去寻找一个叫做LightingSimpleLambert()函数。注意开始前面的Lighting，只是在指示中被省略了。 这个光照函数接收3个参数：表面输出结构体surface output(它包含了物理属性比如albedo和transparency)，光照照进来的方向direction和光的衰减attenuation。 根据Lambertian 反射原理, 表面反射光线的数量由表面法线跟入射光线的夹角决定。如果你玩过台球，那么你应该对这个概念比较熟悉；球的方向由球的入射方向跟球桌对应边缘的夹角决定。如果你以90度击球，这个球会垂直返回；如果你以一个非常小的角度击球，球的方向几乎改变很少。Lambertian光照模型跟这个很像；如果光以90度的方式照到一个三角面上，所有光线都会被反射回来。入射的角度越小，返回来的光线也会越少。下面的图片解释了这个概念： 把这个简单的概念转换成数学概念。在向量代数中，两个单位向量的夹角可以通过点积dot product计算 。当点积的值为零，两个向量垂直，也就是说它们之间的夹角是90度。当点积为1(或或者-1)时，那么这连个向量相互平行。在Cg语言中的函数dot()，以极其高效的方式实现了点积。 下图展示了一束阳光照射到了一个复杂的表面。L 指光的方向(就是着色器中的lightDir)，N是表面的法线。光线以相同的角度反射，反射角跟入射角相同： Lambertian反射简单的使用 NdotL点积作为光强度的相乘的系数： I = N * L 当N 跟 L 平行的时候，光线会反射回来，从这个角度看这个几何图形会非常的亮。_LightColor0这个变量包含了对光进行计算后的到的颜色。 注意 Unity5之前的引擎，光强(intensity of the lights)是不一样的。如果你使用的是基于Lambertian反射模型的旧的漫反射着色器，你会发现NdotL乘了两个参数：是(NdotL * atten * 2)而不是(NdotL * atten)。如果你从Unity4中导入的自定义的着色器，需要你手动纠正这点。而Unity自带的一些老的着色器在设计的时候已经考虑到这点了，帮你纠正了。 当点积是负数的时候，这个光是来自三角面的背面。 这对不透明的几何体没有问题，因为摄像机只会渲染朝前面向摄像机的三角面，否则就会被剔除，不去渲染。 这个基本的Lambert光照模型很适合用于构建自己的着色器原型，因为它已经有了着色器中光照模型的核心功能。 Unity已经为我们创建Lambert光照模型提供了原型。在你的Unity安装目录下的Editor/Data/CGIncludes文件夹内照到UnityCG.cginc文件，会发现其实已经有Lamber和BlinnPhong光照模型了。当你使用#pragma surface surf Lambert指示编译着色器时，等于是告诉着色器请使用Unity提供的UnityCG.cginc文件中的Lambert光照模型，这样我们就不用重复造轮子。我们会在这章的稍后部分探索BlinnPhong光照模型。 创建一个Toon风格的着色器Toon着色器(toon shading)是游戏中最常使用的效果之一，也被称作(AKA)cel shading(cel是celluloid的缩写[中文也叫 赛璐珞])。它是一种非真实渲染技术，可以让3D模型呈现一种平面效果。许多游戏中用这种着色器把3D的物体渲染成一种手绘物体的效果。下图中你能看到这两者的区别，右边的是标准着色器，左边的是Toon着色器：如果只使用表面函数(surface functions)虽然也能获得这样的效果，但是花费性能和时间的代价太大了。表面函数仅仅对材质的属性起作用，而对材质的具体光照环境无能为力。因为toon着色器需要改变光的反射方式，所以我们接下来要创建我们自己的光照模型。 始前准备 开始学习这个知识点之前，我们先创建一个着色器和对应的材质球，而且需要导入一个特殊的纹理，步骤如下： 创建一个新的着色器；在这例子中，我们会用上一个知识点的着色器进行扩展 为着色器创建一个新的材质，并且把它应用到3D模型中。 拥有曲面的模型对于toon着色器来说最好。 这个知识点需要一张额外的纹理，叫做ramp贴图[如果要全译，我把它叫梯度贴图]。有一点很重要，在导入的时候把Wrap Mode改为Clamp，如果你想让颜色的边缘变得灵敏，就把Filter Mode设置为Point ： 操作步骤 通过下面的步骤我们可以获得toon风格的特殊审美呈现： 添加一个新的叫_RampTex纹理属性： _RampTex (\"Ramp\", 2D) = \"white\" {} 同时在CGPROGRAM块中添加对应的变量： sampler2D _RampTex; 修改#pragma指示 ，从而让着色器使用一个叫LightingToon()的函数： #pragma surface surf Toon 使用下面这个光照模型： fixed4 LightingToon(SurfaceOutput s ,fixed3 lightDir,fixed atten){ half NdotL = dot(s.Normal,lightDir); NdotL = tex2D(_RampTex,fixed2(NdotL,0.5)); fixed4 c; c.rgb = s.Albedo * _LightColor0.rgb*NdotL*atten; c.a = s.Alpha; return c;} 原理介绍 toon风格着色器的主要特征是它的光的渲染方式；表面并非均匀的着色。为了能达这种效果，我们需要一张ramp贴图。他的作用是对Lambertian的光线强度NdotL重新映射，然后把值赋值给另一个值。我们使用一张ramp贴图而不是一个梯度值，是为了强制光线按照步骤渲染。下图展示了ramp贴图是如何纠正光的强度的： 相关补充 我们有很多不同方式来获得toon着色器效果。 我们可以使用不同的ramp贴图来让我们的模型看起来更有吸引力，这就需要你们自己去试试了，然后找到一张你认为最好的。 还有另一种可选方法对纹理进行梯度采样，就是通过对光强度NdotL进行截断取值，这样就只能在0到1的范围内给它赋值特定的值： fixed4 LightingToon(SurfaceOutput s ,fixed3 lightDir,fixed atten){ half NdotL = dot(s.Normal,lightDir); half cel = floor(NdotL * _CelShadingLevels)/(_CelShadingLevels - 0.5); half4 c; c.rgb = s.Albedo * _LightColor0.rgb*cel*atten; c.a = s.Alpha; return c;} 截断取值部分的代码中，NdotL乘以了倍数_CelShadingLevels并且把它进行了取整，而得到了一个整数，接着又把结果除了回去。通过上面的这些步骤后， 变量cel被赋值，这个值的范围是0到1之间的值，而且这个值跟_CelShadingLevels相等。有了这个，我们就不再需要ramp纹理了而且所有的颜色梯度也在这个范围。如果你正在你的着色中实现这个功能，不要忘记在你的着色器中添加_CelShadingLevels属性。 创建一个Phong类型类型的高光反射着色器一个物体表面的高光，可以简单的理解为它表面的亮度。这种类型的着色器常用于视野特效(view-dependent effects)。这是因为 为了在着色器中获得贴近现实的高光效果，你需要考虑到摄像机和人的朝向因素。而Phong高光效果是最基础和性能较好的一种着色器效果。它根据人的朝向和光的反射方向，通过计算获得一个有方向的反射。 在应用程序中，这种高光模型非常常见，涵盖游戏行业到电影等产业。虽然它在高光反射模型的精确度上不是最接近现实的，但是在大多数情况下，它大致都能满足而且性能不赖。此外，如果你的游戏对象离摄像机很远，就没有必要在提供准确的高光，这对你的高光效果着色器来说是好事。在这个知识点中，我们会涉及到如何使用表面着色器的输入(Input)结构体中的一些新参数进行逐顶点和逐像素的操作。我们会了解它们之间的区别，而且还会讨论什么时候以及为什么要用这两种不同的实现方式，来应对不同的情况。 始前准备 我们按照下面的步骤来学习这次的知识点： 分别创建一个新的着色器，材质和游戏对象，为了在后面你容易照到它们，请给它们恰当命名。 创建一个新场景，在创建一个新的游戏对象，把着色器应用到材质，然后再把材质应用到游戏对象上。 再添加一个平行光源，这是为了让我们方便看我们着色器代码的高光效果。 操作步骤 请按照下面的步骤创建一个Phong类型的光照模型： 此时你可能发现了一个模式，在我们开始写着色器的时候都有的步骤：着色器属性的创建。所以，让我们先在着色器中添加下面的一些属性： Properties{_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)_MainTex (\"Base (RGB)\", 2D) = \"white\" {}_SpecularColor (\"Specular Color\", Color) = (1,1,1,1)_SpecPower (\"Specular Power\", Range(0,30)) = 1} 接下来在CGPROGRAM块中的SubShader{}块中，添加与之对应的一些变量： float4 _SpecularColor;sampler2D _MainTex;float4 _MainTint;float _SpecPower; 现在我们要添加我们自定义的光照模型，因为我们要计算自己的Phong高光。如果你现在还不能理解下面的代码也不用担心；在原理介绍的部分我们会解释每一行代码的作用。在着色器的SubShader{}中添加下述代码： fixed4 LightingPhong (SurfaceOutput s, fixed3 lightDir, half3 viewDir,fixed atten){ // Reflection float NdotL = dot(s.Normal, lightDir); float3 reflectionVector = normalize(2.0 * s.Normal * NdotL - lightDir); // Specular float spec = pow(max(0, dot(reflectionVector, viewDir)), _SpecPower); float3 finalSpec = _SpecularColor.rgb * spec; // Final effect fixed4 c; c.rgb = (s.Albedo * _LightColor0.rgb * max(0,NdotL) * atten) + (_LightColor0.rgb * finalSpec); c.a = s.Alpha; return c;} 最后，我们还要告诉CGPROGRAM块，需要用我们自定义的光照模型而不是Unity内建的光照模型。 按照下面的步骤修改#pragma指示： CPROGRAM#pragma surface surf Phong 下图演示了我们自定义的Phong光照模型的效果，里面的反射算法也是我们自己的： 原理介绍 我们现在先把光照函数放一放，因为着色器剩下的部分你应该感到很熟悉了。 在上一个知识点中，我们使用的光照函数只提供了光的方向，lightDir。Unity本身有一些现成的光照函数配置可以使用，其中一个就是视角方向，viewDir。可以根据下表或者下面的这个链接https://docs.unity3d.com/Manual/SL-SurfaceShaderLighting.html详细了解： Not view dependent half4 Lighting Name You choose (SurfaceOutput s, half3 lightDir, half atten); View-dependent half4 Lighting Name You choose (SurfaceOutput s, half3 lightDir, half3 viewDir, half atten); 在我们的这个例子中，我们处理的是一个高光着色器，所以我们需要基于视角的光线函数结构。所以我们需要编写下面的着色器代码： CPROGRAM#pragma surface surf Pongfixed4 LightingPhong (SurfaceOutput s, fixed3 lightDir, half3 viewDir,fixed atten){ // ...} 这样写会告诉着色器我们要创建我们自己的基于视角的着色器。请注意，你声明的的光线函数的名字要跟#pragma指示那里保持一致[#pragma指示那里省略了前缀“Lighting”]，否则Unity没有办法定位到你的光照模型。 在Phong类型光照模型中的这部分内容，我们用下面的图来描述。L是光的方向(R是跟它成对出现的反射光线方向)，N是物体表面的法线方向。我们在前面讲解Lambertian光照模型的时候讲到过，V是我们没有讲到的，就是这里的视角方向： Phong光照模型给我们呈现了反射表面的最终光强，它由两部分得出：他的的漫反射颜色(diffuse color)和高光值(Specular value)，如下所示：\\[I = D + S\\] 漫反射部分D是来自Lambertian光照模型，这部分没有改变过：\\[D = N \\cdot L\\] 高光部分S的定义如下：\\[S = (R \\cdot V)^{p}\\] 这里,，p 是高光的力度，就是在着色器中的_SpecPower。唯一不知道参数就是R，这是光线L根据法线方向N计算出来的反射光。在向量的代数运算中，它可以通过下面的表达式计算出来：\\[R = 2N \\cdot (N \\cdot L) - L\\] 这个公式就是着色器中下面的这行代码的具体含义： float3 reflectionVector = normalize(2.0 * s.Normal * NdotL - lightDir); 这能让法线有偏向光的效果；当法向量朝向远离光的方向时，反射光线的方向就会越接近入射光线的方向。 下面的图片能给帮助你更好的理解。而产生图中那样的调试效果的脚本，你可以从本书的支持网页中下载，链接：https://www.packtpub.com/support/code-downloads[记得在下面第二张图中的位置输入书名]: 下图展示了我们的Phong高光着色器最终的计算结果： 创建 BlinnPhong 类型的高光反射着色器Blinn是另一种计算和模拟高光的更有效的方法。它只要视角方向和光线方向向量的中间向量就可以计算出来。这个高光是Jim Blinn带入到Cg世界中的。 他发现比起计算反射向量来，只要中间向量的效率更好。它减少了代码量和处理时间。 如果你在UnityCG.cginc文件中查看了Unity内建的BlinnPhong光照模型的话，它也是用了中间向量，因此它被命名为BlinnPhong 。它只是完整Phong光照计算中的一种简单的版本。 始前准备 让我们按照下面的步骤开始学习这个知识点： 这次我们不创建新的场景，就用原来场景和场景内的对象就好，然后我们需要创建一个新的着色器和材质，并且把名字都叫BlinnPhong。 当我们创建好着色器后，双击它，开始编辑。 操作步骤 按照下面的步骤走，我们来创建BlinnPhong光照模型： 首先，我们需要在着色器的属性(Properties)块中添加我们需要用到的属性，这样好让我们控制高光效果： Properties{ _MainTint (\"Diffuse Tint\", Color) = (1,1,1,1) _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _SpecularColor (\"Specular Color\", Color) = (1,1,1,1) _SpecPower (\"Specular Power\", Range(0.1,60)) = 3} 接下来在CGPROGRAM块中添加与属性对应的变量，这样我们就可以获得来自属性(Properties)中的数据： sampler2D _MainTex;float4 _MainTint;float4 _SpecularColor;float _SpecPower; 接下来就是要创建我们自定义的光照模型了，用来处理漫反射和高光的计算，代码如下所示: fixed4 LightingCustomBlinnPhong (SurfaceOutput s, fixed3 lightDir,half3 viewDir, fixed atten){ float NdotL = max(0,dot(s.Normal, lightDir)); float3 halfVector = normalize(lightDir + viewDir); float NdotH = max(0, dot(s.Normal, halfVector)); float spec = pow(NdotH, _SpecPower) * _SpecularColor; float4 c; c.rgb = (s.Albedo * _LightColor0.rgb * NdotL) + (_LightColor0.rgb * _SpecularColor.rgb * spec) * atten; c.a = s.Alpha; return c;} 为了完成我们的着色器，我们还需要告知着色器的CGPROGRAM块使用我们自定义的光照模型而不是Unity内建的，修改#pragma指示，改成如下代码所示： CPROGRAM#pragma surface surf CustomBlinnPhong 下图演示了我们自己的BlinnPhong光照模型的效果： 原理介绍 BlinnPhong高光跟Phong高光很像，但是前者的效率比后者要高，因为后者用更优化的代码实现了几乎一样的效果。在介绍基于物理原理的渲染之前，这种方法是Unity4中高光反射的默认选择。计算反射向量R的代价通常很高。BlinnPhong高光并没有计算它，而是用介于视角V和光线L之间的中间向量H： 跟完整的计算出我们的反射向量不同，我们转而去获得介于视角方向和光线方向之间的中间向量，基本模拟了反射向量。跟Phong高光比起来，这种方法更加贴近真实的物理现象，但是我们依然认为，向你介绍所有的这些方法依然是很有必要的：\\[S_{Phong} = (R \\cdot V)^p, S_{BlinnPhong} = (N \\cdot H)^p\\] 根据向量的代数计算，中间向量可以用下面的方法算出：\\[H\\frac{V+L}{|V+L|}\\] 这里 的$|V+L|$表示向量$V+L$的长度。在Cg中，我们简单的将视角方向和光线方向相加并且对结果进行标准化成一个单位向量： float3 halfVector = normalize(lightDir + viewDir); 然后，我们简单的对顶点的法线和我们的中间向量求点积，从而获得我们主要的高光值。在这之后，我们把它用指数_SpecPower进行指数运算并且乘以高光颜色变量_SpecularColor。跟Phong高光比起来，整个算法在代码量和运算量上都要少很多，但在很多实时渲染情况中，它依然能给我们带来很好的高光效果。 额外内容 在这一章介绍的光照模型都非常的简单；现实中我们是找不出完全粗糙或完全光滑的材料的。要知道，生活中复杂的材料是很常见的，比如衣服，木材和皮肤等等，这些材质涉及到物体表面下层的光如何散射的知识。 我们用下面的表格来回顾我们之前学些过的不同光照模型知识： Technique Type Unity 5 shader Light Intensity (I) Lambertian Diffuse Legacy Shaders | Diffuse $I = N \\cdot L$ Phong Specular   $I = N \\cdot L + (R \\cdot V)^p$         $R = 2N\\cdot(N \\cdot L) - L$ BlinnPhong Specular Legacy Shaders | Specular $I = N \\cdot L +(N \\cdot H)^p $      $H = \\frac{V+L}{|V+L|}$ 下面的链接有一些关于粗糙表面的更有趣的光照模型，比如Oren-Nayar： https://en.wikipedia.org/wiki/Oren%E2%80%93Nayar_reflectance_model 创建各向异性类型的高光反射着色器各向异性(Anisotropic)类型可以用来模拟高光或者反射，常用于表面凹槽的方向和高光在垂直方向上的扭曲形变。当你想模拟金属抛光表面的时候这种类型的着色器就会非常有用，因为这种表面并不干净，光滑和明亮。 你可以想象当你看CD或者VCD光盘的数据那面时的高光或者底面被打磨过的金属盘子和盆子。 当你仔细检查这些表面的时候你会发现，表面的这些沟纹是有方向的，通常就是被抛光的方向。当你对这样的表面应用高光时，在垂直方向上会被扭曲。这个知识点中我们会向你介绍不同的抛光表面高光概念。在将来的一些知识点中，我们会探索如何使用这个知识点介绍的一些概念来获得一些类似于头发的扭曲反射效果，但是在这里我们还是要先学习这个技术的一些原理知识。我们自定义的各向异性着色器将使用下面这个着色器作为参考：http://wiki.unity3d.com/index.php?title=Anisotropic_Highlight_Shader下图展示了使用各向异性(Anisotropic)着色器能获得的不同类型高光效果： 始前准备 让我们开始学习新的知识点吧，先按照下面的步骤在场景中创建一个着色器，材质和一些光源： 创建一个新的场景，在场景中添加一些游戏对象，添加一个平行光源，这样我们好可视化的调试我们的着色器。 创建一个新的着色器和材质，它们都应用到刚刚创建的游戏对象上去。 最后，我们需要某种法线贴图，它能指出我们各向异性类型高光的方向。 下图展示的就是这个知识点要用的各向异性类型的法线贴图。在本书的支持网页中可以获得[就在本书附带的工程代码中，获取方法前面有介绍]: https://www.packtpub.com/books/content/support 操作步骤 为了获得各向异性效果，我们需要对我们前面创建的着色器进行如下的修改： 首先得再着色器中添加我们需要用到的一些属性。这些属性允许我们控制很多中艺术效果从而最终决定表面的效果呈现： {_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)_MainTex (\"Base (RGB)\", 2D) = \"white\" {}_SpecularColor (\"specular Color\", Color) = (1,1,1,1)_Specular (\"Specular Amount\", Range(0,1)) = 0.5_SpecPower (\"Specular Power\", Range(0,1)) = 0.5_AnisoDir (\"Anisotropic Direction\", 2D) = \"\" {}_AnisoOffset (\"Anisotropic Offset\", Range(-1,1)) = -0.2} 接着我们要让我们的SubShader{}代码块跟我们的属性(Properties)块关联起来，这样才能让我们使用属性(Properties)中的数据： sampler2D _MainTex;sampler2D _AnisoDir;float4 _MainTint;float4 _SpecularColor;float _AnisoOffset;float _Specular;float _SpecPower; 接下来我们要创建我们自己的光照函数，用来处理物体表面的各向异性效果。我们的代码如下： fixed4 LightingAnisotropic(SurfaceAnisoOutput s, fixed3 lightDir, half3 viewDir, fixed atten){ fixed3 halfVector = normalize(normalize(lightDir) + normalize(viewDir)); float NdotL = saturate(dot(s.Normal, lightDir)); fixed HdotA = dot(normalize(s.Normal + s.AnisoDirection),halfVector); float aniso = max(0, sin(radians((HdotA + _AnisoOffset) * 180))); float spec = saturate(pow(aniso, s.Gloss * 128) * s.Specular); fixed4 c; c.rgb = ((s.Albedo * _LightColor0.rgb * NdotL) + (_LightColor0.rgb * _SpecularColor.rgb * spec)) * atten; c.a = s.Alpha; return c;} 为了使用我们新的光照函数，我们需要修改#pragma指示，让Unity去使用我们的光照函数，而不是Unity内建的光照函数。我们同时还要告诉着色器目标着色器模式是3.0，这样我们可以让我们的程序拥有更多的空间用来存放纹理： CGPROGRAM#pragma surface surf Anisotropic#pragma target 3.0 为了让各向异性法线贴图能使用它自己的UV数据，我们需要再输入(Input)结构中添加如下定义代码。 我们其实并不是说完全需要这样做，因为我们也可以使用主帖图上的UV数据，但是如果有它自己单独UV数据的话我们就能单独控制金属抛光效果的截取，这样我们就可以把它进行缩放任何我们想要的大小： { float2 uv_MainTex; float2 uv_AnisoDir;}; 我们还需要定义SurfaceAnisoOutput这个输出结构体： struct SurfaceAnisoOutput{ fixed3 Albedo; fixed3 Normal; fixed3 Emission; fixed3 AnisoDirection; half Specular; fixed Gloss; fixed Alpha;}; 最后，我们需要通过表面函数surf()给我们的光照函数传递正确的数据。这样，我们将会获得我们各向异性法线贴图的每个像素信息，然后像下面的代码一样设置我们的高光参数： void surf(Input IN, inout SurfaceAnisoOutput o){ half4 c = tex2D(_MainTex, IN.uv_MainTex) * _MainTint; float3 anisoTex = UnpackNormal(tex2D(_AnisoDir, IN.uv_AnisoDir)); o.AnisoDirection = anisoTex; o.Specular = _Specular; o.Gloss = _SpecPower; o.Albedo = c.rgb; o.Alpha = c.a;} 各向异性法线贴图允许我们给出表面的方向并且能帮助我们分散物体表面周围的高光效果。下图就是我们的各向异性着色器的效果： 原理介绍 我们按部分来看看这个着色器的核心内容并且解释为什么我们能获得这样的效果。这里我们大部分都讲光照函数部分，因为除此之外的内容对于当前的你来说都能自己理解。 首先我们定了我们自己的结构体SurfaceAnisoOutput。我们之所以这样么做是因为我们需要获得各向异性法线贴图的每个像素信息，而再表面着色器中获得这个的唯一方法就是在surf()函数中使用tex2D()函数获取。 下面的代码就是我们在着色器中自定义的输出结构体： struct SurfaceAnisoOutput{ fixed3 Albedo; fixed3 Normal; fixed3 Emission; fixed3 AnisoDirection; half Specular; fixed Gloss; fixed Alpha;}; SurfaceAnisoOutput输出结构体是光线函数和表面函数进行交互的中间数据。在我们这个例子中，surf()中我们把每个像素的纹理信息都保存在了anisoTex中，接着把anisoTex保存在了AnisoDirection变量中，再然后AnisoDirection被传递到了表面结构体SurfaceAnisoOutput中。一旦我们拥有了这个表面结构体，我们就能在我们的光照函数中使用这每个像素的纹理信息了。 s.AnisoDirection. 当我们设置好这部分数据关联后，我们就可以着手我们具体的光照计算了。跟往常不一样，这里我们使用了中间向量，这样我们就不用去进行完整的反射计算和漫反射计算，因为这些计算都需要让顶点的法向量跟光线或光的方向进行点积的运算。我们的Cg代码如下所示: fixed3 halfVector = normalize(normalize(lightDir) + normalize(viewDir));float NdotL = saturate(dot(s.Normal, lightDir)); 之后，我们开始对高光进行具体的修改，以便获得我们想要的视觉效果。我们首先把顶点法线跟我们各向异性法线贴图的顶点相加得到和，再对和进行标准化，然后把标准化后的向量跟前面步骤获得的中间向量(halfVector)进行点积操作。参考它跟各向异性法线贴图的点积，当值等于1时，说明表面法线跟中间向量(halfVector)平行，当值等于0时，它们相互垂直。最后我们还要用sin()函数来修改这个值，这样根据中间向量(halfVector)我们基本能获得一个更暗一些的中间亮度，并且最终获得一个环状的效果。所有上面提及的操作都包含在了下面两行Cg代码中： fixed HdotA = dot(normalize(s.Normal + s.AnisoDirection), halfVector);float aniso = max(0, sin(radians((HdotA + _AnisoOffset) * 180))); 最后，我们通过s.Gloss对aniso进行指数放大，从而放大效果， 然后再通过乘以s.Specular来全局减少它的强度： float spec = saturate(pow(aniso, s.Gloss * 128) * s.Specular); 这个效果非常适合创建一些更加高级的金属类型的表面，尤其时那些表面被有向抛过光的。当然它也非常适合头发反光或者任何表面有方向性的软表面。下图展示了各向异性光照计算的最终显示效果： Unity 5中基于物理原理的渲染基于物理原理的渲染physically-based rendering是Unity5中加入的最大的变化之一，也就是我们常说的PBR。前面的一些章节重复提到过它但是没有却没向大家过多的展现。如果你不仅想知道PBR的工作原理，还想搞明白如何构建它们，那么这一张正是你需要阅读的。在这一章，你将会学习下面的几个知识点： 理解金属质感的设置 向PBR中添加透明度 创建镜子和反射面 烘培场景中的光 介绍 我们在第三章，理解光照模型 中介绍了所有的光照模型，简单的讨论了一下光是如何表现的。在编写它们的时候效率efficiency是最重要的方面。实时渲染的开销是很大的，类似于Lambertian和BlinnPhong这样的光照模型技术，也仅仅是在模拟现实和性能开销中的折中方案。拥有了更加强劲的GPU(graphics processing unit)后，我们就可以编写更加精细的光照模型和渲染引擎，目的就是为了模拟光的真实行为。简单概括前面的来说，这就是PBR后面的哲学。正如它的名字所表达的那样， 它是尽可能的去接近真实的物理，来处理每一个不同材质，让他们看起来都不一样。不仅如此，PBR这个术语被广泛的用于市场营销，它更像是艺术级的渲染(state-of-the-art rendering)，而不是一个简单的技术。Unity5通过引入两个重要的改变，实现了PBR。首先是一个全新的光照模型(叫Standard)。表面着色器允许开发人员指定材质的物理属性，但是他们却没有对它们应用任何的物理原理限制。PBR用新的光照模型来弥补了这个差距，应用了一些物理原理，比如能量守恒(energy conservation)[一个物体反射的光线不可能多于接收的光线]，微表面散射(microsurface scattering) [粗糙表面比光滑表面的反射更没有规律]，菲涅尔反射(Fresnel reflectance)[高光反射出现在掠射角内]，和表面阻塞(surface occlusion)[一些角落的暗部和一些几何体很难照亮]。所有说的这方面，还有一些其他的，都被用来计算标准光照模型。第二方面让PBR开起来如此真实技术叫全局光照(Global Illumination [GI])，它是对基于物理原理的光线传输的模拟。也就是说，如果这些物体是独立的实体，那么它们不会被绘制[不会反光只吸收光的的物体，这种绝对黑体是看不见的]。它们会影响最终的渲染效果，因为光线在碰到其他物体前首先会从它们身上反射。虽然在着色器中不会自动提及这方面，但是对于了解渲染引擎是如何工作来说是很重要的部分。然而令人难过的是，实时的精确模拟光线在物体表面到底是如何反弹，这已经超出了现代GPU的能力范围。Unity5做了一些很聪明的优化，即保持了视觉质量有没有牺牲性能。然而大部分的一些进阶技术(比如反射) 需要用户的输入。上面说的这些方面都会在本章介绍。 不过希望各位留意的是，即使是PBR或者GI这些技术也不能保证你的游戏可以获得照片级的画质。要获得照片级的画面是一项很有挑战性的工作，跟每一门艺术一样，需要非常专业和杰出的技巧。 理解金属质感的设置Unity5提供了两种不同类型的PBR着色器； 它们指的是材质的检查器面板(Inspector)中的下拉列表中的Standard着色器和Standard (Specular setup)着色器。两者的主要区别在于前者为我们暴露了Metallic这个属性，而后者没有Metallic，但暴露了Specular这个属性。metallic 属性和specular 属性代表了初始化PBR材质不同方式。推动PBR的概念之一是提供给开发人员和艺术家一种有目的性的，基于物理相关的一些属性，让他们可以调整和把玩它们。 有些材质的属性更容易用来表示它们的质金属质感强度指标，而其他的另一些属性则直接于定义了光是如何反射的，也很重要。如果你过去使用过Unity4，那么对于Standard (Specular setup)着色器应该看起来更熟悉。这个知识点会教你如何有效的使用金属质感设置(metallic setup)。有个重点需要各位注意，金属质感的工作流不仅仅用于金属材质；它是根据表面的金属质感或者非金属质感来定义材质的视觉效果的一种方式。尽管呈现的是两种不同的类型的着色器，但这金属(Metallic )和高光(Specular)这两种方案通常来说是相等的表示。 就像Unity文档中所展示的：http://docs.unity3d.com/Manual/StandardShaderMetallicVsSpecular.html，这两种设置都可以创建同样的材质(如下图所示)： 始前准备 在这个知识点中我们将用Unity5提供的标准着色器，所以我们没有必要重新创建一个。我们通过下面的步骤来开始学习这个知识点： 创建一个新的材质球。 在这个材质球的检查器(Inspector)面板，确保Shader这个下拉菜单中选择的是Standard。 同时你需要一个带有纹理的3D模型。 操作步骤 在标准着色器中有两个主要的纹理需要配置：Albedo和Metallic。为了有效地使用金属化工作流，我们需要正确的初始化这些映射： Albedo映射应该用3D模型的unlit(不受光照影响)纹理初始化。 创建Metallic映射之前，先复制一份文件用留给Albedo映射。你可以在项目(Project)面板中中选择要复制的贴图，然后通过快捷键Ctrl + D复制。 用白色 (#000000)给表示纯金属的材质的贴图区域上色。而其他要用的的颜色都用黑色(#000000)。灰色的着色应该用于表示满是灰尘的，风化的和磨损的金属表面，还有生锈表面，有刮擦的绘画等等。事实上，Unity仅仅使用了红颜色(R)通道来保存金属质感的值；而绿颜色通道(G)和蓝颜色通道(B)则被忽略了。 用图片的的alpha通道来提供材质的光滑度(Smoothness)信息。 把金属质感(Metallic)贴图关联到材质球中。金属质感(Metallic)和光滑度(Smoothness)的滑动条都会消失，因为这两个属性现在由贴图控制了。 原理介绍 旧着色器中的光照模型条件让艺术家们很难创造出贴近现实视觉效果。之所以会这样，是因为旧的表面着色器中所有的属性间没有关联。通过介绍金属质感的工作流，Unity5将强制对游戏对象的表现将添加更多系统参数，这样的话艺术家们就能更易创建合理的材质。 金属是电的良导体；而光是电磁波的一种形式，也就是说相比于不良导体(经常被称为绝缘体(insulators))，几乎所的金属都有相似的行为表现。导体的反射率很高，能反射大部分的光子(70-100%)。然后剩余没有被反射的光就被吸收了，不是漫反射出来，也就是说导体的漫反射元素很黑[其实我觉得翻译成很低也能说的通]。相反的是，绝缘体反射率很低(%4)而剩余的光在表面被散射掉了，所以漫反射效果明显。 在标准着色器中，纯金属材质拥有较黑的漫反射元素并且它的高光反射的颜色由Albedo贴图来定义。相反的，对于纯粹的非金属材料来说，Albedo贴图定义的是它们的漫反射元素； 而它们的高光高光颜色其实是由射进来的光颜色决定的遵守这些规则在金属工作流中可以把albedo和specular结合进Albedo贴图中去，实行精确的物理行为。在牺牲材质视觉效果控制的前提下，这能让我们节省更多的空间，而且极大的提升运行速度。 额外内容 想获得更多关于金属质感的设置的信息，你可以参考下面链接的信息： 校准图表(Calibration chart)：如何校准一个金属质感的材质球 (http://blogs.unity3d.com/wp-content/uploads/2014/11/UnityMetallicChart.png) 材质图表(Material chart): 如何为一些常用的材质初始化标准着色器的参数 (http://docs.unity3d.com/Manual/StandardShaderMaterialCharts.html) Quixel MEGASCANS: 一个巨量的材质素材仓库[网站]，还包括纹理和PBR的参数设置[网站已经变了，我纠正一下] (https://quixel.com/megascans/home/) PBR纹理的转换：传统的着色器如何转换成PBR着色器 (http://www.marmoset.co/toolbag/learn/pbr-conversion) Substance Designer：一个基于节点的跟PBR一起工作的额软件 (https://www.allegorithmic.com/products/substance-designer) 基于物理原理渲染的理论：一个关于PBR的完全教程[源网址已经变了，帮大家重新找到了] (https://academy.substance3d.com/courses/the-pbr-guide-part-1-zh) 向PBR中添加透明度透明度是游戏中很重要的一个方面，标准着色器支持三种不同的实现方式。 如果你想让你的材质获得很逼真的透明或者半透明属性，这个知识点非常有用。玻璃，玻璃瓶子，玻璃窗和各种结晶体都很适合PBR透明着色器。这是因为你依然可以获得PBR带来的包含透明和半透明的效果的逼真效果。 如果你想让UI或者像素艺术这样的不同的东西也具有半透明效果，这里由更加高效的可选方法，就是在第二章 表面着色器和纹理贴图 这一章节中，创建一个带透明度的材质 这个知识点。注意为了能获得一个有透明度的标准材质，仅仅是修改它的Albedo颜色属性的alpha通道是不够的。除非你把Rendering Mode设置成transparent，否则你的材质是不会产生透明度的。 始前准备 这个知识点将会使用标准着色器(Standard Shader)，所以我们没有必要创建新的着色器了： 创建一个新的材质球 在材质球的检查器(Inspector)面板确保Shader这个属性设置为了Standard或者Standard (Specular setup)。 然后把这个新创建好的材质球应邀到你想要实现透明度的3D模型上。 操作步骤 标准着色器提供了三种不同类型的透明度。尽管非常的相似，但是它们仍然又细微的差别，并且适用的情形也是不同的。 半透明材质 像干净的塑料，晶体和玻璃这些材料是半透明的。 这就意味着它们都需要PBR这种逼真的效果(比如高光高光，菲涅尔折射和反射)而且允许几何体后面也能被看见的话。如果这是你想要的效果，就按照下面的步骤走： 在材质球的检查器(Inspector)面板，把Rendering Mode这个属性设置为Transparent。 透明度的数值由Albedo颜色或者Albedo贴图(如果有)的alpha通道来决定。 下图展示的是Unity5校准场景中四种高度抛光过的塑料球。从左到右，它们的透明度逐渐增高。最后的一个球是完全透明的，但依然保有PBR中添加的效果： Transparent这个渲染模式非常适合窗户，瓶子，宝石和头戴式耳机 注意 你需要注意的是大部分的透明材质不会投射阴影。 除此之外，材质的Metallic和Smoothness也会影响到透明效果。镜子似的表面可以通过把alpha设置为0获得，但是如果它反射所有入射光的话，它就不会表现出透明效果。 渐隐的游戏对象 有时候，你想用渐隐效果让一个游戏对象完全消失。在这个例子中，高光反射，菲涅尔折射 和反射等效果也会消失。当一个渐隐的游戏对象完全透明，它应该是看不见的。为了完成这些，按照下面的步骤操作： 在材质的检查器(Inspector)面板，把Rendering Mode设置为Fade。 如前面一样，用Albedo的颜色或者贴图的alpha通道来决定最终的透明度。 下图展示了一个渐隐的球体。从图中明显可以看出PBR效果也随着渐隐效果逐渐消失。正如你从下面图见到的那样，往右最后的那个球近乎消失不见了： 这个渲染模式最适合非真实(non-realistic)物体，比如全息投影，镭射光线，人造光线，幽灵和粒子等效果。 有洞的固态几何体 在游戏中遇到的大多数材质都是不透明的，也就是说光没有办法穿透它们。与此同时，很多物体还有非常复杂的几何面(还有平面)。如果用3D 模型来制作叶子和草未免右点太复杂了。一个更加高效的方式使用quad(其实是一个矩形)加一个叶子的纹理来制作。但是叶子本身是不透明的，那剩下的那张纹理就完全是透明的。 如果你想做这种效果，就按照下面的步骤操作： 再材质的检查器(Inspector)面板，把Rendering Mode设置成Cutout。 然后使用Alpha Cutoff滑动条来调整裁剪阈值。在Albedo贴图中所有alpha值等于或者小于Alpha Cutoff值的像素点都会被隐藏。 下图截取至Unity官方的PBR教程(https://www.youtube.com/watch?v=fD_ho_ofY6A)[需要用梯子]，向你演示了Cutout渲染模式效果如何在几何体上打一个孔洞： 值得注意的是Cutout并不允许几何体背面被看见。在前面的示例中，你不能看到球体的内部体积部分。如果你需要这样的一个效果，你需要创建自己的着色器并且确定几何体的背部不会被踢除。 额外内容 这个知识的演示，使用了Unity商城中的ShaderCalibration Scene免费资源，地址如下[已经失效了]： https://www.assetstore.unity3d.com/en/#!/content/25422。 更多关于albedo和transparency的信息，可以通过下面的链接查询： http://docs.unity3d.com/Manual/StandardShaderMaterialParameterAlbedoColor.html。 创建镜子和反射面当我们从一定的角度看高光材质物体时，物体会反射光。然而可惜的是，即使是最精确的光照模型之一：菲涅尔反射Fresnel reflection，也不能完全准确的反射来自周围物体的光。前一个章节验证过的光照模型只考虑了一些光源，但是却忽略了来自其他表面的反射光。很显然，用目前我们学的关于着色的知识，来创建一面镜子是不可能的。但是全局光照Global illumination技术提供了这种可能性，这需要提供包含了周围光照信息的PBR着色器。 这就要求物体不仅需要有高光部分，还需要有依赖周围其他物体的真实的反射部分。实时的反射非常消耗性能并且需要一些自定义的设置和调整才能工作，它们可以用来创建类似高光的效果，就如下图所示： 始前准备 这个知识点中不会涉及新的着色器。恰恰相反，大部分的工作都可以直接在编辑器上完成。就像下面的步骤展示的那样： 创建一个新场景 然后在场景中创建一个quad，这个quad会用来作为镜子。 创建一个新的材质并且把它跟这个镜子关联起来。 把这个quad放在另一个游戏对象前面。 在Unity菜单中通过GameObject | Light | Reflection Probe的步骤创建一个反射探针reflection probe并且把它放在quad的前面。 操作步骤 如果正确的按照前面的步骤操作，那么在你的场景中间会有一个quad，靠近它还有一个反射探针。为了让它出现在镜子中，还需要做西面的这些改变： 把材质的着色器类型改成Standard并且把Rendering Mode设置成Opaque。【这里的属性英文不翻译把，因为Unity大部分人都是用的英文，我担心找不到】 把Metallic和Smoothness这两个的属性设置为1。你可以看到材质会很清晰的反射天空盒。 选择反射探针并且修改Size和Probe Origin直到它刚好在quad的前面，并且让探针包含你想反射的物体。 最后把Type改成Realtime。确定Culling Mask设置的是Everything。 这样的话，你的反射探针就设置好了，看起来就跟下图一样： 如果你的探针是用来做真正的镜子，那么你应该勾选Box Projection这个选项。如果你是用来做一些类似于亮晶晶的小金属碎片或者玻璃桌子，那么你就不应该勾选这个选项。 原理介绍 当着色器想要周围环境信息的时候，它自己提供了一个叫做cube maps的数据结构。它在第一章,创建你的第一个着色器 简短的提及过，跟Color，2D，Float和Vector这些结构一样，都是Cg语言中的一种数据结构。笼统一点来说，cube maps就是2D纹理的3D数据结构。它们表示从中心点看过来的360度的世界视角。 Unity5可以通过特殊的投影预览cube maps，如下图所示： 当cube maps关联到一个摄像机时，它们会被天空盒skyboxes引用，因为它们此时时被用于反射天空的一种方式。它们能用于反射不在实际场景中的几何体，比如星云，云朵，星星等等。 之所以会把它们叫做立方体贴图(cube maps)原因跟它们的创建方式有关：一个立方体贴图是由6张不同的纹理组成的，立方的每个面都有一张纹理。你可以手动的创建一个立方体贴图然后把它放到一个反射探针(reflection probe)上。你可以把反射探针想象成一个拥有6个摄像机，拥有周围环境360度贴图的几何体。 这也解释了为什么探针的性能消耗会这么高。 在我们的场景中创建一个反射探针，这样允许Unity知道那些游戏对象再镜子的周围。如果你需要更多的反射面，那你可以添加多个探针。探针此时可以工作了，你无需再做进一步的操作。标准着色器(Standard Shaders)会自动使用它们。 需要注意的是当它们被设置成实时(Realtime)的时候，它们会在每一帧的开始渲染立方体贴图。这里有一个技巧可以让这个过程更快；如果你知道你想反射的几何体的哪个部分是不会移动的，你可以对反射进行烘焙。这意味着Unity可以在游戏开始前就将反射预先计算好，可以允许更精确(计算量更大)的计算。 为了做这个操作，那么你的反射探针需要设置成烘培(Baked)，于此同时游戏对象也要标记为静态(Static)才行。静态的游戏对象没法移动和改变，因此它们特别适合地形，建筑和道具。只要静态游戏对象发生变化，Unity都会为烘焙的反射探针重新生成立方体贴图。这可能要花费几分钟到几个小时。 为了让你的游戏更加的贴近现实，有时候你需要把实时(Realtime)和烘培(Baked)这两种探针综合来使用。 烘培过的探针能获得高质量的环境反射，然而实时探针可以用于移动的游戏对象比如汽车或者镜子。下一个知识点 烘培场景中的光 将会解释如何进行光的烘培的具体细节。 额外内容 如果你像学习更多关于反射探针的内容，你应该通过下面的链接学习：https://docs.unity3d.com/Manual/class-ReflectionProbe.html " }, { "title": "创建镜子和反射面", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E9%95%9C%E5%AD%90%E5%92%8C%E5%8F%8D%E5%B0%84%E9%9D%A2/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-05-17 00:00:00 +0800", "snippet": "创建镜子和反射面当我们从一定的角度看高光材质物体时，物体会反射光。然而可惜的是，即使是最精确的光照模型之一：菲涅尔反射Fresnel reflection，也不能完全准确的反射来自周围物体的光。前一个章节验证过的光照模型只考虑了一些光源，但是却忽略了来自其他表面的反射光。很显然，用目前我们学的关于着色的知识，来创建一面镜子是不可能的。但是全局光照Global illumination技术提供...", "content": "创建镜子和反射面当我们从一定的角度看高光材质物体时，物体会反射光。然而可惜的是，即使是最精确的光照模型之一：菲涅尔反射Fresnel reflection，也不能完全准确的反射来自周围物体的光。前一个章节验证过的光照模型只考虑了一些光源，但是却忽略了来自其他表面的反射光。很显然，用目前我们学的关于着色的知识，来创建一面镜子是不可能的。但是全局光照Global illumination技术提供了这种可能性，这需要提供包含了周围光照信息的PBR着色器。 这就要求物体不仅需要有高光部分，还需要有依赖周围其他物体的真实的反射部分。实时的反射非常消耗性能并且需要一些自定义的设置和调整才能工作，它们可以用来创建类似高光的效果，就如下图所示： 始前准备 这个知识点中不会涉及新的着色器。恰恰相反，大部分的工作都可以直接在编辑器上完成。就像下面的步骤展示的那样： 创建一个新场景 然后在场景中创建一个quad，这个quad会用来作为镜子。 创建一个新的材质并且把它跟这个镜子关联起来。 把这个quad放在另一个游戏对象前面。 在Unity菜单中通过GameObject | Light | Reflection Probe的步骤创建一个反射探针reflection probe并且把它放在quad的前面。 操作步骤 如果正确的按照前面的步骤操作，那么在你的场景中间会有一个quad，靠近它还有一个反射探针。为了让它出现在镜子中，还需要做西面的这些改变： 把材质的着色器类型改成Standard并且把Rendering Mode设置成Opaque。【这里的属性英文不翻译把，因为Unity大部分人都是用的英文，我担心找不到】 把Metallic和Smoothness这两个的属性设置为1。你可以看到材质会很清晰的反射天空盒。 选择反射探针并且修改Size和Probe Origin直到它刚好在quad的前面，并且让探针包含你想反射的物体。 最后把Type改成Realtime。确定Culling Mask设置的是Everything。 这样的话，你的反射探针就设置好了，看起来就跟下图一样： 如果你的探针是用来做真正的镜子，那么你应该勾选Box Projection这个选项。如果你是用来做一些类似于亮晶晶的小金属碎片或者玻璃桌子，那么你就不应该勾选这个选项。 原理介绍 当着色器想要周围环境信息的时候，它自己提供了一个叫做cube maps的数据结构。它在第一章,创建你的第一个着色器 简短的提及过，跟Color，2D，Float和Vector这些结构一样，都是Cg语言中的一种数据结构。笼统一点来说，cube maps就是2D纹理的3D数据结构。它们表示从中心点看过来的360度的世界视角。 Unity5可以通过特殊的投影预览cube maps，如下图所示： 当cube maps关联到一个摄像机时，它们会被天空盒skyboxes引用，因为它们此时时被用于反射天空的一种方式。它们能用于反射不在实际场景中的几何体，比如星云，云朵，星星等等。 之所以会把它们叫做立方体贴图(cube maps)原因跟它们的创建方式有关：一个立方体贴图是由6张不同的纹理组成的，立方的每个面都有一张纹理。你可以手动的创建一个立方体贴图然后把它放到一个反射探针(reflection probe)上。你可以把反射探针想象成一个拥有6个摄像机，拥有周围环境360度贴图的几何体。 这也解释了为什么探针的性能消耗会这么高。 在我们的场景中创建一个反射探针，这样允许Unity知道那些游戏对象再镜子的周围。如果你需要更多的反射面，那你可以添加多个探针。探针此时可以工作了，你无需再做进一步的操作。标准着色器(Standard Shaders)会自动使用它们。 需要注意的是当它们被设置成实时(Realtime)的时候，它们会在每一帧的开始渲染立方体贴图。这里有一个技巧可以让这个过程更快；如果你知道你想反射的几何体的哪个部分是不会移动的，你可以对反射进行烘焙。这意味着Unity可以在游戏开始前就将反射预先计算好，可以允许更精确(计算量更大)的计算。 为了做这个操作，那么你的反射探针需要设置成烘培(Baked)，于此同时游戏对象也要标记为静态(Static)才行。静态的游戏对象没法移动和改变，因此它们特别适合地形，建筑和道具。只要静态游戏对象发生变化，Unity都会为烘焙的反射探针重新生成立方体贴图。这可能要花费几分钟到几个小时。 为了让你的游戏更加的贴近现实，有时候你需要把实时(Realtime)和烘培(Baked)这两种探针综合来使用。 烘培过的探针能获得高质量的环境反射，然而实时探针可以用于移动的游戏对象比如汽车或者镜子。下一个知识点 烘培场景中的光 将会解释如何进行光的烘培的具体细节。 额外内容 如果你像学习更多关于反射探针的内容，你应该通过下面的链接学习：https://docs.unity3d.com/Manual/class-ReflectionProbe.html " }, { "title": "向pbr中添加透明度", "url": "/game-tech-post-old/posts/%E5%90%91PBR%E4%B8%AD%E6%B7%BB%E5%8A%A0%E9%80%8F%E6%98%8E%E5%BA%A6/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-03-15 00:00:00 +0800", "snippet": "向PBR中添加透明度透明度是游戏中很重要的一个方面，标准着色器支持三种不同的实现方式。 如果你想让你的材质获得很逼真的透明或者半透明属性，这个知识点非常有用。玻璃，玻璃瓶子，玻璃窗和各种结晶体都很适合PBR透明着色器。这是因为你依然可以获得PBR带来的包含透明和半透明的效果的逼真效果。 如果你想让UI或者像素艺术这样的不同的东西也具有半透明效果，这里由更加高效的可选方法，就是在第二章 表面着...", "content": "向PBR中添加透明度透明度是游戏中很重要的一个方面，标准着色器支持三种不同的实现方式。 如果你想让你的材质获得很逼真的透明或者半透明属性，这个知识点非常有用。玻璃，玻璃瓶子，玻璃窗和各种结晶体都很适合PBR透明着色器。这是因为你依然可以获得PBR带来的包含透明和半透明的效果的逼真效果。 如果你想让UI或者像素艺术这样的不同的东西也具有半透明效果，这里由更加高效的可选方法，就是在第二章 表面着色器和纹理贴图 这一章节中，创建一个带透明度的材质 这个知识点。注意为了能获得一个有透明度的标准材质，仅仅是修改它的Albedo颜色属性的alpha通道是不够的。除非你把Rendering Mode设置成transparent，否则你的材质是不会产生透明度的。 始前准备 这个知识点将会使用标准着色器(Standard Shader)，所以我们没有必要创建新的着色器了： 创建一个新的材质球 在材质球的检查器(Inspector)面板确保Shader这个属性设置为了Standard或者Standard (Specular setup)。 然后把这个新创建好的材质球应邀到你想要实现透明度的3D模型上。 操作步骤 标准着色器提供了三种不同类型的透明度。尽管非常的相似，但是它们仍然又细微的差别，并且适用的情形也是不同的。 半透明材质 像干净的塑料，晶体和玻璃这些材料是半透明的。 这就意味着它们都需要PBR这种逼真的效果(比如高光高光，菲涅尔折射和反射)而且允许几何体后面也能被看见的话。如果这是你想要的效果，就按照下面的步骤走： 在材质球的检查器(Inspector)面板，把Rendering Mode这个属性设置为Transparent。 透明度的数值由Albedo颜色或者Albedo贴图(如果有)的alpha通道来决定。 下图展示的是Unity5校准场景中四种高度抛光过的塑料球。从左到右，它们的透明度逐渐增高。最后的一个球是完全透明的，但依然保有PBR中添加的效果： Transparent这个渲染模式非常适合窗户，瓶子，宝石和头戴式耳机 注意 你需要注意的是大部分的透明材质不会投射阴影。 除此之外，材质的Metallic和Smoothness也会影响到透明效果。镜子似的表面可以通过把alpha设置为0获得，但是如果它反射所有入射光的话，它就不会表现出透明效果。 渐隐的游戏对象 有时候，你想用渐隐效果让一个游戏对象完全消失。在这个例子中，高光反射，菲涅尔折射 和反射等效果也会消失。当一个渐隐的游戏对象完全透明，它应该是看不见的。为了完成这些，按照下面的步骤操作： 在材质的检查器(Inspector)面板，把Rendering Mode设置为Fade。 如前面一样，用Albedo的颜色或者贴图的alpha通道来决定最终的透明度。 下图展示了一个渐隐的球体。从图中明显可以看出PBR效果也随着渐隐效果逐渐消失。正如你从下面图见到的那样，往右最后的那个球近乎消失不见了： 这个渲染模式最适合非真实(non-realistic)物体，比如全息投影，镭射光线，人造光线，幽灵和粒子等效果。 有洞的固态几何体 在游戏中遇到的大多数材质都是不透明的，也就是说光没有办法穿透它们。与此同时，很多物体还有非常复杂的几何面(还有平面)。如果用3Ds模型来制作叶子和草未免右点太复杂了。一个更加高效的方式使用quad(其实是一个矩形)加一个叶子的纹理来制作。但是叶子本身是不透明的，那剩下的那张纹理就完全是透明的。 如果你想做这种效果，就按照下面的步骤操作： 再材质的检查器(Inspector)面板，把Rendering Mode设置成Cutout。 然后使用Alpha Cutoff滑动条来调整裁剪阈值。在Albedo贴图中所有alpha值等于或者小于Alpha Cutoff值的像素点都会被隐藏。 下图截取至Unity官方的PBR教程(https://www.youtube.com/watch?v=fD_ho_ofY6A)[需要用梯子]，向你演示了Cutout渲染模式效果如何在几何体上打一个孔洞： 值得注意的是Cutout并不允许几何体背面被看见。在前面的示例中，你不能看到球体的内部体积部分。如果你需要这样的一个效果，你需要创建自己的着色器并且确定几何体的背部不会被踢除。 额外内容 这个知识的演示，使用了Unity商城中的ShaderCalibration Scene免费资源，地址如下[已经失效了]： https://www.assetstore.unity3d.com/en/#!/content/25422。 更多关于albedo和transparency的信息，可以通过下面的链接查询： http://docs.unity3d.com/Manual/StandardShaderMaterialParameterAlbedoColor.html。 " }, { "title": "Unity 5中基于物理原理的渲染", "url": "/game-tech-post-old/posts/Unity-5%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E5%8E%9F%E7%90%86%E7%9A%84%E6%B8%B2%E6%9F%93/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-03-15 00:00:00 +0800", "snippet": "第四章 Unity 5中基于物理原理的渲染基于物理原理的渲染physically-based rendering是Unity5中加入的最大的变化之一，也就是我们常说的PBR。前面的一些章节重复提到过它但是没有却没向大家过多的展现。如果你不仅想知道PBR的工作原理，还想搞明白如何构建它们，那么这一张正是你需要阅读的。在这一章，你将会学习下面的几个知识点： 理解金属质感的设置 向PBR中添加...", "content": "第四章 Unity 5中基于物理原理的渲染基于物理原理的渲染physically-based rendering是Unity5中加入的最大的变化之一，也就是我们常说的PBR。前面的一些章节重复提到过它但是没有却没向大家过多的展现。如果你不仅想知道PBR的工作原理，还想搞明白如何构建它们，那么这一张正是你需要阅读的。在这一章，你将会学习下面的几个知识点： 理解金属质感的设置 向PBR中添加透明度 创建镜子和反射面 烘培场景中的光 介绍 我们在第三章，理解光照模型 中介绍了所有的光照模型，简单的讨论了一下光是如何表现的。在编写它们的时候效率efficiency是最重要的方面。实时渲染的开销是很大的，类似于Lambertian和BlinnPhong这样的光照模型技术，也仅仅是在模拟现实和性能开销中的折中方案。拥有了更加强劲的GPU(graphics processing unit)后，我们就可以编写更加精细的光照模型和渲染引擎，目的就是为了模拟光的真实行为。简单概括前面的来说，这就是PBR后面的哲学。正如它的名字所表达的那样， 它是尽可能的去接近真实的物理，来处理每一个不同材质，让他们看起来都不一样。不仅如此，PBR这个术语被广泛的用于市场营销，它更像是艺术级的渲染(state-of-the-art rendering)，而不是一个简单的技术。Unity5通过引入两个重要的改变，实现了PBR。首先是一个全新的光照模型(叫Standard)。表面着色器允许开发人员指定材质的物理属性，但是他们却没有对它们应用任何的物理原理限制。PBR用新的光照模型来弥补了这个差距，应用了一些物理原理，比如能量守恒(energy conservation)[一个物体反射的光线不可能多于接收的光线]，微表面散射(microsurface scattering) [粗糙表面比光滑表面的反射更没有规律]，菲涅尔反射(Fresnel reflectance)[高光反射出现在掠射角内]，和表面阻塞(surface occlusion)[一些角落的暗部和一些几何体很难照亮]。所有说的这方面，还有一些其他的，都被用来计算标准光照模型。第二方面让PBR开起来如此真实技术叫全局光照(Global Illumination [GI])，它是对基于物理原理的光线传输的模拟。也就是说，如果这些物体是独立的实体，那么它们不会被绘制[不会反光只吸收光的的物体，这种绝对黑体是看不见的]。它们会影响最终的渲染效果，因为光线在碰到其他物体前首先会从它们身上反射。虽然在着色器中不会自动提及这方面，但是对于了解渲染引擎是如何工作来说是很重要的部分。然而令人难过的是，实时的精确模拟光线在物体表面到底是如何反弹，这已经超出了现代GPU的能力范围。Unity5做了一些很聪明的优化，即保持了视觉质量有没有牺牲性能。然而大部分的一些进阶技术(比如反射) 需要用户的输入。上面说的这些方面都会在本章介绍。 不过希望各位留意的是，即使是PBR或者GI这些技术也不能保证你的游戏可以获得照片级的画质。要获得照片级的画面是一项很有挑战性的工作，跟每一门艺术一样，需要非常专业和杰出的技巧。 理解金属质感的设置Unity5提供了两种不同类型的PBR着色器； 它们指的是材质的检查器面板(Inspector)中的下拉列表中的Standard着色器和Standard (Specular setup)着色器。两者的主要区别在于前者为我们暴露了Metallic这个属性，而后者没有Metallic，但暴露了Specular这个属性。metallic 属性和specular 属性代表了初始化PBR材质不同方式。推动PBR的概念之一是提供给开发人员和艺术家一种有目的性的，基于物理相关的一些属性，让他们可以调整和把玩它们。 有些材质的属性更容易用来表示它们的质金属质感强度指标，而其他的另一些属性则直接于定义了光是如何反射的，也很重要。如果你过去使用过Unity4，那么对于Standard (Specular setup)着色器应该看起来更熟悉。这个知识点会教你如何有效的使用金属质感设置(metallic setup)。有个重点需要各位注意，金属质感的工作流不仅仅用于金属材质；它是根据表面的金属质感或者非金属质感来定义材质的视觉效果的一种方式。尽管呈现的是两种不同的类型的着色器，但这金属(Metallic )和高光(Specular)这两种方案通常来说是相等的表示。 就像Unity文档中所展示的：http://docs.unity3d.com/Manual/StandardShaderMetallicVsSpecular.html，这两种设置都可以创建同样的材质(如下图所示)： 始前准备 在这个知识点中我们将用Unity5提供的标准着色器，所以我们没有必要重新创建一个。我们通过下面的步骤来开始学习这个知识点： 创建一个新的材质球。 在这个材质球的检查器(Inspector)面板，确保Shader这个下拉菜单中选择的是Standard。 同时你需要一个带有纹理的3D模型。 操作步骤 在标准着色器中有两个主要的纹理需要配置：Albedo和Metallic。为了有效地使用金属化工作流，我们需要正确的初始化这些映射： Albedo映射应该用3D模型的unlit(不受光照影响)纹理初始化。 创建Metallic映射之前，先复制一份文件用留给Albedo映射。你可以在项目(Project)面板中中选择要复制的贴图，然后通过快捷键Ctrl + D复制。 用白色 (#000000)给表示纯金属的材质的贴图区域上色。而其他要用的的颜色都用黑色(#000000)。灰色的着色应该用于表示满是灰尘的，风化的和磨损的金属表面，还有生锈表面，有刮擦的绘画等等。事实上，Unity仅仅使用了红颜色(R)通道来保存金属质感的值；而绿颜色通道(G)和蓝颜色通道(B)则被忽略了。 用图片的的alpha通道来提供材质的光滑度(Smoothness)信息。 把金属质感(Metallic)贴图关联到材质球中。金属质感(Metallic)和光滑度(Smoothness)的滑动条都会消失，因为这两个属性现在由贴图控制了。 原理介绍 旧着色器中的光照模型条件让艺术家们很难创造出贴近现实视觉效果。之所以会这样，是因为旧的表面着色器中所有的属性间没有关联。通过介绍金属质感的工作流，Unity5将强制对游戏对象的表现将添加更多系统参数，这样的话艺术家们就能更易创建合理的材质。 金属是电的良导体；而光是电磁波的一种形式，也就是说相比于不良导体(经常被称为绝缘体(insulators))，几乎所的金属都有相似的行为表现。导体的反射率很高，能反射大部分的光子(70-100%)。然后剩余没有被反射的光就被吸收了，不是漫反射出来，也就是说导体的漫反射元素很黑[其实我觉得翻译成很低也能说的通]。相反的是，绝缘体反射率很低(%4)而剩余的光在表面被散射掉了，所以漫反射效果明显。 在标准着色器中，纯金属材质拥有较黑的漫反射元素并且它的高光反射的颜色由Albedo贴图来定义。相反的，对于纯粹的非金属材料来说，Albedo贴图定义的是它们的漫反射元素； 而它们的高光高光颜色其实是由射进来的光颜色决定的遵守这些规则在金属工作流中可以把albedo和specular结合进Albedo贴图中去，实行精确的物理行为。在牺牲材质视觉效果控制的前提下，这能让我们节省更多的空间，而且极大的提升运行速度。 额外内容 想获得更多关于金属质感的设置的信息，你可以参考下面链接的信息： 校准图表(Calibration chart)：如何校准一个金属质感的材质球 (http://blogs.unity3d.com/wp-content/uploads/2014/11/UnityMetallicChart.png) 材质图表(Material chart): 如何为一些常用的材质初始化标准着色器的参数 (http://docs.unity3d.com/Manual/StandardShaderMaterialCharts.html) Quixel MEGASCANS: 一个巨量的材质素材仓库[网站]，还包括纹理和PBR的参数设置[网站已经变了，我纠正一下] (https://quixel.com/megascans/home/) PBR纹理的转换：传统的着色器如何转换成PBR着色器 (http://www.marmoset.co/toolbag/learn/pbr-conversion) Substance Designer：一个基于节点的跟PBR一起工作的额软件 (https://www.allegorithmic.com/products/substance-designer) 基于物理原理渲染的理论：一个关于PBR的完全教程[源网址已经变了，帮大家重新找到了] (https://academy.substance3d.com/courses/the-pbr-guide-part-1-zh) " }, { "title": "创建各向异性类型的高光反射着色器", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E5%90%84%E5%90%91%E5%BC%82%E6%80%A7%E7%B1%BB%E5%9E%8B%E7%9A%84%E9%AB%98%E5%85%89%E5%8F%8D%E5%B0%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-02-26 00:00:00 +0800", "snippet": "创建各向异性类型的高光反射着色器各向异性(Anisotropic)类型可以用来模拟高光或者反射，常用于表面凹槽的方向和高光在垂直方向上的扭曲形变。当你想模拟金属抛光表面的时候这种类型的着色器就会非常有用，因为这种表面并不干净，光滑和明亮。 你可以想象当你看CD或者VCD光盘的数据那面时的高光或者底面被打磨过的金属盘子和盆子。 当你仔细检查这些表面的时候你会发现，表面的这些沟纹是有方向的，通常...", "content": "创建各向异性类型的高光反射着色器各向异性(Anisotropic)类型可以用来模拟高光或者反射，常用于表面凹槽的方向和高光在垂直方向上的扭曲形变。当你想模拟金属抛光表面的时候这种类型的着色器就会非常有用，因为这种表面并不干净，光滑和明亮。 你可以想象当你看CD或者VCD光盘的数据那面时的高光或者底面被打磨过的金属盘子和盆子。 当你仔细检查这些表面的时候你会发现，表面的这些沟纹是有方向的，通常就是被抛光的方向。当你对这样的表面应用高光时，在垂直方向上会被扭曲。这个知识点中我们会向你介绍不同的抛光表面高光概念。在将来的一些知识点中，我们会探索如何使用这个知识点介绍的一些概念来获得一些类似于头发的扭曲反射效果，但是在这里我们还是要先学习这个技术的一些原理知识。我们自定义的各向异性着色器将使用下面这个着色器作为参考：http://wiki.unity3d.com/index.php?title=Anisotropic_Highlight_Shader下图展示了使用各向异性(Anisotropic)着色器能获得的不同类型高光效果： 始前准备 让我们开始学习新的知识点吧，先按照下面的步骤在场景中创建一个着色器，材质和一些光源： 创建一个新的场景，在场景中添加一些游戏对象，添加一个平行光源，这样我们好可视化的调试我们的着色器。 创建一个新的着色器和材质，它们都应用到刚刚创建的游戏对象上去。 最后，我们需要某种法线贴图，它能指出我们各向异性类型高光的方向。 下图展示的就是这个知识点要用的各向异性类型的法线贴图。在本书的支持网页中可以获得[就在本书附带的工程代码中，获取方法前面有介绍]: https://www.packtpub.com/books/content/support 操作步骤 为了获得各向异性效果，我们需要对我们前面创建的着色器进行如下的修改： 首先得再着色器中添加我们需要用到的一些属性。这些属性允许我们控制很多中艺术效果从而最终决定表面的效果呈现： {_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)_MainTex (\"Base (RGB)\", 2D) = \"white\" {}_SpecularColor (\"specular Color\", Color) = (1,1,1,1)_Specular (\"Specular Amount\", Range(0,1)) = 0.5_SpecPower (\"Specular Power\", Range(0,1)) = 0.5_AnisoDir (\"Anisotropic Direction\", 2D) = \"\" {}_AnisoOffset (\"Anisotropic Offset\", Range(-1,1)) = -0.2} 接着我们要让我们的SubShader{}代码块跟我们的属性(Properties)块关联起来，这样才能让我们使用属性(Properties)中的数据： sampler2D _MainTex;sampler2D _AnisoDir;float4 _MainTint;float4 _SpecularColor;float _AnisoOffset;float _Specular;float _SpecPower; 接下来我们要创建我们自己的光照函数，用来处理物体表面的各向异性效果。我们的代码如下： fixed4 LightingAnisotropic(SurfaceAnisoOutput s, fixed3 lightDir, half3 viewDir, fixed atten){ fixed3 halfVector = normalize(normalize(lightDir) + normalize(viewDir)); float NdotL = saturate(dot(s.Normal, lightDir)); fixed HdotA = dot(normalize(s.Normal + s.AnisoDirection),halfVector); float aniso = max(0, sin(radians((HdotA + _AnisoOffset) * 180))); float spec = saturate(pow(aniso, s.Gloss * 128) * s.Specular); fixed4 c; c.rgb = ((s.Albedo * _LightColor0.rgb * NdotL) + (_LightColor0.rgb * _SpecularColor.rgb * spec)) * atten; c.a = s.Alpha; return c;} 为了使用我们新的光照函数，我们需要修改#pragma指示，让Unity去使用我们的光照函数，而不是Unity内建的光照函数。我们同时还要告诉着色器目标着色器模式是3.0，这样我们可以让我们的程序拥有更多的空间用来存放纹理： CGPROGRAM#pragma surface surf Anisotropic#pragma target 3.0 为了让各向异性法线贴图能使用它自己的UV数据，我们需要再输入(Input)结构中添加如下定义代码。 我们其实并不是说完全需要这样做，因为我们也可以使用主帖图上的UV数据，但是如果有它自己单独UV数据的话我们就能单独控制金属抛光效果的截取，这样我们就可以把它进行缩放任何我们想要的大小： { float2 uv_MainTex; float2 uv_AnisoDir;}; 我们还需要定义SurfaceAnisoOutput这个输出结构体： struct SurfaceAnisoOutput{ fixed3 Albedo; fixed3 Normal; fixed3 Emission; fixed3 AnisoDirection; half Specular; fixed Gloss; fixed Alpha;}; 最后，我们需要通过表面函数surf()给我们的光照函数传递正确的数据。这样，我们将会获得我们各向异性法线贴图的每个像素信息，然后像下面的代码一样设置我们的高光参数： void surf(Input IN, inout SurfaceAnisoOutput o){ half4 c = tex2D(_MainTex, IN.uv_MainTex) * _MainTint; float3 anisoTex = UnpackNormal(tex2D(_AnisoDir, IN.uv_AnisoDir)); o.AnisoDirection = anisoTex; o.Specular = _Specular; o.Gloss = _SpecPower; o.Albedo = c.rgb; o.Alpha = c.a;} 各向异性法线贴图允许我们给出表面的方向并且能帮助我们分散物体表面周围的高光效果。下图就是我们的各向异性着色器的效果： 原理介绍 我们按部分来看看这个着色器的核心内容并且解释为什么我们能获得这样的效果。这里我们大部分都讲光照函数部分，因为除此之外的内容对于当前的你来说都能自己理解。 首先我们定了我们自己的结构体SurfaceAnisoOutput。我们之所以这样么做是因为我们需要获得各向异性法线贴图的每个像素信息，而再表面着色器中获得这个的唯一方法就是在surf()函数中使用tex2D()函数获取。 下面的代码就是我们在着色器中自定义的输出结构体： struct SurfaceAnisoOutput{ fixed3 Albedo; fixed3 Normal; fixed3 Emission; fixed3 AnisoDirection; half Specular; fixed Gloss; fixed Alpha;}; SurfaceAnisoOutput输出结构体是光线函数和表面函数进行交互的中间数据。在我们这个例子中，surf()中我们把每个像素的纹理信息都保存在了anisoTex中，接着把anisoTex保存在了AnisoDirection变量中，再然后AnisoDirection被传递到了表面结构体SurfaceAnisoOutput中。一旦我们拥有了这个表面结构体，我们就能在我们的光照函数中使用这每个像素的纹理信息了。 s.AnisoDirection. 当我们设置好这部分数据关联后，我们就可以着手我们具体的光照计算了。跟往常不一样，这里我们使用了中间向量，这样我们就不用去进行完整的反射计算和漫反射计算，因为这些计算都需要让顶点的法向量跟光线或光的方向进行点积的运算。我们的Cg代码如下所示: fixed3 halfVector = normalize(normalize(lightDir) + normalize(viewDir));float NdotL = saturate(dot(s.Normal, lightDir)); 之后，我们开始对高光进行具体的修改，以便获得我们想要的视觉效果。我们首先把顶点法线跟我们各向异性法线贴图的顶点相加得到和，再对和进行标准化，然后把标准化后的向量跟前面步骤获得的中间向量(halfVector)进行点积操作。参考它跟各向异性法线贴图的点积，当值等于1时，说明表面法线跟中间向量(halfVector)平行，当值等于0时，它们相互垂直。最后我们还要用sin()函数来修改这个值，这样根据中间向量(halfVector)我们基本能获得一个更暗一些的中间亮度，并且最终获得一个环状的效果。所有上面提及的操作都包含在了下面两行Cg代码中： fixed HdotA = dot(normalize(s.Normal + s.AnisoDirection), halfVector);float aniso = max(0, sin(radians((HdotA + _AnisoOffset) * 180))); 最后，我们通过s.Gloss对aniso进行指数放大，从而放大效果， 然后再通过乘以s.Specular来全局减少它的强度： float spec = saturate(pow(aniso, s.Gloss * 128) * s.Specular); 这个效果非常适合创建一些更加高级的金属类型的表面，尤其时那些表面被有向抛过光的。当然它也非常适合头发反光或者任何表面有方向性的软表面。下图展示了各向异性光照计算的最终显示效果： " }, { "title": "创建一个phong镜面类型的高光反射着色器", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAPhong%E9%95%9C%E9%9D%A2%E7%B1%BB%E5%9E%8B%E7%9A%84%E9%AB%98%E5%85%89%E5%8F%8D%E5%B0%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-02-25 00:00:00 +0800", "snippet": "创建一个Phong类型类型的高光反射着色器一个物体表面的高光，可以简单的理解为它表面的亮度。这种类型的着色器常用于视野特效(view-dependent effects)。这是因为 为了在着色器中获得贴近现实的高光效果，你需要考虑到摄像机和人的朝向因素。而Phong高光效果是最基础和性能较好的一种着色器效果。它根据人的朝向和光的反射方向，通过计算获得一个有方向的反射。 在应用程序中，这种高光...", "content": "创建一个Phong类型类型的高光反射着色器一个物体表面的高光，可以简单的理解为它表面的亮度。这种类型的着色器常用于视野特效(view-dependent effects)。这是因为 为了在着色器中获得贴近现实的高光效果，你需要考虑到摄像机和人的朝向因素。而Phong高光效果是最基础和性能较好的一种着色器效果。它根据人的朝向和光的反射方向，通过计算获得一个有方向的反射。 在应用程序中，这种高光模型非常常见，涵盖游戏行业到电影等产业。虽然它在高光反射模型的精确度上不是最接近现实的，但是在大多数情况下，它大致都能满足而且性能不赖。此外，如果你的游戏对象离摄像机很远，就没有必要在提供准确的高光，这对你的高光效果着色器来说是好事。在这个知识点中，我们会涉及到如何使用表面着色器的输入(Input)结构体中的一些新参数进行逐顶点和逐像素的操作。我们会了解它们之间的区别，而且还会讨论什么时候以及为什么要用这两种不同的实现方式，来应对不同的情况。 始前准备 我们按照下面的步骤来学习这次的知识点： 分别创建一个新的着色器，材质和游戏对象，为了在后面你容易照到它们，请给它们恰当命名。 创建一个新场景，在创建一个新的游戏对象，把着色器应用到材质，然后再把材质应用到游戏对象上。 再添加一个平行光源，这是为了让我们方便看我们着色器代码的高光效果。 操作步骤 请按照下面的步骤创建一个Phong类型的光照模型： 此时你可能发现了一个模式，在我们开始写着色器的时候都有的步骤：着色器属性的创建。所以，让我们先在着色器中添加下面的一些属性： Properties{_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)_MainTex (\"Base (RGB)\", 2D) = \"white\" {}_SpecularColor (\"Specular Color\", Color) = (1,1,1,1)_SpecPower (\"Specular Power\", Range(0,30)) = 1} 接下来在CGPROGRAM块中的SubShader{}块中，添加与之对应的一些变量： float4 _SpecularColor;sampler2D _MainTex;float4 _MainTint;float _SpecPower; 现在我们要添加我们自定义的光照模型，因为我们要计算自己的Phong高光。如果你现在还不能理解下面的代码也不用担心；在原理介绍的部分我们会解释每一行代码的作用。在着色器的SubShader{}中添加下述代码： fixed4 LightingPhong (SurfaceOutput s, fixed3 lightDir, half3 viewDir,fixed atten){ // Reflection float NdotL = dot(s.Normal, lightDir); float3 reflectionVector = normalize(2.0 * s.Normal * NdotL - lightDir); // Specular float spec = pow(max(0, dot(reflectionVector, viewDir)), _SpecPower); float3 finalSpec = _SpecularColor.rgb * spec; // Final effect fixed4 c; c.rgb = (s.Albedo * _LightColor0.rgb * max(0,NdotL) * atten) + (_LightColor0.rgb * finalSpec); c.a = s.Alpha; return c;} 最后，我们还要告诉CGPROGRAM块，需要用我们自定义的光照模型而不是Unity内建的光照模型。 按照下面的步骤修改#pragma指示： CPROGRAM#pragma surface surf Phong 下图演示了我们自定义的Phong光照模型的效果，里面的反射算法也是我们自己的： 原理介绍 我们现在先把光照函数放一放，因为着色器剩下的部分你应该感到很熟悉了。 在上一个知识点中，我们使用的光照函数只提供了光的方向，lightDir。Unity本身有一些现成的光照函数配置可以使用，其中一个就是视角方向，viewDir。可以根据下表或者下面的这个链接https://docs.unity3d.com/Manual/SL-SurfaceShaderLighting.html详细了解： Not view dependent half4 Lighting Name You choose (SurfaceOutput s, half3 lightDir, half atten); View-dependent half4 Lighting Name You choose (SurfaceOutput s, half3 lightDir, half3 viewDir, half atten); 在我们的这个例子中，我们处理的是一个高光着色器，所以我们需要基于视角的光线函数结构。所以我们需要编写下面的着色器代码： CPROGRAM#pragma surface surf Pongfixed4 LightingPhong (SurfaceOutput s, fixed3 lightDir, half3 viewDir,fixed atten){ // ...} 这样写会告诉着色器我们要创建我们自己的基于视角的着色器。请注意，你声明的的光线函数的名字要跟#pragma指示那里保持一致[#pragma指示那里省略了前缀“Lighting”]，否则Unity没有办法定位到你的光照模型。 在Phong类型光照模型中的这部分内容，我们用下面的图来描述。L是光的方向(R是跟它成对出现的反射光线方向)，N是物体表面的法线方向。我们在前面讲解Lambertian光照模型的时候讲到过，V是我们没有讲到的，就是这里的视角方向： Phong光照模型给我们呈现了反射表面的最终光强，它由两部分得出：他的的漫反射颜色(diffuse color)和高光值(Specular value)，如下所示：\\[I = D + S\\] 漫反射部分D是来自Lambertian光照模型，这部分没有改变过：\\[D = N \\cdot L\\] 高光部分S的定义如下：\\[S = (R \\cdot V)^{p}\\] 这里,，p 是高光的力度，就是在着色器中的_SpecPower。唯一不知道参数就是R，这是光线L根据法线方向N计算出来的反射光。在向量的代数运算中，它可以通过下面的表达式计算出来：\\[R = 2N \\cdot (N \\cdot L) - L\\] 这个公式就是着色器中下面的这行代码的具体含义： float3 reflectionVector = normalize(2.0 * s.Normal * NdotL - lightDir); 这能让法线有偏向光的效果；当法向量朝向远离光的方向时，反射光线的方向就会越接近入射光线的方向。 下面的图片能给帮助你更好的理解。而产生图中那样的调试效果的脚本，你可以从本书的支持网页中下载，链接：https://www.packtpub.com/support/code-downloads[记得在下面第二张图中的位置输入书名]: 下图展示了我们的Phong高光着色器最终的计算结果： " }, { "title": "创建 blinnphong 类型的高光反射着色器", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA-BlinnPhong-%E7%B1%BB%E5%9E%8B%E7%9A%84%E9%AB%98%E5%85%89%E5%8F%8D%E5%B0%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-02-25 00:00:00 +0800", "snippet": "创建 BlinnPhong 类型的高光反射着色器Blinn是另一种计算和模拟高光的更有效的方法。它只要视角方向和光线方向向量的中间向量就可以计算出来。这个高光是Jim Blinn带入到Cg世界中的。 他发现比起计算反射向量来，只要中间向量的效率更好。它减少了代码量和处理时间。 如果你在UnityCG.cginc文件中查看了Unity内建的BlinnPhong光照模型的话，它也是用了中间向量，...", "content": "创建 BlinnPhong 类型的高光反射着色器Blinn是另一种计算和模拟高光的更有效的方法。它只要视角方向和光线方向向量的中间向量就可以计算出来。这个高光是Jim Blinn带入到Cg世界中的。 他发现比起计算反射向量来，只要中间向量的效率更好。它减少了代码量和处理时间。 如果你在UnityCG.cginc文件中查看了Unity内建的BlinnPhong光照模型的话，它也是用了中间向量，因此它被命名为BlinnPhong 。它只是完整Phong光照计算中的一种简单的版本。 始前准备 让我们按照下面的步骤开始学习这个知识点： 这次我们不创建新的场景，就用原来场景和场景内的对象就好，然后我们需要创建一个新的着色器和材质，并且把名字都叫BlinnPhong。 当我们创建好着色器后，双击它，开始编辑。 操作步骤 按照下面的步骤走，我们来创建BlinnPhong光照模型： 首先，我们需要在着色器的属性(Properties)块中添加我们需要用到的属性，这样好让我们控制高光效果： Properties{ _MainTint (\"Diffuse Tint\", Color) = (1,1,1,1) _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _SpecularColor (\"Specular Color\", Color) = (1,1,1,1) _SpecPower (\"Specular Power\", Range(0.1,60)) = 3} 接下来在CGPROGRAM块中添加与属性对应的变量，这样我们就可以获得来自属性(Properties)中的数据： sampler2D _MainTex;float4 _MainTint;float4 _SpecularColor;float _SpecPower; 接下来就是要创建我们自定义的光照模型了，用来处理漫反射和高光的计算，代码如下所示: fixed4 LightingCustomBlinnPhong (SurfaceOutput s, fixed3 lightDir,half3 viewDir, fixed atten){ float NdotL = max(0,dot(s.Normal, lightDir)); float3 halfVector = normalize(lightDir + viewDir); float NdotH = max(0, dot(s.Normal, halfVector)); float spec = pow(NdotH, _SpecPower) * _SpecularColor; float4 c; c.rgb = (s.Albedo * _LightColor0.rgb * NdotL) + (_LightColor0.rgb * _SpecularColor.rgb * spec) * atten; c.a = s.Alpha; return c;} 为了完成我们的着色器，我们还需要告知着色器的CGPROGRAM块使用我们自定义的光照模型而不是Unity内建的，修改#pragma指示，改成如下代码所示： CPROGRAM#pragma surface surf CustomBlinnPhong 下图演示了我们自己的BlinnPhong光照模型的效果： 原理介绍 BlinnPhong高光跟Phong高光很像，但是前者的效率比后者要高，因为后者用更优化的代码实现了几乎一样的效果。在介绍基于物理原理的渲染之前，这种方法是Unity4中高光反射的默认选择。计算反射向量R的代价通常很高。BlinnPhong高光并没有计算它，而是用介于视角V和光线L之间的中间向量H： 跟完整的计算出我们的反射向量不同，我们转而去获得介于视角方向和光线方向之间的中间向量，基本模拟了反射向量。跟Phong高光比起来，这种方法更加贴近真实的物理现象，但是我们依然认为，向你介绍所有的这些方法依然是很有必要的：\\[S_{Phong} = (R \\cdot V)^p, S_{BlinnPhong} = (N \\cdot H)^p\\] 根据向量的代数计算，中间向量可以用下面的方法算出：\\[H\\frac{V+L}{|V+L|}\\] 这里 的$|V+L|$表示向量$V+L$的长度。在Cg中，我们简单的将视角方向和光线方向相加并且对结果进行标准化成一个单位向量： float3 halfVector = normalize(lightDir + viewDir); 然后，我们简单的对顶点的法线和我们的中间向量求点积，从而获得我们主要的高光值。在这之后，我们把它用指数_SpecPower进行指数运算并且乘以高光颜色变量_SpecularColor。跟Phong高光比起来，整个算法在代码量和运算量上都要少很多，但在很多实时渲染情况中，它依然能给我们带来很好的高光效果。 额外内容 在这一章介绍的光照模型都非常的简单；现实中我们是找不出完全粗糙或完全光滑的材料的。要知道，生活中复杂的材料是很常见的，比如衣服，木材和皮肤等等，这些材质涉及到物体表面下层的光如何散射的知识。 我们用下面的表格来回顾我们之前学些过的不同光照模型知识： Technique Type Unity 5 shader Light Intensity (I) Lambertian Diffuse Legacy Shaders | Diffuse $I = N \\cdot L$ Phong Specular   $I = N \\cdot L + (R \\cdot V)^p$         $R = 2N\\cdot(N \\cdot L) - L$ BlinnPhong Specular Legacy Shaders | Specular $I = N \\cdot L +(N \\cdot H)^p $      $H = \\frac{V+L}{|V+L|}$ 下面的链接有一些关于粗糙表面的更有趣的光照模型，比如Oren-Nayar： https://en.wikipedia.org/wiki/Oren%E2%80%93Nayar_reflectance_model " }, { "title": "创建一个toon风格的着色器", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAToon%E9%A3%8E%E6%A0%BC%E7%9A%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-02-23 00:00:00 +0800", "snippet": "创建一个Toon风格的着色器Toon着色器(toon shading)是游戏中最常使用的效果之一，也被称作(AKA)cel shading(cel是celluloid的缩写[中文也叫 赛璐珞])。它是一种非真实渲染技术，可以让3D模型呈现一种平面效果。许多游戏中用这种着色器把3D的物体渲染成一种手绘物体的效果。下图中你能看到这两者的区别，右边的是标准着色器，左边的是Toon着色器：如果只使用...", "content": "创建一个Toon风格的着色器Toon着色器(toon shading)是游戏中最常使用的效果之一，也被称作(AKA)cel shading(cel是celluloid的缩写[中文也叫 赛璐珞])。它是一种非真实渲染技术，可以让3D模型呈现一种平面效果。许多游戏中用这种着色器把3D的物体渲染成一种手绘物体的效果。下图中你能看到这两者的区别，右边的是标准着色器，左边的是Toon着色器：如果只使用表面函数(surface functions)虽然也能获得这样的效果，但是花费性能和时间的代价太大了。表面函数仅仅对材质的属性起作用，而对材质的具体光照环境无能为力。因为toon着色器需要改变光的反射方式，所以我们接下来要创建我们自己的光照模型。 始前准备 开始学习这个知识点之前，我们先创建一个着色器和对应的材质球，而且需要导入一个特殊的纹理，步骤如下： 创建一个新的着色器；在这例子中，我们会用上一个知识点的着色器进行扩展 为着色器创建一个新的材质，并且把它应用到3D模型中。 拥有曲面的模型对于toon着色器来说最好。 这个知识点需要一张额外的纹理，叫做ramp贴图[如果要全译，我把它叫梯度贴图]。有一点很重要，在导入的时候把Wrap Mode改为Clamp，如果你想让颜色的边缘变得灵敏，就把Filter Mode设置为Point ： 操作步骤 通过下面的步骤我们可以获得toon风格的特殊审美呈现： 添加一个新的叫_RampTex纹理属性： _RampTex (\"Ramp\", 2D) = \"white\" {} 同时在CGPROGRAM块中添加对应的变量： sampler2D _RampTex; 修改#pragma指示 ，从而让着色器使用一个叫LightingToon()的函数： #pragma surface surf Toon 使用下面这个光照模型： fixed4 LightingToon(SurfaceOutput s ,fixed3 lightDir,fixed atten){ half NdotL = dot(s.Normal,lightDir); NdotL = tex2D(_RampTex,fixed2(NdotL,0.5)); fixed4 c; c.rgb = s.Albedo * _LightColor0.rgb*NdotL*atten; c.a = s.Alpha; return c;} 原理介绍 toon风格着色器的主要特征是它的光的渲染方式；表面并非均匀的着色。为了能达这种效果，我们需要一张ramp贴图。他的作用是对Lambertian的光线强度NdotL重新映射，然后把值赋值给另一个值。我们使用一张ramp贴图而不是一个梯度值，是为了强制光线按照步骤渲染。下图展示了ramp贴图是如何纠正光的强度的： 相关补充 我们有很多不同方式来获得toon着色器效果。 我们可以使用不同的ramp贴图来让我们的模型看起来更有吸引力，这就需要你们自己去试试了，然后找到一张你认为最好的。 还有另一种可选方法对纹理进行梯度采样，就是通过对光强度NdotL进行截断取值，这样就只能在0到1的范围内给它赋值特定的值： fixed4 LightingToon(SurfaceOutput s ,fixed3 lightDir,fixed atten){ half NdotL = dot(s.Normal,lightDir); half cel = floor(NdotL * _CelShadingLevels)/(_CelShadingLevels - 0.5); half4 c; c.rgb = s.Albedo * _LightColor0.rgb*cel*atten; c.a = s.Alpha; return c;} 截断取值部分的代码中，NdotL乘以了倍数_CelShadingLevels并且把它进行了取整，而得到了一个整数，接着又把结果除了回去。通过上面的这些步骤后， 变量cel被赋值，这个值的范围是0到1之间的值，而且这个值跟_CelShadingLevels相等。有了这个，我们就不再需要ramp纹理了而且所有的颜色梯度也在这个范围。如果你正在你的着色中实现这个功能，不要忘记在你的着色器中添加_CelShadingLevels属性。 " }, { "title": "理解光照模型", "url": "/game-tech-post-old/posts/%E7%90%86%E8%A7%A3%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-02-22 00:00:00 +0800", "snippet": "第三章 理解光照模型在前面的那些章节中，我们介绍了表面着色器并且还理解了如何修改一些物理属性(比如Albedo和Specular)来模拟不同的材质。这些到底是如何工作的呢？每个表面着色器中最重要的部分一一光照模型lighting model。它的功能就是接受这些参数然后计算每一个像素点的最终着色。Unity通常会对开发者隐藏这部分，因为如果想要编写一个光照模型的话，你就必须要去理解光在物体表...", "content": "第三章 理解光照模型在前面的那些章节中，我们介绍了表面着色器并且还理解了如何修改一些物理属性(比如Albedo和Specular)来模拟不同的材质。这些到底是如何工作的呢？每个表面着色器中最重要的部分一一光照模型lighting model。它的功能就是接受这些参数然后计算每一个像素点的最终着色。Unity通常会对开发者隐藏这部分，因为如果想要编写一个光照模型的话，你就必须要去理解光在物体表面是如何反射和折射的。这个章节中我们会毫无保留的向你展示光照模型是如何工作的，并且给你介绍一些你自己创建光照模型所需要的一些基础知识。这一章中，我们会学习下面所列的知识点： 创建一个自定义的漫反射光照模型 创建一个Toon风格的着色器 创建一个Phong类型类型的高光反射着色器 创建 BlinnPhong 类型的高光反射着色器 创建各向异性类型的高光反射着色器 介绍 想要模拟光的工作方式是一项非常具有挑战性的工作，同时也非常消耗计算资源。在之前的很早一段时间内，游戏中使用的都是一些非常简单的光照模型，效果看起来差到难以置信。尽管现在的3D游戏引擎已经使用了基于物理原理的渲染器，但是有些更简单的光照模型技术还是值得我们去探索的。但有时，我们不得不面对资源紧张的现实，没有办法在这些资源有限的设备上完整实现光照模型，比如我们的移动设备。所以你想在这上面实现自己的光照模型，那么你就很有必要了解这些简单的光照模型。 创建一个自定义的漫反射光照模型如果你对Unity4很了解的话，你应该知道Unity提供的默认的着色器是基于一个叫Lambertian reflectance的光照模型。我们会在这个知识点向你展示如何创建一个自定义的光照模型，并且解释它后面的数学原理和实现方式。下面的两张图分别展示了标准着色器Standard Shader (右)和diffuse Lambert着色器对同一个几何体进行渲染后，不同的显示效果：基于Lambertian reflectance光照模型的着色器是典型的非真实渲染着色器；我们现实生活中没有物体会看起来像那样。然而Lambert 着色器依然能在一些低多边形风格的游戏中经常看到，因为跟一些复杂的几何体比起来，它们的三角面数量对比非常明显。用于计算Lambertian反射的光照模型非常高效，这特别适合移动端的游戏。Unity其实已经提供了光照函数给我们，好让我们能在着色器中使用。它就是Lambertian光照模型。它是光反射模拟的一种更基础更有效率的形式，你能在当今的很多游戏中看到它的存在。 因为它们已经内建在了Unity的表面着色器语言中，所以我从这个开始和基于它开始构建也不失为一个好的选择。你也可以在Unity用户手册中找到一个例子，但我们还是会更深入学习，从而向你解释这些数据是从哪里来的以及为什么它是那样工作的。这些可以为设置光照模型打下一个很好的基础，这些知识将来也能在后面的章节中对我们有帮助。 始前准备 让我们从实现下面几个步骤开始： 创建一个新的着色器并且给它命名好。 创建一个新的材质球，命名好，并且把上一步新建的着色器应用于该材质。 接下来，创建一个球形对象，并且把它大致放在场景中间的位置。 最后，我们创建一个方向光源，让光找到游戏对象上。 当你在Unity中设置好这些资源后， 你就会有一个类似于下图的场景： 操作步骤 Lambertian反射可以在着色器中修改下面的代码实现： 首先在着色器的属性Properties块中添加下面的属性： _MainTex(\"Texture\", 2D) = \"white\" 修改着色器的#pragma指示符，从而让着色器使用我们自定义的光照模型，而不是标准Standard： #pragma surface surf SimpleLambert 使用一个非常简单的表面函数surface function，这个函数仅仅通过它的UV数据对纹理进行采样： void surf (Input IN, inout SurfaceOutput o){ o.Albedo = tex2D(_MainTex,IN.uv_MainTex).rgb;} 添加一个叫做LightingSimpleLambert()的函数，这个函数包含了下面实现Lambertian反射的代码： half4 LightingSimpleLambert(SurfaceOutput s,half3 lightDir,half atten){ half NdotL = dot(s.Normal,lightDir); half4 c; c.rgb = s.Albedo * _LightColor0.rgb * (NdotL*atten*1); c.a = s.Alpha; return c;} 原理介绍 如我们前面 第一章，创建你的第一个着色器 所看到的那样，#pragma指示用于指定我们该用哪个表面函数。选择不同的光照模型都是按照下面同一种方法：SimpleLambert 会强制Cg 去寻找一个叫做LightingSimpleLambert()函数。注意开始前面的Lighting，只是在指示中被省略了。 这个光照函数接收3个参数：表面输出结构体surface output(它包含了物理属性比如albedo和transparency)，光照照进来的方向direction和光的衰减attenuation。 根据Lambertian 反射原理, 表面反射光线的数量由表面法线跟入射光线的夹角决定。如果你玩过台球，那么你应该对这个概念比较熟悉；球的方向由球的入射方向跟球桌对应边缘的夹角决定。如果你以90度击球，这个球会垂直返回；如果你以一个非常小的角度击球，球的方向几乎改变很少。Lambertian光照模型跟这个很像；如果光以90度的方式照到一个三角面上，所有光线都会被反射回来。入射的角度越小，返回来的光线也会越少。下面的图片解释了这个概念： 把这个简单的概念转换成数学概念。在向量代数中，两个单位向量的夹角可以通过点积dot product计算 。当点积的值为零，两个向量垂直，也就是说它们之间的夹角是90度。当点积为1(或或者-1)时，那么这连个向量相互平行。在Cg语言中的函数dot()，以极其高效的方式实现了点积。 下图展示了一束阳光照射到了一个复杂的表面。L 指光的方向(就是着色器中的lightDir)，N是表面的法线。光线以相同的角度反射，反射角跟入射角相同： Lambertian反射简单的使用 NdotL点积作为光强度的相乘的系数： I = N * L 当N 跟 L 平行的时候，光线会反射回来，从这个角度看这个几何图形会非常的亮。_LightColor0这个变量包含了对光进行计算后的到的颜色。 注意 Unity5之前的引擎，光强(intensity of the lights)是不一样的。如果你使用的是基于Lambertian反射模型的旧的漫反射着色器，你会发现NdotL乘了两个参数：是(NdotL * atten * 2)而不是(NdotL * atten)。如果你从Unity4中导入的自定义的着色器，需要你手动纠正这点。而Unity自带的一些老的着色器在设计的时候已经考虑到这点了，帮你纠正了。 当点积是负数的时候，这个光是来自三角面的背面。 这对不透明的几何体没有问题，因为摄像机只会渲染朝前面向摄像机的三角面，否则就会被剔除，不去渲染。 这个基本的Lambert光照模型很适合用于构建自己的着色器原型，因为它已经有了着色器中光照模型的核心功能。 Unity已经为我们创建Lambert光照模型提供了原型。在你的Unity安装目录下的Editor/Data/CGIncludes文件夹内照到UnityCG.cginc文件，会发现其实已经有Lamber和BlinnPhong光照模型了。当你使用#pragma surface surf Lambert指示编译着色器时，等于是告诉着色器请使用Unity提供的UnityCG.cginc文件中的Lambert光照模型，这样我们就不用重复造轮子。我们会在这章的稍后部分探索BlinnPhong光照模型。 " }, { "title": "在地形的表面绘制一个圆", "url": "/game-tech-post-old/posts/%E5%9C%A8%E5%9C%B0%E5%BD%A2%E7%9A%84%E8%A1%A8%E9%9D%A2%E7%BB%98%E5%88%B6%E4%B8%80%E4%B8%AA%E5%9C%86/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-16 00:00:00 +0800", "snippet": "在地形的表面绘制一个圆在很多的RTS类型的游戏中，通过围绕被选中的单位绘制一个圆圈来表示距离（攻击范围，可移动距离，视野等等）。如果地面是平坦的，那么可以用通过对一张绘制有圆圈的矩形纹理进行缩放就能简单的做到。但是如果地面并不平坦，那么这个矩形的纹理就很有可能被高出的山丘或者其他几何物体遮住。接下来的知识点将展示如何编写一个着色器，让你可以在任何复杂的物体表面绘制一个圆圈[且不会被遮住]。如...", "content": "在地形的表面绘制一个圆在很多的RTS类型的游戏中，通过围绕被选中的单位绘制一个圆圈来表示距离（攻击范围，可移动距离，视野等等）。如果地面是平坦的，那么可以用通过对一张绘制有圆圈的矩形纹理进行缩放就能简单的做到。但是如果地面并不平坦，那么这个矩形的纹理就很有可能被高出的山丘或者其他几何物体遮住。接下来的知识点将展示如何编写一个着色器，让你可以在任何复杂的物体表面绘制一个圆圈[且不会被遮住]。如果你想对这个圆圈移动或者执行动画，那么我们就需要有着色器和C#代码才行。下图展示了用着色器在一个丘陵地形中绘制一个圆圈的例子： 始前准备 这里的着色器主要是用于地形的，对于其他的游戏对象不适用。所以我们首先要做的是在Unity中创建好一个地形。 我们先分别建立一个着色器和材质，名字分别是RadiusShader和RadiusMaterial。 当你的角色物体准备好后；我们会绕着它绘制一个圆圈。 在Unity的菜单[这里的菜单操作我就不翻译了，翻译了感觉反而不好，怕翻译错了，大家找不到]，选择 GameObject | 3D Object | Terrain 来创建一个新的地形。 为地形创建一些几何面。你可以导入一个已存在的地形或者自己用地形工具画一个新的。(Raise/Lower Terrain, Paint Height, SmoothHeight )[括号里面这些都是Unity地形编辑器中的工具] 地形是Unity中特殊的游戏对象，它表面的纹理映射方式跟传统的3D模型不一样。你不能通过在着色器定义一个_MainTex来提供纹理，因为在地形中需要直接由地形自己提供。这一步骤可以通过在地形编辑器中选择Paint Texture 然后点击Add Texture…: 完成上面步骤后，纹理就设置好了。你必须修改地形的材质这样就可以在地形中使用我们提供的自定义的着色器。在 Terrain Settings中, 把Material一栏的属性改为Custom，接着把我们的Radius material材质拖拽到Custom Material栏上。 接下来就要准备你自己的着色器了。 操作步骤 让我们开始编辑着色器RadiusShader 的代码: 在新的着色器中, 添加下面四个属性: _Center(\"Center\", Vector) = (0,0,0,0)_Radius(\"Radius\", Float) = 0.5_RadiusColor(\"Radius Color\", Color) = (1,0,0,1)_RadiusWidth(\"Radius Width\", Float) = 2 然后在CGPROGRAM块中添加它们各自的变量与之对应： float3 _Center; float _Radius; fixed4 _RadiusColor; float _RadiusWidth; 所以现在输入表面函数的数据不仅仅是纹理的UV数据了，还包括地形的中每一个点的位置(这个位置是基于世界坐标的)。 为了拿到这个参数我们需要修改输入结构体 Input struct，如下所示： struct Input { float2 uv_MainTex; // The UV of the terrain texture float3 worldPos; // The in-world position }; 最后我们在表面函数中使用这个参数： void surf(Input IN, inout SurfaceOutputStandard o) { float d = distance(_Center, IN.worldPos); if (d &gt; _Radius &amp;&amp; d &lt; _Radius + _RadiusWidth) o.Albedo = _RadiusColor; else o.Albedo = tex2D(_MainTex, IN.uv_MainTex).rgb; } 通过上面的步骤，你就可以在地形中绘制一个圆。你可以通过材质的检查器面板Inspector tab去改变这个圆的位置，半径和颜色。 在表面移动这个圆 如果你想让圆跟着你的角色移动，那就还需要一些额外的工作： 创建一个叫Radius的C#脚本。 在脚本中添加下面这些属性： public Material radiusMaterial;public float radius = 1;public Color color = Color.white; 在Update()方法中，添加下面这些代码： radiusMaterial.SetVector(\"_Center\", transform.position);radiusMaterial.SetFloat(\"_Radius\", radius);radiusMaterial.SetColor(\"_RadiusColor\", color); 然后把这个脚本挂在到你的角色身上。 最后把Radius material这个材质拖拽到C#脚本中的Radius Material中去[是在检查器面板Inspector tab中]。 现在你可以移动你的角色，并且这个圆能很好的跟随玩家。并且修改脚本中的半径也能修改圆圈的半径大小。 原理介绍 绘制这个圆的相关参数是中心点，半径和颜色。它们分别可以在着色器中的_Center, _Radius, 和 _RadiusColor中获得。 通过在输入结构体Input structure 添加一个worldPos的变量，这等于是让Unity提供给我们像素点的位置，这些位置是用世界坐标来表示的。 这是编辑器中一个游戏对象的确切位置。surf()函数是这个圆真正绘制的地方。 它会计算绘制点到中心点的距离，然后判断这个绘制点是否处于_Radius 和_Radius + _RadiusWidth之间；如果满足就使用对应的颜色。如果不是就不修改，跟我们以前遇到的情况一样对纹理贴图取样即可。 " }, { "title": "纹理的压缩和混合", "url": "/game-tech-post-old/posts/%E7%BA%B9%E7%90%86%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%B7%B7%E5%90%88/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-14 00:00:00 +0800", "snippet": "纹理的压缩和混合纹理的作用并不仅仅只是我们通常认为的保存加载的数据或者像素颜色，同时还有像素点在x和y方向以及RGBA通道的各种设置。我们能把多张图片压缩进一张单独的RGBA纹理中并且使用它们各自的R，G，B和A元素，因为我们可以在着色器中把它们各自纹理中的这些元素分别解压出来。将各自的灰度图压缩进一张单独的RGBA纹理的结果可以通过下图看出来：为什么说这会有用呢？在你的应用程序实际消耗的大...", "content": "纹理的压缩和混合纹理的作用并不仅仅只是我们通常认为的保存加载的数据或者像素颜色，同时还有像素点在x和y方向以及RGBA通道的各种设置。我们能把多张图片压缩进一张单独的RGBA纹理中并且使用它们各自的R，G，B和A元素，因为我们可以在着色器中把它们各自纹理中的这些元素分别解压出来。将各自的灰度图压缩进一张单独的RGBA纹理的结果可以通过下图看出来：为什么说这会有用呢？在你的应用程序实际消耗的大部分中内存当中，贴图占了很大的一部分。所以如果你想要减少应用程序的大小的话，我们能在着色器中查看所有使用的图片并且想想我们是否能将这些纹理合并到一张单独的纹理中。任何灰度的纹理都可以压缩进另一张有RGBA通道的纹理。第一次听起来可能有点怪怪的，但我们接下来会用这个知识点来演示纹理压缩的用法并且在我们的着色器中使用这张压缩过的纹理。举其中一个纹理压缩用法例子，比如你想把一套纹理[有好几张]混合进一张单独的纹理中。这在地形类着色器中很常见，在我们的例子中，我们会用一些排好序的控制纹理或者压缩过的纹理，很好的混合进另一张纹理中。这个知识点会讲到这个技术的，同时还会告诉你如何开始编写好这样一个混合四张纹理的着色器。 始前准备 在我们Unity的着色器文件夹中创建一个新的着色器同时创建一个新的材质与之对应。这两者的命名怎么方便怎么来，不过尽量保证组织和引用方便吧。 建好着色器和材质后，再创建一个新的场景，好给后面做测试。 收集好四张你打算混合在一起的纹理。我们直接用它们展示这几张纹理是如何放到物体表面的。 我们可以用一些非常复杂的混合纹理在地形网格上创建一个非常真实的地形分布纹理，如下所示： 操作步骤 我们通过下面代码来学习如何使用压缩纹理。 我们在着色器的属性Properties块中添加一些属性。我们需要5个sampler2D类型的游戏对象或纹理，2个颜色属性： Properties{_ MainTint (\"Diffuse Tint\", Color) = (1,1,1,1) //Add the properties below so we can input all of our textures _ColorA (\"Terrain Color A\", Color) = (1,1,1,1) _ColorB (\"Terrain Color B\", Color) = (1,1,1,1) _RTexture (\"Red Channel Texture\", 2D) = \"\"{} _GTexture (\"Green Channel Texture\", 2D) = \"\"{} _BTexture (\"Blue Channel Texture\", 2D) = \"\"{} _ATexture (\"Alpha Channel Texture\", 2D) = \"\"{} _BlendTex (\"Blend Texture\", 2D) = \"\"{}} 接下来我们在SubShader{}块中创建一些变量，记住要跟上一步的属性块对应。 CGPROGRAM#pragma surface surf Lambert float4 _MainTint;float4 _ColorA; float4 _ColorB;sampler2D _RTexture;sampler2D _GTexture;sampler2D _BTexture;sampler2D _BlendTex;sampler2D _ATexture; 我们现在获得了纹理属性后把它们传递给SubShader{}函数。为了能够让使用者可以控制每个纹理的截取比例，我们需要修改输入结构体Input struct。这样我们就可以使用每个纹理的截取和偏移量等参数: struct Input{ float2 uv_RTexture; float2 uv_GTexture; float2 uv_BTexture; float2 uv_ATexture; float2 uv_BlendTex;}; 注意[译者添加] 如果遇到Too many texture interpolators would be used for ForwardBase pass错误，因为是Input中定义的材质uv变量太多了，当前版本的shader model不支持造成。此时将shader model改为更高的版本可以解决。如果你的#pragma target 3.0不支持3个材质，可以改为#pragma target 4.0试试吧。 如果非要用#pragma target 3.0，只能通过共用uv_MainTex或者使用屏幕坐标来解决了。 然后再surf()函数里，为了便于理解，我们把纹理的信息都分别保存到它们各自的变量中： //Get the pixel data from the blend texture//we need a float 4 here because the texture//will return R,G,B,and A or X,Y,Z, and Wfloat4 blendData = tex2D(_BlendTex, IN.uv_BlendTex);//Get the data from the textures we want to blendfloat4 rTexData = tex2D(_RTexture, IN.uv_RTexture);float4 gTexData = tex2D(_GTexture, IN.uv_GTexture);float4 bTexData = tex2D(_BTexture, IN.uv_BTexture);float4 aTexData = tex2D(_ATexture, IN.uv_ATexture); 我们用lerp()函数把每一个纹理混合到一起。这个函数接收三个参数，lerp(value : a, value : b, blend: c)。lerp()函数用前面两个参数的纹理跟最后一个浮点型参数进行混合： //No we need to contruct a new RGBA value and add all//the different blended texture back togetherfloat4 finalColor;finalColor = lerp(rTexData, gTexData, blendData.g);finalColor = lerp(finalColor, bTexData, blendData.b);finalColor = lerp(finalColor, aTexData, blendData.a);finalColor.a = 1.0; 最后，我们把混合后的纹理乘以颜色并且用红色通道来决定到底该用这两个地形颜色的哪一个： //Add on our terrain tinting colorsfloat4 terrainLayers = lerp(_ColorA, _ColorB, blendData.r);finalColor *= terrainLayers;finalColor = saturate(finalColor);o.Albedo = finalColor.rgb * _MainTint.rgb;o.Alpha = finalColor.a; 下图展示了我们通过混合四张地形纹理贴图，并且创建一个地形的技术： 原理介绍 这里代码量好像有点多，但是混合后面的概念是比较简单的。为了展示混合的技术，我们使用了来自CgFX标准库中的内建函数lerp()。这个函数允许我们以第三个参数作为混合量，获得一个介于第一个参数和第二个参数之间的数： 函数 描述 lerp(a,b,f) 这里其实是线性插值： (1 – f )* a + b * f 这里的a和b需要时向量或者标量。但是f只能是跟a和b类型一样的标量或者向量。 我们举例子来演示，比如我们想要获得一个介于1和2之间的中间值，我们此时可以给lerp()函数的第三个参数传一个0.5那么这个函数就会返回1.5。这刚好能满足我们混合纹理的需求，因为在RGBA纹理中的每一个通道的值都是一个浮点值，这些值得取值范围通常都是0到1。 在这个着色器中，我们都简单的从需要混合的纹理中，拿了一个通道的值，来控制用lerp()函数获得的颜色值，这些值最终在赋值给每一个像素点。比如我们用草的纹理和泥土的纹理，再加上我们混合纹理中的红色通道，把这些值分别传递给lerp()函数的第一，二，三个参数。这样我们就能获得地表中每一个像素正确混合后的颜色。 下图更直观的向我们展示了当我们使用lerp()函数时，到底发生了什么： 着色器代码简单的使用了混合纹理的四个通道和所有的颜色纹理，最终创建了一个混合后的纹理。这个最终的纹理的颜色用于跟漫反射的光进行相乘的操作。 [这里找不到这个项目的代码，只能随机应变翻译，没有项目可以跑] " }, { "title": "创建一个有全息效果的着色器", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%9C%89%E5%85%A8%E6%81%AF%E6%95%88%E6%9E%9C%E7%9A%84%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-13 00:00:00 +0800", "snippet": "创建一个有全息效果的着色器近些年来太空主题的发行的越来越多。科幻游戏中很重要的一个部分就是在游戏中集合了来自未来的各种技术。全息投影就是其中的典型代表。全息投影尽管有很多种形式，但是通常用一种半透明，看起来很薄的投影来呈现。这次的这个知识点将会向你展示如何创建一个这样的着色器来模拟这样的效果。我们首先想到：要创建一个优秀的全息投影特效，你需要能够添加噪音，扫描动画和和震动。下图就展示了一个全...", "content": "创建一个有全息效果的着色器近些年来太空主题的发行的越来越多。科幻游戏中很重要的一个部分就是在游戏中集合了来自未来的各种技术。全息投影就是其中的典型代表。全息投影尽管有很多种形式，但是通常用一种半透明，看起来很薄的投影来呈现。这次的这个知识点将会向你展示如何创建一个这样的着色器来模拟这样的效果。我们首先想到：要创建一个优秀的全息投影特效，你需要能够添加噪音，扫描动画和和震动。下图就展示了一个全息投影效果的列子： 始前准备 正如全息投影效果展示的知识物体的轮廓，所以我们可以把我们的这个着色器命名成Silhouette[轮廓的意思]。把它跟材质关联起来并且把它应用到你的3D模型中去。 操作步骤 根据下面的步骤可以将我们的当前的着色器修改为有全息投影效果的着色器： 在着色器中添加下面的属性： _DotProduct(\"Rim effect\", Range(-1,1)) = 0.25 并且添加跟属性对应的变量到CGPROGRAM块中去： float _DotProduct; 因为这个材质是有透明度的，所以需要添加下面的标签： Tags{\t\"Queue\" = \"Transparent\"\t\"IgnoreProjector\" = \"True\"\t\"RenderType\" = \"Transparent\"} 注意 根据你将会使用的游戏对象类型，你可能想要它的背面也能看到。如果是这种情况，那么我们就需要在代码中添加Cull Off，从而让模型的背面不会被剔除。 这个着色器并不会尝试去模拟真实世界的材质，所以这里就没有必要再使用PBR关照模型了。我们将会用性能消耗更少的Lambertian 反射来代替它。另外，我们应该使用nolighting来关闭所有的光线并且用alpha:fade来告诉Cg我们得着色器是一个有透明度的着色器： #pragma surface surf Lambert alpha:fade nolighting 修改输入结构体从而能让Unity输入当前的视口方向和世界的法线方向： struct Input{\tfloat2 uv_MainTex;\tfloat3 worldNormal;\tfloat3 viewDir;}; 修改你的表面函数surface function成下面的样子。请记住因为这个着色器使用Lambertian反射作为光照函数，所以表面输出结构体的名字也要相应改成SurfaeOutput，这是SurfaceOutputStandard类型的实例。 void surf(Input IN, inout SurfaceOutput o){\tfloat4 c = tex2D(_MainTex, IN.uv_MainTex) * _Color;\to.Albedo = c.rgb;\tfloat border = 1 - (abs(dot(IN.viewDir, IN.worldNormal)));\tfloat alpha = (border * (1 - _DotProduct) + _DotProduct);\to.Alpha = c.a * alpha;} 现在你可以使用Rim effect这个滑动条来选择全息投影效果的强度。 原理介绍 正如前面提到的，这个着色器仅仅是展示了物体的轮廓。如果我们从不同的角度看这个物体，它的轮廓也会改变。从几何学的角度上讲，模型的所有边都包含在法线方向normal direction垂直于视口方向view direction的三角形上。输入结构体Input structure声明了这些变量，分别是worldNormal和viewDir这两个参数。 要知道两个向量是否垂直可以用点积dot product进行判断。她是一个操作符，接收两个向量作为参数，如果这两个向量垂直，会返回零。我们使用参数DotProduct来控制点积趋近于零的程度从而控制那些三角形应该完全消失。 这个着色器的另一方面，我们用了_DotProduct(不可见)来确定模型的边（完全可见）和角度之间消失的力度。这个线性插值是通过下面的代码实现的： float alpha = (border * (1 - _DotProduct) + _DotProduct); 最后，贴图原来的alpha值乘以一个计算好的系数后，我们获得了最终的样子。 相关补充 这种技术非常的简单并且性能消耗相对较低。不过这种着色器还可以用于其他的各种各样的特效，比如下面的这些： 科幻游戏中包裹星球的浅色大气层 被选中的游戏物体的边或者当前鼠标下的物体 鬼魂或者幽灵 引擎冒出的烟 爆炸的冲击波 太空战舰被攻击时的防护罩 额外内容 在反射计算中向量的点积dot product扮演着非常重要的角色。我们在 第三章，理解光照模型 这个章节中会详细的介绍它是如何工作的以及为什么会广泛的用于很多的着色器中。 " }, { "title": "创建一个带透明度的材质", "url": "/game-tech-post-old/posts/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6%E9%80%8F%E6%98%8E%E5%BA%A6%E7%9A%84%E6%9D%90%E8%B4%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-12 00:00:00 +0800", "snippet": "创建一个带透明度的材质到目前为止我们所看到的着色器似乎都有一个共同点——它们都用于了固体材质。如果你想要的提升你的游戏的视觉效果，那么带透明度的材质通常是一个好的开始。它们用途广泛，从火焰效果到窗户的玻璃都会用到它们。但稍微麻烦的是，它们用起来要复杂一点点。在渲染固体模型之前，Unity会根据它们离摄像机的距离(这个叫Z ordering)进行排序，并且跳过渲染所有背朝摄像机的三角面(这个是...", "content": "创建一个带透明度的材质到目前为止我们所看到的着色器似乎都有一个共同点——它们都用于了固体材质。如果你想要的提升你的游戏的视觉效果，那么带透明度的材质通常是一个好的开始。它们用途广泛，从火焰效果到窗户的玻璃都会用到它们。但稍微麻烦的是，它们用起来要复杂一点点。在渲染固体模型之前，Unity会根据它们离摄像机的距离(这个叫Z ordering)进行排序，并且跳过渲染所有背朝摄像机的三角面(这个是剔除技术culling)。当渲染带透明度的几何物体时，这些含有两个面的几何物体就会产生问题。这次的知识点将会为你展示：当我们创建有透明度的表面着色器时，我们如何解决这个过程中产生的这些问题。我们在第六章,片元着色器和抓取通道我们还会着重回顾这个话题，真实渲染中的玻璃和水体着色器都会涉及到。 始前准备 这个知识点需要一个新的着色器，我们就叫它Transparent吧。同时也需要一个新的材质，这样才能把着色器应用于游戏物体。因为这个物体需要成为一个透明的玻璃窗，那么我们最好用Unity中的quad或者plane来做。我们当然也需要一些不透明的其他游戏对象来对比测试效果。在这个例子中，我们会使用一张PNG图片作为玻璃纹理。这张图片的alpha通道将会用于控制玻璃的透明度。这样的PNG图片大家自行自作，软件不限。但是需要遵守下面的这些步骤： 找一张要用于你窗户玻璃的图片。 用照片编辑软件打开这样图片，比如GIMP或者Photoshop。 选择图片中你想要变成半透明的部分。 在这张图片上创建一个空白(full opacity[抱歉我不懂PS，不知道这个参数的含义])图层 选择上一步创建的图片，以黑色来填充这个图层。 保存图片然后导入到Unity中。 这个知识点中，我们用来试验的图片是一张来自圣斯德望主教座堂 Meaux Cathedral in France(https://en.wikipedia.org/wiki/Stained_glass)的花窗玻璃。 如果遵循了上面的图片制作步骤，那么你也会获得如下类似的一张图片（RGB通道在左图，A通道在右图）： 操作步骤 正如我们前面提醒的，我们在使用透明度着色器时需要注意几个方面： 在着色器的SubShader{}代码块中，添加下面的标签告知着色器这是用于透明度的： Tags{\t\"Queue\" = \"Transparent\"\t\"IgnoreProjector\" = \"True\"\t\"RenderType\" = \"Transparent\"} 由于这个着色器是为2D 材料设计的，所以确保你的模型的背面不会被绘制，通过添加下面的这个代码： Cull Back 告诉着色器这个材料是半透明的并且需要跟屏幕中绘制的什么内容混合： #pragma surface surf Standard alpha:fade 使用这个表面着色器来决定玻璃的颜色和透明度： void surf(Input IN, inout SurfaceOutputStandard o){\tfloat4 c = tex2D(_MainTex, IN.uv_MainTex) * _Color;\to.Albedo = c.rgb;\to.Alpha = c.a;} 原理介绍 这个着色器中介绍了几个新的概念。首先，标签Tags用于添加一些关于游戏对象是如何渲染的信息。但是这次这里真正让人感兴趣的是Queue。Unity默认会根据物体距离摄像机的距离来对游戏对象进行排序。所以当一个物体距离摄像机越近，那么它就会比所有离摄像机更远的物体先绘制。在大多数情况下，它对游戏来说都没有问题，但是有些情况下你可能想要自己控制游戏场景中物体的渲染顺序。Unity已经有提供给我们一些默认的渲染队列，每一个队列都有一个单独的值好让Unity按照这个顺序在屏幕中绘制游戏物体。这些内建的渲染队列分别叫做[这些参数就不翻译了] Background，Geometry，AlphaTest，Transparent， 和 Overlay。 这些队列并不是随意创建的；创造它们是为了让我们能更容易的编写着色器代码和跟实时渲染进行交互。下表描述了每一个不同的渲染队列的作用： 渲染队列 队列描述 渲染队列值 Background 这个渲染队列最先渲染。它被用于天空盒等等。 1000 Geometry 这个是默认的渲染队列。大多数游戏对象都用这个 。不透明物体使用这个队列。 2000 AlphaTest Alpha-tested几何体使用这个队列。跟 Geometry队列不同的是在所有的固态物体都被渲染的情况下，它在渲染alpha-tested游戏对象上效率更高。 2450 Transparent 这个队列在Geometry队列和AlphaTest队列之后，并且是由后向前渲染顺序。任何的alpha渲染（着色器不会写入深度buffer）都应该在这个队列，比如玻璃效果和例子效果。 3000 Overlay 这个渲染队列是为叠加效果准备的。所有在最后渲染的东西都用此队列，比如镜头光晕。 4000 所以，一旦你知道你的游戏对象属于哪个渲染队列后，那么你就可以给它设置渲染队列。我们这次的着色器用到了Transparent队列，所以我们在代码中用到了Tags{“Queue”=”Trasparent”}.这样的标签。 注意 事实上Transparent队列在Geometry队列后渲染并不是意味着玻璃会出现在其他所有固态物体的上面。Unity会在最后再绘制玻璃，同时也并不会渲染任何一个被其他物体遮住部分的游戏对象的像素点。这样的控制可以用一种叫ZBuffering的技术实现。更多关于模型是如何被渲染的资料可以在下面的链接找到： http://docs.unity3d.com/Manual/SLCullAndDepth.html。 标签IgnoreProjector可以让这个游戏对象不受Unity的投影的影响。最后，RenderType扮演了一个着色器替换的角色，这个话题在 第九章，游戏和屏幕效果中会简略的谈一下这个话题。 最后一个要介绍的概念就是alpha:fade。这表示这个材质中的所有像素点会根据它们的alpha值决定必须要先跟屏幕中的什么物体混合渲染。如果没有用这个指明的话，像素会按照正确的顺序绘制，但是它们不会有任何的透明度。 " }, { "title": "通过改变uv值来移动贴图", "url": "/game-tech-post-old/posts/%E9%80%9A%E8%BF%87%E6%94%B9%E5%8F%98UV%E5%80%BC%E6%9D%A5%E7%A7%BB%E5%8A%A8%E8%B4%B4%E5%9B%BE/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-09 00:00:00 +0800", "snippet": "通过改变UV值来移动纹理在当惊的游戏产业中，一个很常见的游戏纹理技术就是允许你对游戏物体表面的纹理进行滚动。这种技术可以让你创建很多效果，比如瀑布，河流，流动的沿江等等。同时这些技术也是制作动画精灵特效的基础，我们会在这一章节的一系列知识点中来讲解这些内容。 首先，让我们来看看在表面着色器(SurfaceShader)如何创建一个简单的纹理滚动效果。 始前准备 在这个知识点开...", "content": "通过改变UV值来移动纹理在当惊的游戏产业中，一个很常见的游戏纹理技术就是允许你对游戏物体表面的纹理进行滚动。这种技术可以让你创建很多效果，比如瀑布，河流，流动的沿江等等。同时这些技术也是制作动画精灵特效的基础，我们会在这一章节的一系列知识点中来讲解这些内容。 首先，让我们来看看在表面着色器(SurfaceShader)如何创建一个简单的纹理滚动效果。 始前准备 在这个知识点开始之前，需要你创建一个新的着色器文件和材质。这么做的目的是为了有个干净的着色器，然后我们可以更加方便的学习和观看滚动效果。 操作步骤 闲话少说，我们打开刚才创建的的着色器[着色器的名字文章中没有说，就自己取一个启动的名字吧]，然后输入下面每个步骤所展示的代码： 这个着色器需要两个控制纹理滚动的新属性。所以我们添加一个速度属性控制X方向的滚动，添加另一个速度属性控制Y方向的滚动，如下面的代码所示： Properties { _MainTint(\"Diffuse Tint\",Color) = (1,1,1,1) _MainTex (\"Base (RGB)\", 2D) = \"white\" {} _ScrollXSpeed(\"X Scroll Speed\",Range(0,10)) = 2; _ScrollYSpeed(\"Y Scroll Speed\",Range(0,10)) = 2; } 修改CGPROGRAM代码块中的Cg属性中的变量，创建新的变量[把原来的都删掉，用下面展示的代替]，这样我们就能访问来自着色器属性的值了： fixed4 _MainTint;fixed _ScrollXSpeed;fixed _ScrollYSpeed;sampler2D _MainTex; 修改表面函数surface function从而修改传递给tex2D()函数的UV值。然后，使用内建的_Time变量来对UV进行循环播放的动画，这样的话当我们点击Unity中的运行按钮的时候，我们就能看到动画效果了： void surf (Input IN, inout SurfaceOutputStandard o) { // Create a separate variable to store our UVs // before we pass them to the tex2D() function fixed2 scrollUV = IN.uv_MainTex; // Create variables that store the individual x and y // components for the UV's scaled by time fixed xScrollValue = _ScrollXSpeed * _Time; fixed yScrollValue = _ScrollYSpeed * _Time; // Apply the final UV offset scrollUV += fixed2(xScrollValue,yScrollValue); // Apply textures and tint half4 c = tex2D(_MainTex,scrollUV); o.Albedo = c.rgb * _MainTint; o.Alpha = c.a; } 下面的图片中的示例就是利用滚动UV的系统来创建的一个自然环境中河流的动画，你可以注意到场景中叫ScrollingUVs的特效就是来自于本书提供的代码： 原理介绍 这个纹理滚动的着色器中，定义了一系列的属性，这些属性允许玩家增加或者减少滚动效果的速度。这里的关键点是，来自材质的检查器面板Inspector tab的一些浮点值会输入到着色器的表面函数surface function中去。如果你想了解属性的更多信息，可以去看第一章，创建你的第一个着色器 。 一旦我们获得了来自材质检查器面板Inspector这些浮点值后，我们就可以在着色器中利用它们来对UV值进行偏移修改。 但是在此之前，我们首先把UV值保存在了一个叫做scrolledUV的独立变量中。这个变量需要是float2/fixed2类型，因为从Input结构传过来给我们的UV值是下面这样的： struct Input{\tfloat2 uv_MainTex;} 一旦拿到了游戏网格的UV，我们就可以用我们的滚动速度和着色器内建的_Time变量偏移修改它们。这个内建的变量会返回float4类型的变量，也就是说这个变量的每一个部分都包含了不同的时间值，这个时间来自游戏内的时间。 关于这个独特的时间值，可以通过下面的链接查看它的完整描述： https://docs.unity3d.com/Manual/SL-UnityShaderVariables.html 这个_Time变量根据Unity的游戏时钟增量过的浮点值。所以我们能使用这个值，根据UV的两个方向移动我们的UV，并且根据我们的滚动速度对这个时间进行缩放： // Create variables that store the individual x and y// components for the uv's scaled by timefixed xScrollValue = _ScrollXSpeed * _Time;fixed yScrollValue = _ScrollYSpeed * _Time; 通过时间算出了正确的UV偏移量，接着就可以添加新的偏移量的值到原来的UV位置中去。这也是我们为什么在下一行要用+=操作符的原因。我们想要拿到原来的UV位置，对这个位置加上新的偏移量，然后再把这个值传给tex2D()这个函数作为纹理的新UV。这个过程让我们创建了纹理在游戏对象表面移动的效果。 表面上来看，我们的效果好像在移动纹理，但实际上我们是在修改UV而已： scrolledUV += fixed2(xScrollValue, yScrollValue);half4 c = tex2D (_MainTex, scrolledUV); " }, { "title": "法线贴图", "url": "/game-tech-post-old/posts/%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2021-01-09 00:00:00 +0800", "snippet": "法线贴图3D模型的每一个三角面都有一个朝向facing direction，这个朝向就是它向前的指向。它通常用一个垂直并且放置在三角面正中心的一个箭头来表示。这个朝向对于光在表面反射中来说非常的重要。如果相邻的两个三角面朝向不同的方向，那么它们对光的反射也会朝向不同的角度，也就是在着色器中它们的处理方式会不一样。对于曲面物体来说，这里有个疑问：很显然这些拥有曲面的几何体仍然是由平面三角形构成...", "content": "法线贴图3D模型的每一个三角面都有一个朝向facing direction，这个朝向就是它向前的指向。它通常用一个垂直并且放置在三角面正中心的一个箭头来表示。这个朝向对于光在表面反射中来说非常的重要。如果相邻的两个三角面朝向不同的方向，那么它们对光的反射也会朝向不同的角度，也就是在着色器中它们的处理方式会不一样。对于曲面物体来说，这里有个疑问：很显然这些拥有曲面的几何体仍然是由平面三角形构成的，那光线改如何处理？为了避免这个问题，对应三角面的光的反射计算方式此时不根据它的朝向计算，而是根据它的法线方向normal direction方向计算。前面向着色器添加纹理那个知识点讲到，顶点是保存有数据的。法线方向信息也是继UV信息之后，保存在顶点中最有用的信息。这是一个单位长度的向量，并且它表示了顶点的朝向。不考虑朝向的话，那么三角面内的每一个顶点都有它自己的法线方向，只不过这个法线方向是一个存储在顶点中的线性插值。这给了我们用低模模拟高模的能力。下面示例图展示了同一个几何形状在不同的顶点插值密度下的表现。在左边，法线垂直于由顶点表示的面；很明显每个面之间有明显的的割裂感。再看看最右边的几何体，它的法线是通过他的面线性插值得到的，可以看出来的是，尽管它的表面看起来还是很粗糙，但是光线的反射看起来却似乎很光滑。很容易看出来尽管这三个物体的几何体都相同，但是它们的光线反射却不一样。尽管都是由平面三角形构成，但是右边物体的光线反射似乎看起来像曲面反射。一个有着粗糙的边的光滑物体很明显的表示单位顶点的法线肯定进行了线性插值。如果我们对保存在每个顶点的法线按其方向进行绘制，我们就能够看到它们，正如下图所展示的那样。你应该注意的是每个三角形仅有三条法线，但是相连的三角形有相同的顶点，会看到不止有一条法线从中绘制出来。法线贴图在计算3D模型的法线技术中脱颖而出。跟纹理贴图类似，法线方向也可以用一张额外的纹理表示，我们把它们叫做法线贴图normal map或者凹凸贴图bump map。 法线贴图通常是一张RGB图片，里面的RGB通常分别用来表示法线方向中的X，Y，Z方向。现在有很多种技术方法来创建一张法线贴图。比如这些应用程序，CrazyBump(http://www.crazybump.com/)跟NDO Painter(http://www.crazybump.com/)可以把2D数据转换成法线数据。其他的应用程序比如Zbrush 4R7(http://www.pixologic.com/)和AUTODESK(http://usa.autodesk.com)可以把雕刻数据转换成法线贴图。如何创建法线贴图完全超出了本书的范畴，但上面的内容对你了解相关相应的知识还是有好处的。在Unity中向着色器添加法线的过程很简单，因为在表面着色器中有着UnpackNormals()这样的方法给你调用。就让我们看看这是怎样的一个过程。 始前准备 分别创建一个新的材质和着色器，并且把它设置到场景视图Scene view中的游戏对象中去。这样的话，我们的项目非常简单，好让我们仅仅是观察法线贴图这项技术。 这个知识点中你需要一张法线贴图，但是我们这本书附带的Unity工程中包含了一张。[当然，你也可以从我这里把这张图片下载下来，如下图] 操作步骤 下面就是创建法线贴图着色器的步骤了： 让我们设置好我们的属性块，从而可以获得颜色和贴图： Properties{\t_MainTint (\"Diffuse Tint\", Color) = (1,1,1,1)\t_NormalTex (\"Normal Map\", 2D) = \"bump\" {}} 注意 因为用的是bump来初始化了属性的贴图类型，这等于是告诉了Unity_NormalTex包含了法线贴图。如果这个贴图没有被设置， 那么会默认给它设置一张灰色的贴图。颜色值会用(0.5,0.5,0.5,1)，然后看不出一点凹凸感。 在CGPROGRAM下面的SubShader{}块中声明下面两个变量，让这两个变量跟属性块中的两个属性关联起来： CPROGRAM#pragma surface surf Lambert// Link the property to the CG programsampler2D _NormalTex;float4 _MainTint; 我们需要修改输入结构体Input struct的名字，从而让我们可以让我们通过模型的UV来访问法线贴图： // Make sure you get the UVs for the texture in the structstruct Input{\tfloat2 uv_NormalTex;} 最后，我们通过内建的UnpackNormal()函数从法线贴图中提取出我们需要的法线信息。接着，你只要把这些新的法线应用到表面着色器的输出上即可： // Get the normal data out of the normal map texture// using the UnpackNormal functionfloat3 normalMap = UnpackNormal(tex2D(_NormalTex, IN.uv_NormalTex));// Apply the new normal to the lighting modelo.Normal = normalMap.rgb; 下图展示了我们的法线贴图着色器的最终效果： 注意 着色器可以同时拥有纹理贴图和法线贴图。用UV数据同时来关联这两种贴图并不少见。然而，也可以在特有的顶点数据(UV2)中提供第二个UV的参数设置来设置法线贴图。 原理介绍 法线贴图效果背后的数学原理完全超出了本书的范畴，不过Unity已经为我们做了这一切。由于Unity为我们创建了各种方法所以我们不用一遍又一遍的做重复劳动。这也是为什么说表面着色器是编写着色器代码的高效方式的另一个原因。 如果你在Unity的安装文件夹下的Data文件夹下的UnityCG.cginc文件中查找的话，你可以找到UnpackNormal()这个函数的定义。当你在表面着色器声明这个函数的时候，Unity会通过提供给它的法线贴图进行处理并且返回给你正确类型的数据，这样你就可以逐像素光照函数中使用它们。这为你节约了大量的时间！当对一张纹理[法线贴图]进行采样时，你可以获得从0到1取值范围的RGB值；然而，法线方向向量的取值范围确实-1到1。通过UnpackNormal()函数就可以给法线方向向量获取合理的值。 当你通过UnpackNormal()函数对法线贴图进行了处理后，你把处理后的结果返回给了SurfaceOutput结构体，这样你才能在光照函数中使用它们。这是通过着色器中o.Normal = normalMap.rgb;这条语句实现的。我们会在第三章理解光照模型这一章中会看，法线究竟是怎么用于计算每一个像素点最终颜色的。 相关补充 你也可以在你的法线贴图着色器中添加一些控制从而可以让用户修改法线贴图的强度。这一点很容易通过改变法线贴图变量的x和y元素然后把它们全部返回来办到。在法线贴图着色器中的属性块中添加另一个属性，名称为NormalMapIntensity： _NormalMapIntensity(\"Normal intensity\", Range(0,1)) = 1 把解包出来的法线贴图数据的x和y都乘以这个属性然后把这个得到的新的值返回给法线贴图变量： fixed3 n = UnpackNormal(tex2D(_BumpTex, IN.uv_ uv_MainTex)).rgb;n.x *= _NormalMapIntensity;n.y *= _NormalMapIntensity;o.Normal = normalize(n); 注意 法线向量的长度最好是等于1。当它们乘以_NormalMapIntensity后会改变它们的长度，所以对它进行标准化[归一化]是很有必要的。 现在你可以让使用者在材质的检查器面板Inspector tab修改法线贴图的强度了。 下图为我们展示了法线贴图在不同强度参数下的不同表现： " }, { "title": "在layabox中使用unity中的导航网格，实现ai自动寻路", "url": "/game-tech-post-old/posts/%E5%9C%A8LayaBox%E4%B8%AD%E4%BD%BF%E7%94%A8Unity%E4%B8%AD%E7%9A%84%E5%AF%BC%E8%88%AA%E7%BD%91%E6%A0%BC-%E5%AE%9E%E7%8E%B0AI%E8%87%AA%E5%8A%A8%E5%AF%BB%E8%B7%AF/", "categories": "LayaBox", "tags": "U3D, LayaBox, NavMesh, 自动寻路", "date": "2021-01-07 00:00:00 +0800", "snippet": "在LayaBox中使用Unity的导航网格，实现AI自动寻路使用这个这个库的好处在于，你不必了解AStar算法，一样可以使用AStar算法来进行AI导航。只需要调用接口即可。下面我给出LayaBox的示例项目地址和Unity导出网格示例项目地址，各位按需克隆下来即可Unity示例项目：https://github.com/linkliu/ExportNavMeshLayaBox示例项目：ht...", "content": "在LayaBox中使用Unity的导航网格，实现AI自动寻路使用这个这个库的好处在于，你不必了解AStar算法，一样可以使用AStar算法来进行AI导航。只需要调用接口即可。下面我给出LayaBox的示例项目地址和Unity导出网格示例项目地址，各位按需克隆下来即可Unity示例项目：https://github.com/linkliu/ExportNavMeshLayaBox示例项目：https://github.com/linkliu/LayaNavMesh原始的教程在http://ask.layabox.com/question/47899这里，大家可以去看看这里也行这次的实例会从下面三个方面来讲解： Laya要用到的导航组件库NavMesh.js Unity如何将Navmesh数据导出成json文件【Laya中用到】 Unity中用到的NavMeshComponents开始之前，说一下相关软件的版本LayaAir 2.9 ,Laya引擎库2.7.1,Unity 2018.4.11f11.Laya中用到的导航组件库NavMesh.js可以直接在Unity中对导航网格进行编辑，非常的方便。NavMesh.js可以直接从这里去拿https://github.com/lear315/NevMesh.Js/tree/main/build名字可能跟我的不一样，但是里面内容完全一样，我这里是强迫症发作，把Nev改成了Nav。然后只要拿NavMesh.js和NavMesh.d.ts这两文件就行了。NavMesh.js请放在Laya项目的bin/libs目录下面。NavMesh.d.ts放在项目的libs文件夹中。并且在bin/index.js中增加loadLib(“libs/NevMesh.js”)，注意需在loadLib(“js/bundle.js”);前面。完成上面这些步骤，就把导航组件库NavMesh.js放到我们的项目中了2.Unity如何将Navmesh数据导出成json文件将Unity的导航网格数据导出成LayaBox需要的json数据，需要用到两个关键文件，一个是把导航网格转换成.obj文件的NavMeshExport.cs。另一个是Python自动转换脚本convert_obj_three.py，这两个文件的获取方式，我贴在下面：NavMeshExport.cs：https://github.com/lear315/NevMesh.Js/tree/main/unityconvert_obj_three.py： https://github.com/lear315/NevMesh.Js/tree/main/pythonNavMeshExport.cs是一个Unity中的一个C#脚本，只要放到Unity中即可，便会在Unity中生成一个导出菜单，合并在LayaBox的导出菜单中。如下图点击Export按钮，就会把当前的导航网格导出到ExportNavMesh文件中，里面就是需要下一步需要的.obj文件。convert_obj_three.py是一个python脚本，所以各位需要安装python，并且配置配置好python环境，并且把python添加到系统的环境变量中去。这个脚本的使用方法是 python convert_obj_three.py -i xx.obj -o xx.json，这个命令是把上一步生成的.obj文件转换成.json文件，这样我们就能在LayaBox中使用这个.json文件来进行AI导航了。我的示例项目中已经做好了一键obj转json的功能，具体的用法是：选中你要转换的obj文件，然后右键，菜单选择Convert Navmesh to Json，就回自动在当前目录下生成一个同名的.json文件。这个就是LayaBox需要的文件，把这个文件放在LayaBox中的一个目录中。3.Unity中用到的NavMeshComponentsUnity中的导航网格的生成需要用到NavMeshComponents组件，目前这个组件Unity没有集成到Unity编辑器中，至少Unity2018以及之前的版本没有。但是Unity官方把它们放在Github上，地址在这里：https://github.com/Unity-Technologies/NavMeshComponents克隆下来后，你只需要把Assets/NavMeshComponents这个文件复制到自己的项目中就行了，其他的东西可以不用。NavMeshComponents的用法我就不细讲了，各位可以到https://docs.unity3d.com/Manual/NavMesh-BuildingComponents.html查看，也可以看这个中文的的博客https://blog.csdn.net/wangjiangrong/article/details/88823523各位按需观看吧。总结完成上面的三个步骤后，准备工作都OK了，具体的使用，各位可以去看我的LayaBox示例项目吧，哪里有完整的代码。感谢各位耐心看完。" }, { "title": "向着色器添加纹理", "url": "/game-tech-post-old/posts/%E5%90%91%E7%9D%80%E8%89%B2%E5%99%A8%E6%B7%BB%E5%8A%A0%E7%BA%B9%E7%90%86/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-12-11 00:00:00 +0800", "snippet": "向着色器添加纹理 通过纹理，可以很容易让着色器变得生动起来，获得非常真实的效果。为了更有效的使用纹理，我们需要了解一张2D图片是如何映射到3D模型中去的。 这个映射的过程称之为纹理贴图texture mapping，为了完成映射，我们在使用的模型和着色器上还有额外的工作。模型实际上是由很多的三角形拼接而成的；而三角形的每个顶点都保存有着色器可以访问的各种数据。 其中很重要的一个信息就是UV信...", "content": "向着色器添加纹理 通过纹理，可以很容易让着色器变得生动起来，获得非常真实的效果。为了更有效的使用纹理，我们需要了解一张2D图片是如何映射到3D模型中去的。 这个映射的过程称之为纹理贴图texture mapping，为了完成映射，我们在使用的模型和着色器上还有额外的工作。模型实际上是由很多的三角形拼接而成的；而三角形的每个顶点都保存有着色器可以访问的各种数据。 其中很重要的一个信息就是UV信息 (UV data)。 它包含两个坐标，U和V，其取值范围是0到1。这两者表示2D图片的像素点坐标的XY位置信息，而这些信息将会映射到顶点中去。 UV数据只为顶点表示[意思可能也等价于：UV数据只存在顶点中]； 当三角内的点需要被纹理贴图时，GPU会插值最接近的UV值，从而从相应的纹理中找到正确的像素点。下面的图片展示了一张2D纹理贴图到3D模型中的三角形中的情况：UV数据保存在3D模型中并且需要3D模型工具去编辑它们。有些模型缺少UV组件，因而它们不支持纹理贴图。比如3D模型软件中的默认的那个兔子模型，就没有提供这么一个组件。 始前准备 学习这个知识点的时候，你需要一个有UV数据和纹理的3D模型。然后把它们都导入到Unity中。也可以直接拖拽到Unity编辑器中，会自动导入。因为标准着色器支持默认的纹理贴图。我们会用到这一点，而后会详细的介绍它是如何工作的。 操作步骤 用标准着色器给你的模型添加一张纹理异常的简单，按照下面步骤： 创建一个叫TexturedShader标准着色器。 创建一个名为TexturedMaterial的材质球。 通过拖拽的方式，把着色器赋值给材质，把着色器拖到材质上即可。 选择刚才的材质，然后拖拽模型对应的纹理到一个叫Albedo(RGB)的矩形区域中的空白部分。如果你正确的执行了上述步骤，你的材质检查器面板(Inspector )会如下图所示： 标准着色器知道如何通过UV信息把2D图像映射到3D模型中 . 原理介绍 当通过材质的检查器面板使用标准材质的时候，纹理贴图背后的处理过程对于开发者来说是透明的。如果我们想了解它是如何工作的，那我们需要更加详细的了解我们刚才创建的TexturedShader着色器。在着色器的属性Properties部分，我们可以看到Albedo (RGB)的纹理跟代码的关联如下代码所示： MainTex:_MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} 在我们着色器代码中的CGPROGRAM代码块部分，纹理被定义为sampler2D类型，这是一种标准的2D纹理类型： sampler2D _MainTex; 紧接着下一行给我们展示了Input这个结构。这个结构就是surface 函数中得输入参数并且这个结构包含了一个叫做uv_MainTex的包组数组： struct Input {\tfloat2 uv_MainTex;}; 每一次调用surf()函数的时候，对应3D模型中的包含_MainTex **这个UV的Input 结构都需要被渲染。标准着色器会知道uv_MainTex 跟_MainTex **是关联的，并且会自动初始化它。如果你真的很想了解到底UV是怎么从3D模型映射到2D纹理的话，你可以看看第三章, 理解光照模型。 终于，UV数据被用来在**surface **函数中展示成一张纹理： fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; 注意 U和V的取值范围都是从0到1，(0,0)和(1,1)相当于两个相对的角[可以想象成一个是左下角，一个是右上角]。如果你的纹理出现了颠倒的情况，试着把V的值也颠倒就能解决了。 相关补充 当你把纹理导入到Unity的时候，你就会默认设置一些sampler2D类型将要使用的一些属性。 最重要的就是筛选模式Filter mode，它决定了一张纹理显示的时候颜色是如何插值的。跟UV数据会准确的指向像素的正中心非常不同；在一些其他的情况中，你也许想对最近的像素之间进行颜色插值从而获得更一致的颜色。下图是示例纹理在检查器面板Inspector tab的截屏： 对于多数的应用程序来说，双线性Bilinear提供了一种性能消耗低而且高效方法来对纹理进行平滑的处理方式。然而如果你是创建一个2D游戏，双线性Bilinear模式可能会产生模糊块。在这种情况下，你可以使用**点Point **模式来删除来自纹理采样的所有插值。 当以一个很大的倾斜角去观看一张纹理时，纹理采样似乎会呈现一种看起来不舒服的人工制品。你可以通过设置更高的**Aniso Level **的值来减少这种感觉。这一点对地板纹理和天花板纹理特别有用，可以解决一些小瑕疵导致的纹理观感不连续性的问题。 额外内容 如果你想了解更多关于纹理时如何映射到3D模型表面的内部工作原理，你可以通过下面的网址了解相关信息[可能需要用梯子才能访问]： http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter03.html。 如果想了解导入一张2D纹理时完整的可选择项列表，可以通过下面这个相关的网址查询：http://docs.unity3d.com/Manual/class-TextureImporter.html " }, { "title": "使用包组数组", "url": "/game-tech-post-old/posts/%E4%BD%BF%E7%94%A8%E5%8C%85%E7%BB%84%E6%95%B0%E7%BB%84/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-12-09 00:00:00 +0800", "snippet": "使用包组[包装组织]笼统的讲，显示器上每一个像素点都至少会执行一次。这也是为什么GPU要设计高度优化的并行架构的原因。同样的在Cg语言的标准变量类型和操作符中，这种设计哲学也很明显。理解它们，不仅仅是为了正确的使用着色器，同时也是为了能够写出更高效的着色器。 操作步骤 在Cg语言中有两种类型的变量：单精度值single和包组packed arrays。后者很容易辨别因为这种类...", "content": "使用包组[包装组织]笼统的讲，显示器上每一个像素点都至少会执行一次。这也是为什么GPU要设计高度优化的并行架构的原因。同样的在Cg语言的标准变量类型和操作符中，这种设计哲学也很明显。理解它们，不仅仅是为了正确的使用着色器，同时也是为了能够写出更高效的着色器。 操作步骤 在Cg语言中有两种类型的变量：单精度值single和包组packed arrays。后者很容易辨别因为这种类型通常会以数字结尾，比如float4，int4等等。正如它们的名字所表示的一样，这些类型的变量跟我们编程语言中的结构体structs类似，这也意味着每一个这样的变量包含了多个单精度值。在Cg语言中我们称之为包组packed arrays，尽管它们并非真的是传统意义上的数组。 在包组中的元素能像常见的结构体那样访问。通常它们表示成x，y，z 和w 。然而Cg语言还有另一种表示，就是r，g，b，a。尽管你使用x或者r去表示都是可以的，但是对于代码阅读者来说它们之间的区别就非常的大了。事实上，在着色器编程中，经常涉及到的就是位置和颜色的计算。你可能对下面的标准着色器代码中的代码片段还有印象吧： o.Alpha = _Color.a; 在这里，o是一个结构体而_Color就是一个包组。这也是为什么Cg要禁止上面提到的两种表示进行混用的原因：你不能使用_Color.xgz。 这里还有一个很重要的包组的特性，这种特性在C#中没有：swizzling[这个不知道怎么翻译]。Cg允许仅通过简单的一行代码就对包组内的元素进行寻址和重新排序。又是下面在标准着色器中熟悉的代码片段： o.Albedo = _Color.rgb; Albedo 是一个 fixed3类型，也就是说它里面包含了三个fixed类型的值。 然而_Color 是一个fixed4类型的定义。由于_Color定义包含的元素比 Albedo定义包含的元素要多，直接赋值的话，由于不匹配，肯定会产生一个编译错误。如果用C#代码来进行同样的操作，代码如下所示： o.Albedo.r = _Color.r;o.Albedo.g = _Color.g;o.Albedo.b = _Color.b; 相比于C#代码，在Cg语言中，我们可以用如下代码简写： o.Albedo = _Color.rgb; Cg语言也允许对元素进行重新排序。比如，通过_Color.bgr这个代码去交换红色和蓝色通道的颜色。 最后要讲一点，当一个单精度值赋值给包组时，这个值会被复制到包组的所有元素中去： o.Albedo = 0; // Black =(0,0,0)o.Albedo = 1; // White =(1,1,1) 这个就是Cg语言中的smearing特性。 Swizzling还可以被用作表达式的左值，不过仅当包组的具体元素能被这样使用： o.Albedo.rg = _Color.rg; 上面这种特性，叫做masking. 压缩矩阵真正发挥swizzling特性潜力的是在它应用于压缩矩阵的时候。Cg语言允许像float4x4这种类型，这是一个四行四列的矩阵。你可以使用_mRC标记访问矩阵中的单个元素，R表示元素所在的行而C表示元素所在的列： float4x4 matrix; // ... float first = matrix._m00; float last = matrix._m33;_mRC标记还可以接连使用： float4 diagonal = matrix._m00_m11_m22_m33;如果要获取矩阵的整行，可以使用中括号： float4 firstRow = matrix[0]; // Equivalent to float4 firstRow = matrix._m00_m01_m02_m03; 额外内容 包组是Cg语言中最棒的特性之一，你可以从下面的连接获得关于包组的更多信息： http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter02.html " }, { "title": "表面着色器和纹理贴图", "url": "/game-tech-post-old/posts/%E8%A1%A8%E9%9D%A2%E7%9D%80%E8%89%B2%E5%99%A8%E5%92%8C%E7%BA%B9%E7%90%86%E8%B4%B4%E5%9B%BE/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-10-24 00:00:00 +0800", "snippet": "第二章 表面着色器和纹理贴图在这一章节，我们将会探索表面着色器的使用。我们会用一个非常简单的磨砂材质开始讲起，然后会在后面讲解全息投影和高级的地形混合。 我们将能够使用纹理制作动画效果，混合等，或者用着色器去驱动我们想要的属性。在这一章你将会学习下面一些表面着色器的使用方法： 漫反射的着色处理 使用包组 向着色器添加纹理 通过改变UV值来移动纹理 法线贴图 创建一个带透明度的材质...", "content": "第二章 表面着色器和纹理贴图在这一章节，我们将会探索表面着色器的使用。我们会用一个非常简单的磨砂材质开始讲起，然后会在后面讲解全息投影和高级的地形混合。 我们将能够使用纹理制作动画效果，混合等，或者用着色器去驱动我们想要的属性。在这一章你将会学习下面一些表面着色器的使用方法： 漫反射的着色处理 使用包组 向着色器添加纹理 通过改变UV值来移动纹理 法线贴图 创建一个带透明度的材质 创建一个有全息效果的着色器 纹理的压缩和混合 在地形的表面绘制一个圆 ***介绍我们在第一章，创建你的第一个着色器 已经介绍了表面着色器，这是Unity引擎中的主要着色器类型。在这一章我们将更详细的向你展示它到底是什么以及它具体是如何工作的。通常来说，每个表面着色器都有两个重要的步骤。 首先，你需要在材质中描述你想指定的物理属性，比如漫反射的颜色，光滑度和透明度等。 这些属性将会在一个叫表面函数 surface function的函数中初始化并且保存在一个叫表面输出 surface output的结构体中。其次，表面输出 surface output结构体传入到一个光照模型 lighting model中。这是一个特殊的函数，这个函数会获取场景周围的光照信息。所有获得的这些信息将会被用于去计算你的模型最终在每一个像素点上最终呈现出来的颜色。这个光照函数就是着色器真正进行计算的地方，而正是这部分代码，决定了使用这个着色器材质的光照表现。下面的示意图简单的总结了表面着色器时如何工作的。在第三章，理解光照模型 将探索自定义光照模型，当学习到第五章，顶点函数 会着重讲解顶点修改器：漫反射的着色处理在我们开始学习纹理贴图之前，了解漫反射材质时如何工作的显得尤为重要。具体的一些物体也许会有统一的光照和光滑的表面，但是可以还是不够光滑来反射光线。磨砂材质是漫反射着色器使用的一个典型代表 。然而我们现实世界中，完全漫反射材质是不存在的；漫反射着色器是一种成本相对比较低的实现方式并且在低多边形风格中有着大量的应用。 始前准备 有好几种方式来创建你自己的漫反射着色器。最快的一个方式是在Unity5中创建一个表面着色器然后编辑它，移除所有的纹理，跟我们前面学习的第一章，创建你的第一个着色器 类似。 操作步骤 让我们开始创建我们的标准着色器，首先在Unity中新建一个标准着色器，然后按照下面的步骤进行修改： 首先在着色器的属性列表移除除_Color之外的所有属性： _Color (\"Color\", Color) = (1,1,1,1) 在SubShader{}代码块中，移除_MainTex，_Glossiness和_Metallic这三个变量。但是你不能删除uv_MainTex 这个变量，因为Cg着色器语言不允许输入结构体为空。这个值会被Unity简单的忽略。 删除surf()函数内代码内容并且把下面代码放在里面： o.Albedo = _Color.rgb; 最终，你的着色器代码应该如下所示： Shader \"CookbookShaders/Diffuse\" { Properties { Color (\"Color\", Color) = (1,1,1,1) } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 struct Input { float2 uv_MainTex; }; fixed4 _Color; void surf (Input IN, inout SurfaceOutputStandard o) { o.Albedo = _Color.rgb; } ENDCG } FallBack \"Diffuse\"} 当这个着色器从标准着色器修改调整之后，那么这个着色器将会使用基于物理原理的渲染去模拟光在模型表面的表现。如果你想试着获得一个看起来不那么真实表现的话，你可以直接修改#pragma部分，这样着色器就可以使用Lambert而不是Standard。如果你这样修改了的话，那么你还应该用SurfaceOutput替换掉**SurfaceOutputStandard **。按照书上的意思，应该是改成下图所示： 原理介绍 通过表面输出surface output，着色器可以让你材质的渲染属性跟光照模型lighting model进行沟通。 它基本封装了光照模型需要的所有参数。很明显，不同的关照模型肯定有着不同的表面输出结构。下表列出了在Unity中使用的三种主要的输出结构以及它们能如何使用： Type of shaders Unity 4 Unity 5 Diffuse Any Surface Shader:SurfaceOutput Standard:SurfaceOutputStandard Specular Any Surface Shader:SurfaceOutput Standard (Specular setup):SurfaceOutputStandardSpecular 表面输出SurfaceOutput结构体所包含的属性如下： fixed3 Albedo: 材质的漫反射颜色 fixed3 Normal: 空间中法线的切线，如果有法线的话 fixed3 Emission:这是材质指定的光的颜色 （如果是标准着色器Standard Shaders的话，它会被定义为half3类型） fixed Alpha: 这是材质的透明度 half Specular: 这是高光反射度【就是看起来多像高光？】，值的变化是从0到1 fixed Gloss: 这是高光强度 标准表面输出SurfaceOutputStandard结构体包含以下的属性： fixed3 Albedo: 这是材质的基本颜色(不管是高光反射还是漫反射) fixed3 Normal：空间中法线的切线，如果有法线的话 half3 Emission: 跟表面输出结构体一样的意思，不过在这里定义为half3类型，而在表面输出结构体中定义为fixed3类型。 fixed Alpha：同表面输出结构体 half Occlusion: 这个是遮挡（默认是1） half Smoothness: 这个是光滑度 (0 = 粗糙, 1 = 光滑) half Metallic:金属质感 0 = 无金属质感, 1= 金属 标准高光表面输出SurfaceOutputStandardSpecular结构拥有如下属性： fixed3 Albedo：同上 fixed3 Normal：同上 half3 Emission：同上 fixed Alpha：同上 half Occlusion：同上 half Smoothness：同上 fixed3 Specular: 这个是高光反射的颜色，这个跟表面叔叔结构体中的高光反射有很大的不同，因为这里是用颜色表示，而在表面输出结构体中只是一个简单的值 正确的给表面输出结构体赋值，初始化，是使用表面着色器的前提。 " }, { "title": "使用表面着色器的属性", "url": "/game-tech-post-old/posts/%E4%BD%BF%E7%94%A8%E8%A1%A8%E9%9D%A2%E7%9D%80%E8%89%B2%E5%99%A8%E7%9A%84%E5%B1%9E%E6%80%A7/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-09-02 00:00:00 +0800", "snippet": "使用表面着色器的属性现在我们已经为着色器创建了一些属性，这里我们将要正式的把这些属性跟着色器关联起来，这些属性就像着色器的调节器一样，可以让材质拥有更好的交互性。我们可以在材质的检查器面板(Inspector tab)使用着色器属性的值，因为我们为这个属性添加了一个变量名，但是如果你在着色器代码中想要通过这个变量名来获得这个值，我们仍然还有很多事情要做。 操作步骤 下面的步骤...", "content": "使用表面着色器的属性现在我们已经为着色器创建了一些属性，这里我们将要正式的把这些属性跟着色器关联起来，这些属性就像着色器的调节器一样，可以让材质拥有更好的交互性。我们可以在材质的检查器面板(Inspector tab)使用着色器属性的值，因为我们为这个属性添加了一个变量名，但是如果你在着色器代码中想要通过这个变量名来获得这个值，我们仍然还有很多事情要做。 操作步骤 下面的步骤展示了如何在表面着色器中使用属性： 开始之前，我们先删除下面的行的代码,就好像我们在章节创建一个基本的标准着色器中删除属性的操作步骤一样，删除_MainTex属性： _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} sampler2D _MainTex; fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; 下一步，添加下面这些行的代码到着色器代码中，添加到CGPROGRAM下面, add the following lines of code to the shader, below the CGPROGRAM line: float4 _AmbientColor;float _MySliderValue; 当第二部完成之后，我们就可以在着色器中使用属性的值了。我们把_Color属性的值与_AmbientColor值相加，并且把两者的结果赋值给o.Albedo。为了达成目的，我们需要在着色器代码中的surf()方法中添加如下代码： void surf (Input IN, inout SurfaceOutputStandard o) { fixed4 c = pow((_Color + _AmbientColor), _MySliderValue); o.Albedo = c.rgb; o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a;} 最终你的代码将会是如下所示。如果你在你的VSCode中保存好然后返回Unity编辑器，你的着色器将会重新编译。 如果没有什么错误，那么现在你可以修改材质的环境光和自发光的颜色，当然也可以通过滑动条增加最终颜色的饱和度。听巧妙的噢。 Shader \"CookbookShaders/StandardDiffuse3\" { // We define Properties in the properties block Properties { _Color (\"Color\", Color) = (1,1,1,1) _AmbientColor(\"Ambient Color\", Color) = (1,1,1,1) _MySliderValue(\"This is a Slider\", Range(0,10)) = 2.5 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 // We need to declare the properties variable type inside of the //CGPROGRAM so we can access its value from the properties block. CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 struct Input { float2 uv_MainTex;}; fixed4 _Color; float4 _AmbientColor; float _MySliderValue; void surf (Input IN, inout SurfaceOutputStandard o) { // We can then use the properties values in our shader fixed4 c = pow((_Color + _AmbientColor), _MySliderValue); o.Albedo = c.rgb; o.Alpha = c.a; } ENDCG } FallBack \"Diffuse\"} 提示下载示例代码你可以在Packt网站登陆后，下载所有已购买书籍的所有示例代码文件，下载地址：http://www.packtpub.com。如果你是在别处购买的书，那么请访问：http://www.packtpub.com/support然后注册，以便通过邮件直接获取相关的代码文件。 注意pow(arg1, arg2)这个方法是内建的，他的功能跟数学的幂函数power是等价的。第一个参数是底数，第二参数是指数 。想了解更深入的了解pow()方法，请去看Cg语言的教程。下面这个网址提供了非常棒的资源，能让你学习更多有关着色器的知识，并且里面有Cg着色器语言的所有函数的表：http://http.developer.nvidia.com/CgTutorial/cg_tutorial_appendix_e.html 下面的屏幕截图展示了通过材质的检查器面板(Inspector tab)来控制材质的属性，从而控制材质的颜色和饱和度： 原理介绍 当你在属性(Properties )代码块中声明一个新的属性时，等于是在材质的检查器面板( Inspector tab)给着色器添加了可以访问调整值[tweaked value]的方式。这个值存储在这个属性的变量名中。在这个例子中，_AmbientColor，_Color 和_MySliderValue这三个变量就是我们用来保存调整值的。为了让你能够在SubShader{} 这个代码块中使用这些值，你需要在这个代码块中对应创建三个变量，而且这三个变量的名字要跟属性代码块中的变量名保持一致。这样的话Unity会自动把SubShader{}代码块和属性代码块中的变量关联起来，然后让着色器知道这些变量使用的是相同的数据。另外，这个属性声明同时也告诉我们在SubShader{}代码块中对应的变量的数据类型，在后续有关着色器的优化相关的章节中，会用到这些。 当你再subshader代码块中创建好变量后，接下来你就可以再surf()方法中使用它们的值。在这个例子中，_Color，_AmbientColor与_MySliderValue这三个变量获得了来自材质的检查器面板(Inspector tab) 对应的值。变量_Color跟变量_AmbientColor这两个值相加，并且把这个值当作底数，_MySliderValue的值当作指数，进行幂运算。 大多数着色器都是从一个标准着色器开始，然后一步一步修改它直到它们符合设计的样子。我们现如的这个例子为以后需要散射组件的表面着色器打好了基础。 注意材质时一种资源(assets)。这意味着，当你的游戏在编辑器中运行时，你对它的任何改变都将会是永久的[这里解释一下，一般在Unity编辑器运行时，你对游戏做的修改，在停止运行后，又会恢复到运行之前的状态，这里材质不一样，修改之后，即使停止运行，它也不会恢复]。如果你不小心错误修改了属性的值，你可以通过快捷键Ctrl + Z取消这个修改。 相关补充 跟其他一些编程语言一样，Cg也是不允许有错误。如果你的着色器代码中有错误的话，着色器将不会起作用。当着色器不起作用时，你的材质会因为没有着色器而以品红的方式渲染： 当一个脚本没有被编译，Unity引擎会禁止你的游戏导出或者运行。 然而，着色器中有错误，Unity并不会阻止你运行你的游戏。如果你的着色器呈现出品红色，那么就应该检查一下到底哪里出现了问题。当你在Unity的编辑器中选中这个报错的着色器，那么你可以在检查器面板(Inspectortab)中看到一大串错误： 尽管错误提示展示了错误所在的行，但是通常不一定是引起错误的正真原因。上一张示例图所展示的错误是因为删除了了SubShader{}代码块中的sampler2D _MainTex变量引起的。 然而报错的地方是试图去访问这个未定义的变量所在的代码行。找到错误并且修复的过程就是我们常说的debug。你最常用的一些错误检查如下： 忘记括号匹配。 如果忘记用花括号对代码块进行配对匹配，那么编译器就会在代码文档的最后，开始或者新的代码块中提示错误。 忘记写分号结束语句。这是最常见的错误，同时也是最容易定位和修复的错误。通常会在下一行开始产生一个错误。 在属性(Properties)代码块中定义了一个属性，但是没有在SubShader{}代码块中定义对应的变量。【这两者是需要成对出现的，也就是说在属性(Properties)块里面定义了一个新的属性，那么在SubShader{}代码块中就需要声明一个与之对应的变量】 更Unity中的C#脚本不一样，Cg语言中的浮点值不需要在后面加f来表示浮点类型：浮点值1.0就写作1.0，而不是1.0f。 着色器中提示的错误很具有误导性，特别是因为它们那严格的语法约束。如果看不懂错误什么意思，那就直接百度或者谷歌。 或者去Unity的论坛搜索一下看看，里面可能就有跟你遇到相同问题（修复了相同问题）的开发者。 额外内容 在第二章，表面着色器和纹理纹理，我们会了解如何去掌握表面着色器(Surface Shaders)跟它们的属性(properties )。如果使用着色器的所有潜能和特性，到底能做些什么？如果你对这个问题感兴趣，你应该去看一看第十章，更高级的着色器技术 。里面有本书的一些最高级的着色器技术。 " }, { "title": "给着色器添加属性", "url": "/game-tech-post-old/posts/%E7%BB%99%E7%9D%80%E8%89%B2%E5%99%A8%E6%B7%BB%E5%8A%A0%E5%B1%9E%E6%80%A7/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-19 00:00:00 +0800", "snippet": "给着色器添加属性着色器的属性对于着色器管线来说时非常重要，因为艺术家或者用户想要添加纹理或者调整着色器的值都是通过著色器的属性来修改的。着色器的属性在材质的检查器面板(Inspector )中会提供GUI，提供图形界面让玩家去调整一个着色器，不用打开额外的编辑器。用Visual Studio Code打开你的着色器代码，从第2行到第7行的代码块就是着色器的属性(Properties )。...", "content": "给着色器添加属性着色器的属性对于着色器管线来说时非常重要，因为艺术家或者用户想要添加纹理或者调整着色器的值都是通过著色器的属性来修改的。着色器的属性在材质的检查器面板(Inspector )中会提供GUI，提供图形界面让玩家去调整一个着色器，不用打开额外的编辑器。用Visual Studio Code打开你的着色器代码，从第2行到第7行的代码块就是着色器的属性(Properties )。当前的这个着色器，他会有一个叫_MainTex的属性。如果你查看使用了这个着色器的材质，你能注意到着色器的检查器面板(Inspector )中有一个纹理(texture )的GUI元素。着色器中的这行代码为我们创建了这个GUI元素。还有就是，Unity工作人员通过编码方式和努力的迭代，让你改变属性的这个过程非常快速高效。 始前准备 让我们来了解一下这个过程在标准漫反射(StandardDiffuse)着色器中是如何工作的，为此我们要创建自己的属性并且学习更多相关的着色器语法。比如我们会修改之前创建的着色器。在这个修改的着色器中，不适用纹理，而是仅仅使用能从检查器面板(Inspector)直接修改的颜色和其他的属性。开始之前，我们先复制一个标准漫反射(StandardDiffuse)着色器。你可以在项目(Project)面板中选中它，然后按Ctrl + D。这样就会复制一份新的StandardDiffuse 1的着色器。【书上的写法有问题，在Inspector面板根本不能选中复制，应该在项目面板中选中在复制】注意你最好给你复制的这个着色器在第一行代码处给它一个恰当的名字。比如，Shader “CookbookShaders/StandardDiffuse”可以告诉Unity这个着色器叫StandardDiffuse并且把它分组到CookbookShaders这个着色器组。如果你是通过Ctrl + D复制的着色器，你新复制的这个着色器跟被复制的着色器就会用相同的名字和分组。为了避免混淆，一定要记得复制着色器代码之后，在第一行那里修改着色器的名字，给一个不会重复的名字。 操作步骤 当StandardDiffuse2这个着色器准备好后，我们就可以开始修改它的属性了： 在着色器的属性(Properties )块中，删除着色器中下面的属性代码，整行删除： _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} 当我们移除这个必要的属性后，着色器不会被编译直到所有跟_MainTex的代码都被移除。然我们删除另外有引用的代码： sampler2D _MainTex; 原始的着色器使用_MainTex给游戏模型上色。为了改变这个，我们替换掉surf()方法的第一行代码，通过如下代码： fixed4 c = _Color; 当你修改完成之后，返回Unity，然后着色器会被重新编译， 之后我们的材质检查器面板中就没有纹理选择这一选项了。 为了完成这个着色器的调整，让我们添加一个额外的属性给着色器，看看会有什么效果。输入下面的代码： _AmbientColor (\"Ambient Color\", Color) = (1,1,1,1) 我们在材质的检查器面板中添加了另一个颜色选项。现在，让我们来额外添加另一种类型的属性来找找属性语法的感觉。添加下面的代码到属性代码块中： _MySliderValue (\"This is a Slider\", Range(0,10)) = 2.5 我们创建了其他两种不同类型的GUI元素，它们可以让我们与着色器进行可视化的交互。我们这次创建了一个叫做This is a Slider的滑动条，就如下图所示： 着色器的属性让你可以通过可视化的方式调整着色器，而不用在着色器自己的代码中调整。 下一个知识点将会为你介绍如何利用这些属性创建一些更有趣的着色器。注意尽管属性属于着色器，但是着色器上属性的值却是保存在材质上的。不同的材质可以很安全的共用相同的着色器。从另一方面说，修改材质上的属性的值，将会影响到所有使用了该材质的游戏对象的外观。 原理介绍 每一个Unity的着色器都有它想要的内建的代码结构。属性代码块就是Unity所期望的功能之一。属性代码块的目的是让着色器编程人员能快速的创建GUI交互元素，并且将GUI元素与着色器代码相关联起来。那些你在着色器属性面板中申明的属性，能让你在着色器代码中使用，从而修改着色器中的一些值，颜色和纹理。 定义一个属性的语法[也可以叫语义，也可以叫语法糖]如下： 让我们来解释一下这个示意图。 当你第一次开始写一个新的属性时，你需要给这个书信一个变量名(Variable Name)。这个变量名能让着色器使用并且能让着色器代码获得来自该变量名绑定的GUI元素的值。这给我们节约了大量的时间因为我们不用自己来创建这么一个系统。属性的下一个元素时检查器面板GUI名称( Inspector GUI Name )和属性的类型(Type)，这两个元素放在一对括号中。当玩家想要交互和调整着色器时，检查器面板GUI名称( Inspector GUI Name )将会在材质的检查器面板(Inspector tab)中展示。类型(Type)就是这个属性想要控制的数据类型。在Unity着色器中，有很多属性可以使用的类型。下面这个表展示了我们在着色器中可以使用的变量类型： Surface Shader property types Range (min, max) 创建一个浮点类型的滑动条属性，值从最小值到最大值[min最小值，max最大值] Color 在检查器面板(Inspector tab)中创建一个颜色选取框，当你打开的时候会弹出一个调色板，颜色值(R,G,B,A)[四个浮点数，分别表示红，绿，蓝，透明度] 2D 创建了纹理选取框的GUI元素，可以让玩家通过拖拽的方式给着色器一张纹理 Rect 创建一个非2次幂纹理[NPOT]选取框，功能更2D属性类似 Cube 在检查器面板(Inspector tab)创建一个立方体纹理[大家想想天空盒],可以让玩家拖拽立方体纹理到着色器中 Float 在检查器面板(Inspector tab)中创建一个浮点型的值，但是没有滑动条 Vector 创建一个有四个值的属性，能让你表示方向或者颜色 最后就是这些属性的默认值(Default Value)了。可以在着色器代码中简单的给着色器的属性设置特定的值。在上一个图片属性改成颜色属性的列子中，属性 _AmbientColor的默认值是一个Color类型的默认值，其值为1，1，1，1。这个颜色属性需要一个RGBA或者float4或者r,g,b,a=x,y,z,w赋值。颜色属性第一次创建的时候默认值时白色。 额外内容 着色器属性的文档在Unity手册中的位置在http://docs.unity3d.com/Documentation/Components/SL-Properties.html " }, { "title": "如何把unity 4的旧着色器迁移至unity 5", "url": "/game-tech-post-old/posts/%E5%A6%82%E4%BD%95%E6%8A%8AUnity-4%E7%9A%84%E6%97%A7%E7%9D%80%E8%89%B2%E5%99%A8%E8%BF%81%E7%A7%BB%E8%87%B3Unity-5/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-15 00:00:00 +0800", "snippet": "如何把Unity 4的旧着色器迁移至Unity 5不可否认，在过去10年中图形学在电子游戏中获得了惊人的发展。每一个新游戏带来的尖端技术让我们的游戏画面更加接近现实。随着Unity引擎版本的不断迭代，它的着色器技术也自然而然的经历了相当大的变化。这也是为什第一次接触着色器的时候感到困惑的原因。在Unity5还没有推出之前，Unity自带了两种不同的着色器，分别是：漫反射(Diffuse)和高...", "content": "如何把Unity 4的旧着色器迁移至Unity 5不可否认，在过去10年中图形学在电子游戏中获得了惊人的发展。每一个新游戏带来的尖端技术让我们的游戏画面更加接近现实。随着Unity引擎版本的不断迭代，它的着色器技术也自然而然的经历了相当大的变化。这也是为什第一次接触着色器的时候感到困惑的原因。在Unity5还没有推出之前，Unity自带了两种不同的着色器，分别是：漫反射(Diffuse)和高光反射(Specular)。正如其名字所描述，它们分别用来模拟表面粗糙和表面光滑的材料。如果你现在使用的Unity5，那么你其实可以跳过这个知识点。该知识点会讲解如何在Unity5中重现这些效果。 始前准备 要开始这个知识点，前提时你有个用Unity4版本作为开发引擎工作空间，并且你使用了这个版本内建的一些着色器。当你开发新游戏的时候，毫无疑问你应该改选择最新版本的Unity引擎。然而如果你的项目已经使用了旧版的Unity引擎开发，那么你在迁移着色器前应该三思。引擎背后可能又很多东西都不一样了，即使有时候内建的着色器表面看起来可以正常工作，但是你写的脚本可未必能。所以如果你要迁移整个项目空间，这个时候首先要做的事情就是备份。但是要注意噢，仅仅只是保存Assets资源和场景可不够，同时所有的.meta文件也要一并保存，因为大多数Unity的配置信息保存在元数据中。在迁移项目的过程中最稳妥的办法还是要把整个项目空间所在文件夹都复制一份。最好的是物理拷贝一份，如果是windows就在资源管理器物理复制，如果是Mac就在Finder中物理复制。【建议大家将这个项目目录用压缩工具【如winrar】打包一份】。 操作步骤 如果你想要迁移你的内建着色器，有两个主要选择：采用自动升级的方式或者切换至标准着色器 着色器版本的自动升级 这种选择是最操作起来最简单的。Unity5可以导入使用旧版内建着色器的项目并且自动升级。你需要主义的是一旦升级完成后，那么你在Unity4中就不能再使用它们了。尽管这个过程并没有直接改变你的Assets资源，但是Unity的元数据已经被转换过了。要进行这个过程，你需要打开Unity5引擎，然后点击文件(File)|打开项目(Open Project)来打开你就项目所在的文件夹。然后回有提示问你是否愿意转换；然后点击升级(Upgrade)执行改过程。Unity就会重新导入所有的Assets资源并且重新编译所有的游戏脚本。如果你的项目非常巨大，这个过程可能回持续几个小时。一旦转换完成，来自Unity4的内建的旧着色器会被相应的替换掉。 你可以通过检查器面板验证这个转换，材质实例中从原来的Bumped Diffuse变为了Legacy Shader/Bumped Diffuse。 注意 尽管Unity4版本的漫反射，高光反射和其他内建的着色器现在已经已弃用了，但是Unity5依然向后对它们保持兼容。它们在材质的Legacy Shaders路径下的下拉列表中依然可以看到。 使用标准着色器 相比于使用旧版本的着色器，你可能想使用Unity5新的内建标准着色器替代它们。但是这么做之前，请留意新旧两个版本的着色器是基于不同的光照模型的，你的材质很可能看起来不一样。Unity4总共有8个不同的内建着色器，它被划分进了6个大类(法线(Normal)，透明(Transparent)，透明剪切(Transparent Cutout)，自发光(Self-Illuminated)和反射(Reflective))。但在Unity5中，它们都被上一个知识点所讲的那些标准着色器所替代了。不幸的是，没有什么很好的办法能够将旧着色器完美的迁移只新版本的着色器。但是你可以通过下面这个表格着重理解如何通过配置标准着色器去模拟unity4的旧着色器的效果： Shader Unity 4 Unity 4 (Legacy) Unity 5 Diffuse Diffuse Lambert Legacy Shader/Diffuse Lambert Standard Physically-based rendering: Metallic Workflow Specular Specular Blinn-Phong Legacy Shader/Specular Blinn-Phong Standard (Specular setup) Physically-based rendering: Specular Workflow Transparent Specular Blinn-Phong Legacy Shader/Transparent Vertex-Lit Standard Rendering Mode: Transparent Transparent Cutout Vertex-Lit Legacy Shader/Transparent Cutout Vertex-Lit Standard Rendering Mode: Cutout 你可以在旧材质的检查器面板(Inspector)上通过着色器(Shader)下拉菜单改变它所使用的着色器。所有你需要做的就是简单的选择适当的标准材质。如果你的旧着色器使用了纹理，颜色和发现题图，那么在新版本的标准着色器上也会自动使用。当然为了更好的接近之前旧版本着色器的光照模型，你可能需要配置标准着色器的相关参数。 下图展示的是常见的斯坦福兔(Stanford bunny )，它们分别使用旧版本的漫反射着色器(右)，被转换的标准着色器(左)，和把平滑度(Smoothness)设置成0的标准着色器(中)： 迁移用户自定义的着色器 如果你以前在Unity4上有写自定义的着色器，很有可能在Unity5中能直接正常使用。即使如此，Unity也有可能在着色器的工作原理上做了细小的改动，这些改动是可能引发一些错误和不一致性。有个变化最明显的重要参数就是光的强度。 光在Unity5中是原来亮度的两倍。所有的旧版本着色器在重写的的时候都应该考虑到这一点；如果你升级了你的着色器或者切换到标准着色器，你不会发现有任何的不同。但是如果你是自己写的光照模型，那么你就要注意确认光的强度不能再乘以二了。我们就用下面的代码举例来确认这种变化： // Unity 4c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten * 2);// Unity 5c.rgb = s.Albedo * _LightColor0.rgb * (diff * atten); 如果你还没有写过着色器，大可不必惊慌：光照模型会在第三章，理解光照模型 中全面详细的讲解。 注意 Unity5对着色器的处理相比于Unity4来说还有一些其他的变化，你可以下面这个网址中查看所有着色器在Unity5中的处理方式的变化 http://docs.unity3d.com/Manual/UpgradeGuide5-Shaders.html。 原理介绍 着色器的编写需要权衡画面表现和效率；效果逼真的着色器需要极大的计算量，可能导致严重的延迟。所以，有一点很重要，就是只使用我们确切需要的效果：如果一个材质不需要高光反射，那么就不要在着色器中去计算它们。这也是在Unity4中把这些效果拆分成了很多不同着色器的主要原因。 新版本的标准着色器有潜力替换掉先前旧版本的着色器，因为它把法线贴图，透明度和反射都包括在内了。然而，这个标准着色器经过巧妙的优化，使它能够只去计算用到的效果，没用到的效果就不计算。尽管这样，标准着色器主要还是设计用于模拟现实的材质。相比较而言，漫反射和高光反射着色器并不是为模拟现实的材质设计的。 这就是为什么从旧版本的着色器切换到标准着色器时，游戏对象在渲染的时候通常回发生一些细小的变化的原因。 额外内容 第三章， 理解光照模型, 将会深入探索漫反射和高光反射着色器的作用原理。尽管在Unity5中，它们已经被弃用了，但是如果你想要设计新的光照那么理解它们还是有必要的。 第四章，Unity 5中基于物理原理的渲染 ，将会介绍如何在Unity5中展现标准着色器的潜力。 " }, { "title": "读者反馈", "url": "/game-tech-post-old/posts/%E8%AF%BB%E8%80%85%E5%8F%8D%E9%A6%88/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "读者反馈非常欢迎来自各位读者的反馈。这能让我们知道你们是否喜欢这本书。你们给与的重要反馈可以让我们写出更适合且对你们更有帮助的内容。通常最简单的反馈方式是通过feedback@packtpub.com邮箱给我们发邮件，然后在反馈邮件的标题中告诉我们书标题。如果在本书中有你擅长领域的话题想跟我们讨论，或者你愿意把你专长领域的知识贡献给本书，也可以通过这个网址 www.packtpub.com/...", "content": "读者反馈非常欢迎来自各位读者的反馈。这能让我们知道你们是否喜欢这本书。你们给与的重要反馈可以让我们写出更适合且对你们更有帮助的内容。通常最简单的反馈方式是通过feedback@packtpub.com邮箱给我们发邮件，然后在反馈邮件的标题中告诉我们书标题。如果在本书中有你擅长领域的话题想跟我们讨论，或者你愿意把你专长领域的知识贡献给本书，也可以通过这个网址 www.packtpub.com/authors的指引进行操作" }, { "title": "第一章.创建你的第一个着色器", "url": "/game-tech-post-old/posts/%E7%AC%AC%E4%B8%80%E7%AB%A0.%E5%88%9B%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%9D%80%E8%89%B2%E5%99%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "第一章 创建你的第一个着色器在这一章我们包含了一些在当今游戏开发着色器管线中更通用的漫反射技术基础。在这一章我们将会学习下面的知识点: 创建一个基础的标准着色器 从Unity4迁移旧着色器至Unity5 为着色器添加属性 在表面着色器中使用属性介绍让我在脑海中想象一个完全由白色绘制立方体。尽管立方体的每一个面的颜色都是相同的，但是由于不同方向的光线照射和我们看这个立方体的角度的不同，...", "content": "第一章 创建你的第一个着色器在这一章我们包含了一些在当今游戏开发着色器管线中更通用的漫反射技术基础。在这一章我们将会学习下面的知识点: 创建一个基础的标准着色器 从Unity4迁移旧着色器至Unity5 为着色器添加属性 在表面着色器中使用属性介绍让我在脑海中想象一个完全由白色绘制立方体。尽管立方体的每一个面的颜色都是相同的，但是由于不同方向的光线照射和我们看这个立方体的角度的不同，我们总能发现立方体不同的白色阴影。这种层级的逼真场景就是通过3D图形学中的着色器实现的，它是一种模拟光的作用原理的特别的程序。一个木质的立方体和一个金属的立方体也许可以是同一种3d模型，之所以让他们看起来一个是木质的，一个是金属的，就是因为它们使用了不同的着色器的缘故。我们循序渐进，第一章将会向你介绍如何在Unity中进行着色器编码。如果你从来没有编写着色器的经验，那么在这一章，你将会了解着色器是什么，他们如何工作和如何自定义着色器。 接着在这一章的结尾，你将会学习如何构建拥有基础操作的基础着色器。有了这些知识后，那么你将可以创建任何的表面着色器。创建一个基本的标准着色器每一个Unity游戏开发者应该都对组件(components)这个概念非常熟悉。游戏中的对象都有很多的组件，这些组件决定了游戏中的对象看起来是什么样子和会有什么样的行为。然而游戏脚本(scripts ) 定义的是游戏对象会有怎样的行为，渲染器(renderers )决定游戏对象如何出现在屏幕中。 对于我们想要看到游戏对象类型，Unity本身提供了一些渲染器。每一个3D模型通常都有一个网格渲染器。一个游戏对象应该只能有一个渲染器，但是一个渲染器它可以包含多个材质(materials)。 每个材质封装了一个着色器–3D图形的最后一环。这些组件的关系可以用如下的示意图表示：理解这些组件之间的不同之处对于理解着色器的工作原理是很有必要的 始前准备开始学习这个知识点之前，你需要打开你的Unity5并且创建一个新的项目。本书的内容讲解都会在这个项目中开展，随着学习的深入你之后自己创建的着色器都可以放在这。这一步完成之后—-欢迎来到着色器实时编程的精彩世界。 操作步骤 在创建我们的第一个着色器前，让我们为实验着色器创建一个简单游戏场景。首先我们导航到Unity的菜单栏，然后选择游戏对象|创建空对象。然后在Unity编辑器的层级面板(Hierarchy)选中刚刚创建的空对象，在上面创建一个平面作为地面，再创建几个球体用来应用我们的着色器，然后在场景里面创建平行光源。当场景弄好后，我们接下来就按步骤开始着色器的编写： 在编辑器的项目(Project)窗口中，直接右键选择创建(Create)|文件夹(Folder)。【这里的文件夹名字我就直接用英文了，大家在自己开发的过程中也尽量用有意义的英文文件夹吧】注意如果你导入了本书提供的项目文件（就是你从网站上下载的代码，他是一个unitypackage包，导入之后这个文件自动就有了），你可以直接跳至步骤4。 选择该文件夹，右键然后选择重命名(Rename)，把这个文件夹命名成Shaders。或者你也可以选中该文件夹，然后按F2，重命名为Shaders。 用上面同样的方法创建一个Materials的文件夹，用来放材质文件的。 右键Shaders文件夹，然后在出的窗口中选择创建(Create)|着色器(Shader)|标准表面着色器(Standard Surface Shader)（这里注意跟原文不一样，创建一个着色器要三步，书中只有两部）。接着我们创建一个材质，右键Materials文件夹，然后在弹窗中选择创建(Create)|材质(Material)。 把刚刚创建的着色器和材质都命名成StandardDiffuse。【各位，文件名也用英文呀，因为怕Unity对中文的支持不好】 然后用Visual Studio 2015或者Visual Studio Code打开StandardDiffuse这个着色器【这里我不建议用MonoDevelop这个编辑器，原文是用这个，不好用，强烈建议用各位用Visual Studio Code打开，这个编辑器很好用，一定要去试试】 注意 打开着色器你会发现Unity其实已经为我们的着色器生成了一些基本的代码。这些基础代码给了你一个基础的漫反射着色器，而且可以传入一张纹理。我们会在后面的步骤修改这些着色器代码，创建自己的着色器。 首先我们给自己的着色器一个自定义的文件夹【这不是传统的文件夹，我更倾向理解为材质选择路径】，这样方便使用时可以按照这个文件夹找到它。着色器的第一行代码是一段描述，这段描述的作用是当我们为材质选择着色器时，这段描述会会转换成选择路径，给材质添加我们自己的着色器。我们把这个路径重写为 Shader “CookbookShaders/StandardDiffuse”。当然你也能在任何时间把它命名为任何路径。不用特别在意这个路径名。然后记得保存我们的代码，然后切换回Unity编辑器。当Unity编辑器检测到着色器代码有更新，它会自动重新编译着色器。修改后的着色器代码如下所示： Shader \"CookbookShaders/StandardDiffuse\" { Properties { _Color (\"Color\", Color) = (1,1,1,1) _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {} _Glossiness (\"Smoothness\", Range(0,1)) = 0.5 _Metallic (\"Metallic\", Range(0,1)) = 0.0 } SubShader { Tags { \"RenderType\"=\"Opaque\" } LOD 200 CGPROGRAM // Physically based Standard lighting model, and enable shadows on all light types #pragma surface surf Standard fullforwardshadows // Use shader model 3.0 target, to get nicer looking lighting #pragma target 3.0 sampler2D _MainTex; struct Input { float2 uv_MainTex; }; half _Glossiness; half _Metallic; fixed4 _Color; void surf (Input IN, inout SurfaceOutputStandard o) { // Albedo comes from a texture tinted by color fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // Metallic and smoothness come from slider variables o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a; } ENDCG }FallBack \"Diffuse\" } 专业一点说，这是一个基于物理原理渲染(physically-basedrendering)的表面着色器，只是Unity5把它作为了一个内建的标准着色器。根据这种着色器的字面意思，这是一种根据现实中光的物理原理，来模拟游戏中光照射到物体时所表现的物理特性，通过这种模拟，来虚拟现实。 如果你用的时早期版本的着色器（比如Unity4），那么你的着色器代码跟现在的会有比较大的差别。相比于现在的基于物理原理的着色器技术而言，Unity4使用的技术还是相对比较简单的。所有的这些着色器类型我们会在本书后面的章节介绍。 当你的着色器创建好后，我们需要将它与材质关联起来。选中我们之前在步骤4创建的StandardDiffuse材质，然后看检查器面板(Inspector tab)。然后再着色器(Shader)下拉列表中选择CookbookShaders | StandardDiffuse。（如果你在第7步修改的路径跟书上不一样，那么这里的选项也不一样）通过上述步骤，你的着色器就会跟这个材质关联起来，你现在可以把这个材质添加到一个游戏对象中去了。 注意 你可以在项目窗口(Project tab)选中这个材质，然后直接拖拽到你在游戏场景中的游戏对象身上。当然你也可以直接选中这个材质，然后拖拽到Unity编辑器的检查器面板(Inspector tab)上，把这个材质应用到这个游戏对象上，前提是你要先选中这个游戏对象，然后再拖拽，这样检查器面板(Inspector tab)显示的才是游戏对象的属性。 下面时这个示例的屏幕截图：【各位按照自己的情况来就行了，不一定非要找一个跟书本一样的模型】 看起来很简陋, 但是着色器开发环境搭建好了，接下来我们可以开发自己想要的着色器了 原理介绍 Unity帮助你简化了着色器运行的环境配置，你很多时候只需要点击鼠标就可以完成。但事实上这些简单的操作背后有着大量的各种各样的工作，只是Unity引擎替你做了。Unity 使用CG着色器语言，并且它在背后做了大量的工作【unity会自动生成相应的CG代码】，让你在写着色器的时候非常高效。用表面着色器格式的语言来写着色器更加方便。比如处理你自己的纹理的坐标或者线性变换矩阵，这些功能都已经准备好，不用再从头开始。以前写着色器，你必须重新创建一个着色器然后一遍又一遍的重新很多代码。随着你对表面着色器的深入理解，你可能会越想了解CG语言更底层的功能以及Unity是如何处理那些更底层的图形处理单元(graphics processing unit (GPU))任务的。 注意Unity项目中的所有文件都有自己的引用，跟它在你电脑上具体的某个文件夹上没有关系。我们在编辑器上，你可以可以随便移动着色器文件和材质文件，它们之间不会有关联信息丢失的风险。但你千万不要在编辑器外面移动这些文件，【比如直接打开项目文件夹，在电脑上直接移动这些文件】这样的话Unity编辑器不能够更新这些文件之间的关联，可能会发生丢失的情况。 我们通过简单的修改着色器的路径属性可以给着色器一个我们想要的名字，我们在Unity环境中进行了基础的漫反射着色器的研究，包括光呀，阴影呀之类的。而这些，仅仅是通过改变一行代码。 额外内容 在Unity5中内建的着色器的源码通常被隐藏起来了，你不能像打开自己的着色器代码那样打开它。在你的Unity安装目录Unity45\\Editor\\Data\\CGIncludes，你能找到大部分的Unity内建的CG功能代码。在这个目录下面，你能找到被Unity隐藏起来的一些着色器。经过多年的迭代，它们已经发生了很多的改变；如果你想查阅Unity不同版本之间的色器源码发生了那些变化，下面这个网站也许是个好去处：https://unity3d.com/get-unity/download/archive。选择你的Unity版本，然后在下拉列表中选择内建着色器(Built in shaders) ，如下图所示。 此时我们需要留意其中的三个文件—UnityCG.cginc，Lighting.cginc和UnityShaderVariables.cginc。我们现在学习的着色器都只要用到这三个相关的文件： 第十章.更高级的着色器技术, 我们将会深层次探索如何使用GcInclude进行模块化的着色器编程" }, { "title": "示例代码下载", "url": "/game-tech-post-old/posts/%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81%E4%B8%8B%E8%BD%BD/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "示例代码下载通过这个网站http://www.packtpub.com，你可以用自己的账号下载本书的实例代码(其实我本人是建议自己手动敲一遍，我试了一下，代码是可以直接在这个网站下载的，就算你没有购买这本书也是可以的。但是需要注册一个账号才行，然后搜索到这本书，这本书的页面下面就有下载代码的链接)。如果你在别的地方购买了这本书，那么你可以浏览网站 http://www.packtpub.co...", "content": "示例代码下载通过这个网站http://www.packtpub.com，你可以用自己的账号下载本书的实例代码(其实我本人是建议自己手动敲一遍，我试了一下，代码是可以直接在这个网站下载的，就算你没有购买这本书也是可以的。但是需要注册一个账号才行，然后搜索到这本书，这本书的页面下面就有下载代码的链接)。如果你在别的地方购买了这本书，那么你可以浏览网站 http://www.packtpub.com/support](https://www.packtpub.com/support)注册一个账号，然后在该页面直接通过书名搜索，也能找到这些文件的下载链接。代码文件可以通过下面的步骤获得： 通过邮箱和账号密码在我们的网站上登陆或者注册。 把网页拉到最下面，点击支持主页(Support Home)（这本书出了很久了，网页早就改版了，这是我实际打开网页的操作步骤）。 然后点击该页面左边的代码下载&amp;勘误表(Code Downloads &amp; Errata)。 然后在搜索(Search)框中输入你的书名（不用输入完整的书名，支持模糊搜索）。 选择那本你想要下载代码的书。 然后在下面的下拉菜单中选择你是从哪儿购买本书的（不要紧，随便选一个，然后下拉菜单的下面就会有一个下载链接）。 然后点击代码下载（需要注册，链接早就生成了，为了方便大家，我贴出链接，点击就可以下载了，不清楚是否是永久链接） 下载好后，请自行解压，然后就可以获得本书的代码了。" }, { "title": "盗版声明", "url": "/game-tech-post-old/posts/%E7%9B%97%E7%89%88%E5%A3%B0%E6%98%8E/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "盗版声明在网上，所有媒体的版权资料盗版问题从未停歇。 在Packt网，我们非常重视保护我们的版权和许可证。如果你在英特网上看到任何来自我们工作成果的 非法拷贝，不管来自那里，还请你提供给我们地址或者网址，这样我们可以挽回我们的损失。还请通过copyright@packtpub.com邮箱联系我们。我们非常感激您帮助我们保护作者和保护我们继续给你带来有价值的内容。", "content": "盗版声明在网上，所有媒体的版权资料盗版问题从未停歇。 在Packt网，我们非常重视保护我们的版权和许可证。如果你在英特网上看到任何来自我们工作成果的 非法拷贝，不管来自那里，还请你提供给我们地址或者网址，这样我们可以挽回我们的损失。还请通过copyright@packtpub.com邮箱联系我们。我们非常感激您帮助我们保护作者和保护我们继续给你带来有价值的内容。" }, { "title": "本书的一些文体要求", "url": "/game-tech-post-old/posts/%E6%9C%AC%E4%B9%A6%E7%9A%84%E4%B8%80%E4%BA%9B%E6%96%87%E4%BD%93%E8%A6%81%E6%B1%82/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "本书的一些文体说明在书中你可以发现很多种不同的文本样式用来表示不同的信息内容。这里列举几个来解释一下。（需要说明一下的是，我在翻译的过程中，代码的字体样式可能会跟书本上不一样，我主要是用markdown的代码块来表示。然后它的粗体，比如强调，那我就用markdown中的强调标签来表示，说声抱歉了，希望大家能看的懂）代码块，数据库表名，文件夹名字 ，文件名字，文件扩展名，路径名称，虚拟URL（...", "content": "本书的一些文体说明在书中你可以发现很多种不同的文本样式用来表示不同的信息内容。这里列举几个来解释一下。（需要说明一下的是，我在翻译的过程中，代码的字体样式可能会跟书本上不一样，我主要是用markdown的代码块来表示。然后它的粗体，比如强调，那我就用markdown中的强调标签来表示，说声抱歉了，希望大家能看的懂）代码块，数据库表名，文件夹名字 ，文件名字，文件扩展名，路径名称，虚拟URL（觉得这个翻译不准确），用户输入，推特账号等会按照如下表示：“请输入下面的代码到你的着色器属性块（**Properties **）中”void surf (Input IN, inout SurfaceOutput o) { \tfloat4 c; \tc = pow((_EmissiveColor + _AmbientColor), _MySliderValue); \to.Albedo = c.rgb; o.Alpha = c.a;} 当我们想提醒你代码块中的特别部分，那么对应的代码行或者语句会用粗体标记,比如那个void：(代码块中我不知道怎么加粗，下面这个就不用代码块了)void surf (Input IN, inout SurfaceOutputStandard o){​\tfixed4 c = pow((_Color + _AmbientColor), _MySliderValue);​\to.Albedo = c.rgb;​\to.Metallic = _Metallic;​\to.Smoothness = _Glossiness;​\to.Alpha = c.a;}新的术语 和 非常重要的词语 都应该用粗体表示.像出现再电脑屏幕中的菜单和弹窗中的文本，也会用粗体加以强调。比如：“在Unity编辑器的菜单栏中的“项目(Project),在资产(Assets)文件夹上右键单击和在菜单中选择创建(Create)|文件夹(Folder)。” （中文后面括号里的是英文版的编辑器中菜单项的名字）注意(Note)警告或者很重要的注意会像这样，有个注意(Note)提醒你。提示(Tip)提示和小技巧会像这样，有个提示(Tip)提示你。" }, { "title": "本书有问题请联系", "url": "/game-tech-post-old/posts/%E6%9C%AC%E4%B9%A6%E6%9C%89%E9%97%AE%E9%A2%98%E8%AF%B7%E8%81%94%E7%B3%BB/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "本书有问题请联系如果您对本书有任何层面的问题，您可以通过邮箱questions@packtpub.com联系我们，我们会尽己所能改善这些问题。", "content": "本书有问题请联系如果您对本书有任何层面的问题，您可以通过邮箱questions@packtpub.com联系我们，我们会尽己所能改善这些问题。" }, { "title": "本书一些彩图的下载", "url": "/game-tech-post-old/posts/%E6%9C%AC%E4%B9%A6%E4%B8%80%E4%BA%9B%E5%BD%A9%E5%9B%BE%E7%9A%84%E4%B8%8B%E8%BD%BD/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "本书一些彩图的下载这本书中的彩图，比如说屏幕截图/示意图我们都把他放在了一个PDF文件中。希望这些图片可以让你更好的理解屏幕输出图像的变化。 你可以通过下面的链接下载这个PDF文件https://www.packtpub.com/sites/default/files/downloads/Unity5xShadersAndEffectsCookboo", "content": "本书一些彩图的下载这本书中的彩图，比如说屏幕截图/示意图我们都把他放在了一个PDF文件中。希望这些图片可以让你更好的理解屏幕输出图像的变化。 你可以通过下面的链接下载这个PDF文件https://www.packtpub.com/sites/default/files/downloads/Unity5xShadersAndEffectsCookboo" }, { "title": "客户支持", "url": "/game-tech-post-old/posts/%E5%AE%A2%E6%88%B7%E6%94%AF%E6%8C%81/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "客户支持很高心您能拥有此书，为了让您物有所值，我们还为你准备了很多东西（很搞不懂这也要搞一个章节出来，就一句话）。", "content": "客户支持很高心您能拥有此书，为了让您物有所值，我们还为你准备了很多东西（很搞不懂这也要搞一个章节出来，就一句话）。" }, { "title": "勘误表", "url": "/game-tech-post-old/posts/%E5%8B%98%E8%AF%AF%E8%A1%A8/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "勘误表尽管我们非常注意本书内容的准确性，但还是会有不小心出错的地方。如果您在我们出版的书中（不限本书）找到了错误，有可能是文字错误或者代码错误，我们非常欢迎您将这些错误报告给我们。如此善举，既解他人之惑，亦可助改善此书。如果您发现任何勘误，请通过链接https://www.packtpub.com/support/errata （原书写的链接失效了）向我们报告。当您的勘误确认后，您提交的勘误...", "content": "勘误表尽管我们非常注意本书内容的准确性，但还是会有不小心出错的地方。如果您在我们出版的书中（不限本书）找到了错误，有可能是文字错误或者代码错误，我们非常欢迎您将这些错误报告给我们。如此善举，既解他人之惑，亦可助改善此书。如果您发现任何勘误，请通过链接https://www.packtpub.com/support/errata （原书写的链接失效了）向我们报告。当您的勘误确认后，您提交的勘误将会被接受并且勘误会上传至我们的网站和任何已存在的勘误名单中。 如果您想看看之前的勘误提交，可以访问https://www.packtpub.com/support/code-downloads（原书的网址失效了，现在是这个），然后输入书名搜索，你想要的信息会出现在下面的勘误部分。" }, { "title": "内容结构", "url": "/game-tech-post-old/posts/%E5%86%85%E5%AE%B9%E7%BB%93%E6%9E%84/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-13 00:00:00 +0800", "snippet": "内容结构在本书中， 会经常出现一系列的小标题 (始前准备，操作步骤，原理介绍，额外内容 ，相关补充)。主要功能是对每一个知识点进行说明，如何完成该知识点的掌握。下面说明具体的用法： 始前准备 这个部分会告诉你这个知识点会学习什么，怎么安装和设置对应的软件。 操作步骤 这个部分包含了学习该知识点包含那些步骤。 原理介绍 该部分通常是为了详...", "content": "内容结构在本书中， 会经常出现一系列的小标题 (始前准备，操作步骤，原理介绍，额外内容 ，相关补充)。主要功能是对每一个知识点进行说明，如何完成该知识点的掌握。下面说明具体的用法： 始前准备 这个部分会告诉你这个知识点会学习什么，怎么安装和设置对应的软件。 操作步骤 这个部分包含了学习该知识点包含那些步骤。 原理介绍 该部分通常是为了详细解释“操作步骤”这个部分的知识原理，上面的每一步到底做了什么。 额外内容 为了让读者了解更多与该知识点相关的额外知识，我们才准备了这个额外信息让读者阅读。 相关补充 如果想了解更多与该知识点相关的信息，这里还额外提供了一些相关链接。 " }, { "title": "本书的适合人群", "url": "/game-tech-post-old/posts/%E6%9C%AC%E4%B9%A6%E7%9A%84%E9%80%82%E5%90%88%E4%BA%BA%E7%BE%A4/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-10 00:00:00 +0800", "snippet": "本书的适合人群本书适合色器编程初学者，或者想通过专业的后处理特效让游戏更棒的开发者。当然开发者本身需要对Unity游戏引擎有比较深入的理解。", "content": "本书的适合人群本书适合色器编程初学者，或者想通过专业的后处理特效让游戏更棒的开发者。当然开发者本身需要对Unity游戏引擎有比较深入的理解。" }, { "title": "学习的过程中你需要准备的", "url": "/game-tech-post-old/posts/%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%BD%A0%E9%9C%80%E8%A6%81%E5%87%86%E5%A4%87%E7%9A%84/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-10 00:00:00 +0800", "snippet": "学习的过程中你需要准备的下面列举了在学习本书知识的过程中必须的工具软件和可选的工具软件: Unity5引擎 一款3D建模软件，比如Maya，3DMax，或Blender (可选l) 一款2D图片编辑软件，比如PS或者Gimp (可选)", "content": "学习的过程中你需要准备的下面列举了在学习本书知识的过程中必须的工具软件和可选的工具软件: Unity5引擎 一款3D建模软件，比如Maya，3DMax，或Blender (可选l) 一款2D图片编辑软件，比如PS或者Gimp (可选)" }, { "title": "这本书包含哪些内容", "url": "/game-tech-post-old/posts/%E8%BF%99%E6%9C%AC%E4%B9%A6%E5%8C%85%E5%90%AB%E5%93%AA%E4%BA%9B%E5%86%85%E5%AE%B9/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-09 00:00:00 +0800", "snippet": "这本书包含哪些内容第一章,创建你的第一个着色器, 向你介绍如何在unity4和unity5中编写着色器代码（我会试着在unity2018上去实验，保证shader代码的正常执行，不限于unity4和5）。第二章, 表面着色器和纹理贴图, 介绍了一些如何实现表面着色器的通用且实用的技术，比如如何给游戏模型使用纹理和法线贴图。第三章, 理解光照模型，带你深入理解在给模型使用着色器时光带来的影响，...", "content": "这本书包含哪些内容第一章,创建你的第一个着色器, 向你介绍如何在unity4和unity5中编写着色器代码（我会试着在unity2018上去实验，保证shader代码的正常执行，不限于unity4和5）。第二章, 表面着色器和纹理贴图, 介绍了一些如何实现表面着色器的通用且实用的技术，比如如何给游戏模型使用纹理和法线贴图。第三章, 理解光照模型，带你深入理解在给模型使用着色器时光带来的影响，这一章会教你一些如何实现自定义的光照模型的技术技巧，以便于你去实现一些独特的特效，比如Toon着色器效果。第四章, Unity 5中基于物理原理的渲染, 这一章为你介绍在unity5中基于物理原理的标准渲染技术，这些技术主要是为了在你的游戏中实现次世代的画面（直译就是看起来跟现实世界一样）。会向你解释如何尽可能的模拟这种现实，让你对透明度，反射表面和全局光照有更深入的理解。第五章, 顶点函数,向你介绍如何使用着色器来修改游戏中物体的几何特性；想知道范围体爆炸，着色器模拟下雪等特效嘛？这一章里的着色器操作顶点的技术技巧会告诉你如何实现第六章, 片元着色器和抓取通道, 这一章会解释如何使用半透明材质和抓取通道来实现扭曲形变效果第七章, 移动设备着色器适配，主要介绍如何针对移动设备进行优化。第八章, 通过Unity 渲染纹理实现屏幕效果,介绍了通过该技术才能更容易实现的视觉特效的实现方式。第九章, 游戏和屏幕效果,向你介绍一些游戏后处理特效，让游戏模拟的更加真实，比如夜视仪特效。第十章, 更高级的着色器技术,介绍一些向毛坯特效的着色器，热图渲染等本书会涉及的大部分高级技术技巧" }, { "title": "电子书 优惠折扣 以及更多信息", "url": "/game-tech-post-old/posts/%E7%94%B5%E5%AD%90%E4%B9%A6-%E4%BC%98%E6%83%A0%E6%8A%98%E6%89%A3-%E4%BB%A5%E5%8F%8A%E6%9B%B4%E5%A4%9A%E4%BF%A1%E6%81%AF/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-06 00:00:00 +0800", "snippet": "电子书, 优惠折扣, 额外信息**Packt **电子书网站拥有包含pdf和ePub格式的所有已经出版的书籍的电子书。你可以在www.PacktPub.com 更新你的电子书版本并且如果你购买过相应的纸质书籍的话，可以在购买对应的电子版本时享有折扣。你可以通过 customercare@packtpub.com 这个邮箱向我们了解优惠的详细信息。你可以在 www.PacktPub.com 阅...", "content": "电子书, 优惠折扣, 额外信息**Packt **电子书网站拥有包含pdf和ePub格式的所有已经出版的书籍的电子书。你可以在www.PacktPub.com 更新你的电子书版本并且如果你购买过相应的纸质书籍的话，可以在购买对应的电子版本时享有折扣。你可以通过 customercare@packtpub.com 这个邮箱向我们了解优惠的详细信息。你可以在 www.PacktPub.com 阅读一系列免费的技术文章，现在在网站注册可以获知最新的免费和折扣信息https://www2.packtpub.com/books/subscription/packtlib （告诉大家一个不幸的消息，上面这个网址已经过期了）你是否因为IT技术问题缺乏具体的示例而苦恼，上面这个网站也许可以帮到你，这是一个在线的数字图书馆。你可以在这个数字图书馆上搜索，获取资料和阅读Packt电子书网站为你准备的电子书。" }, { "title": "前言", "url": "/game-tech-post-old/posts/%E5%89%8D%E8%A8%80/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-06 00:00:00 +0800", "snippet": "前言Unity 5.x Shaders and Effects Cookbook这本书能让你在Unity5引擎中创建着色器和特效更加得心应手，能让你入门起来比较容易，学会创建大部分基础的着色器，并且学会如何组织你的着色器代码。本书的章节安排是循序渐进的，每一章节的基础知识，旨在后面让你能实现更高级的技术技巧，比如实现范围体爆炸效果，毛皮特效等。这本书是专门在Unity5这个游戏引擎下讲解的，...", "content": "前言Unity 5.x Shaders and Effects Cookbook这本书能让你在Unity5引擎中创建着色器和特效更加得心应手，能让你入门起来比较容易，学会创建大部分基础的着色器，并且学会如何组织你的着色器代码。本书的章节安排是循序渐进的，每一章节的基础知识，旨在后面让你能实现更高级的技术技巧，比如实现范围体爆炸效果，毛皮特效等。这本书是专门在Unity5这个游戏引擎下讲解的，希望帮助你掌握诸如基于物理原理的渲染和全局光照等知识，让你尽可能获得照片级的效果。在每一章的结尾，你都会获得一些新的技巧，这些技巧有助于提高你的着色器质量并且让你在写着色器的时候更加有效率。 为了让你能从入门到专家，每一个章节的特殊技巧和知识点都是我们为你精心编排的。对于着色器的初学者来说，你也可以通过一个章节一个章节的阅读，逐渐丰富你的着色器知识。不管怎样，通过本书的知识点，可以让你的游戏在次世代看起来更棒。当你完成这本书的学习之后，在Unity3d创建游戏的过程中，你就可以有各种各样的着色器用于你的游戏，并且了解怎么向你的游戏中去添加它们，怎么向你的游戏添加各种特效，怎么去优化你的游戏。让我们开始吧。" }, { "title": "为什么订阅", "url": "/game-tech-post-old/posts/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AE%A2%E9%98%85/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-06 00:00:00 +0800", "snippet": "为什么希望你订阅?可以查阅所有 Packt网站发布的的书籍可以拷贝，打印所有书籍可以通过浏览器查找你最需要的资料", "content": "为什么希望你订阅?可以查阅所有 Packt网站发布的的书籍可以拷贝，打印所有书籍可以通过浏览器查找你最需要的资料" }, { "title": "Www.packtpub.com", "url": "/game-tech-post-old/posts/www.PacktPub.com/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-06 00:00:00 +0800", "snippet": "www.PacktPub.com这是一个电子书的网站，等于是帮这个网站宣传了吧，大家直接点击超链接进去看就行了。一般来说，你只要在上面买了电子书，特别是技术书籍，相关的代码，附件也可以从上面下载。", "content": "www.PacktPub.com这是一个电子书的网站，等于是帮这个网站宣传了吧，大家直接点击超链接进去看就行了。一般来说，你只要在上面买了电子书，特别是技术书籍，相关的代码，附件也可以从上面下载。" }, { "title": "鸣谢", "url": "/game-tech-post-old/posts/%E9%B8%A3%E8%B0%A2/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-05 00:00:00 +0800", "snippet": "鸣谢本书作者Alan ZucconiKenneth Lammers审稿Kenneth Lammers组稿编辑Priya Singh策划编辑Rahul NairErol Staveley项目内容编辑Mehvash Fatima技术编辑Pranil PathareDanish Shaikh文字编辑Tasneem Fatehi项目助理Kinjal Bari校对员Safis Editing索引员Mo...", "content": "鸣谢本书作者Alan ZucconiKenneth Lammers审稿Kenneth Lammers组稿编辑Priya Singh策划编辑Rahul NairErol Staveley项目内容编辑Mehvash Fatima技术编辑Pranil PathareDanish Shaikh文字编辑Tasneem Fatehi项目助理Kinjal Bari校对员Safis Editing索引员Monica Ajmera Mehta图像Kirk D’PenhaDisha Haria制作协调员Nilesh Mohite封面设计Nilesh Mohite关于作者Alan Zucconi 是一个充满激情的开发者, 作者, 和一个激励的演讲者, 是开发者领域的佼佼者。 有着过去10年来相关领域的专业技能积累，并且决定在今后把精力都放在学术领域和游戏产业领域。作为一名自由职业者，他以非凡的创造力去探索如何让游戏更好的与艺术结合。 在此之前，他在伦敦帝国理工学院工作，在这里他发现了他教学和写作的激情。 他的头衔包括了 gravity puzzle, 0RBITALIS, 和the upcoming time travel platformer, Still Time（这些单词实在不知道怎么翻译了，应该是游戏名字）.Kenneth Lammers 在游戏领域有超过15年的经验, 担任过角色艺术家，技术美术，技术美术总监，和程序员。这让他有机会参与《使命召唤3》《除暴战警2》 《心灵杀手》和《Kinect星球大战》等众多著名游戏的开发。他现在跟他的商业伙伴Noah Kaarbo一起运营自己的Ozone 工作。，同时，他们也跟亚马逊，Eline Media，IGT和微软也有过合作。他之前为微软游戏工作室，动视和Surreal工作过。现如今他离开了哪些工作室，一手开办了自己的 CreativeTD 和 Ozone 工作室（感觉翻译成互动娱乐更好）。Kenny通过Packt Publishing出版社写了他的第一版 《Unity Shaders and Effects Cookbook》书，整个过程非常的愉快。" }, { "title": "关于作者", "url": "/game-tech-post-old/posts/%E5%85%B3%E4%BA%8E%E4%BD%9C%E8%80%85/", "categories": "shader", "tags": "U3D, Shader, Cookbook, 中文版", "date": "2020-08-05 00:00:00 +0800", "snippet": "关于作者Alan Zucconi 是一个充满激情的开发者, 作者, 和一个激励的演讲者, 是开发者领域的佼佼者。 有着过去10年来相关领域的专业技能积累，并且决定在今后把精力都放在学术领域和游戏产业领域。作为一名自由职业者，他以非凡的创造力去探索如何让游戏更好的与艺术结合。 在此之前，他在伦敦帝国理工学院工作，在这里他发现了他教学和写作的激情。 他的头衔包括了 gravity puzzle...", "content": "关于作者Alan Zucconi 是一个充满激情的开发者, 作者, 和一个激励的演讲者, 是开发者领域的佼佼者。 有着过去10年来相关领域的专业技能积累，并且决定在今后把精力都放在学术领域和游戏产业领域。作为一名自由职业者，他以非凡的创造力去探索如何让游戏更好的与艺术结合。 在此之前，他在伦敦帝国理工学院工作，在这里他发现了他教学和写作的激情。 他的头衔包括了 gravity puzzle, 0RBITALIS, 和the upcoming time travel platformer, Still Time（这些单词实在不知道怎么翻译了，应该是游戏名字）.Kenneth Lammers 在游戏领域有超过15年的经验, 担任过角色艺术家，技术美术，技术美术总监，和程序员。这让他有机会参与《使命召唤3》《除暴战警2》 《心灵杀手》和《Kinect星球大战》等众多著名游戏的开发。他现在跟他的商业伙伴Noah Kaarbo一起运营自己的Ozone 工作。，同时，他们也跟亚马逊，Eline Media，IGT和微软也有过合作。他之前为微软游戏工作室，动视和Surreal工作过。现如今他离开了哪些工作室，一手开办了自己的 CreativeTD 和 Ozone 工作室（感觉翻译成互动娱乐更好）。Kenny通过Packt Publishing出版社写了他的第一版 《Unity Shaders and Effects Cookbook》书，整个过程非常的愉快。" } ]
